# 머신러닝 기반 S&P 500 방향성 예측 성능 분석 (FIXED VERSION)

**생성일시**: 2025-12-20 18:33:29

**예측 기간**: 60일 후 방향성

**사용 방법론**: Volatility Indices 기반 머신러닝 모델 (Campisi et al., 2024)

**주요 개선사항**:
- ✅ Data Leakage 문제 해결 (Pipeline 사용)
- ✅ Diebold-Mariano 통계 검정 추가
- ✅ Performance 최적화 (Refit Frequency)

---

## 1. 데이터 요약

- **수집 기간**: 2011-01-03 ~ 2022-07-29
- **총 관측치 수**: 2,913
- **변수 수**: 10
- **Walk-Forward CV 이터레이션**: 755개
- **Refit Frequency**: 매 1일
- **데이터 소스**: Yahoo Finance

## 2. 기술 통계량

| Variable   |    N |    Mean |   St. Dev. |   Skewness |   Kurtosis |   rho1 |   rho2 |   rho3 |    ADF |         JB |
|:-----------|-----:|--------:|-----------:|-----------:|-----------:|-------:|-------:|-------:|-------:|-----------:|
| VIX        | 2913 |  18.145 |      7.353 |      2.532 |     11.379 |  0.967 |  0.945 |  0.921 | -5.33  |  18767     |
| VIX9D      | 2913 |  17.56  |      8.801 |      3.294 |     19.505 |  0.939 |  0.908 |  0.87  | -6.658 |  51273.3   |
| VIX3M      | 2913 |  20.037 |      6.572 |      1.979 |      7.007 |  0.981 |  0.968 |  0.951 | -3.729 |   7834.16  |
| VIX6M      | 2913 |  21.419 |      5.879 |      1.395 |      2.607 |  0.987 |  0.977 |  0.965 | -2.987 |   1764.74  |
| VVIX       | 2913 |  96.772 |     16.883 |      1.153 |      2.859 |  0.946 |  0.899 |  0.856 | -5.954 |   1631.77  |
| SKEW       | 2913 | 128.957 |      9.666 |      0.763 |      0.295 |  0.928 |  0.896 |  0.866 | -4.248 |    292.503 |
| VXN        | 2913 |  20.863 |      7.504 |      1.838 |      5.776 |  0.972 |  0.953 |  0.932 | -4.768 |   5670.55  |
| GVZ        | 2913 |  17.144 |      4.955 |      1.284 |      3.126 |  0.976 |  0.954 |  0.934 | -4.12  |   1980.05  |
| OVX        | 2913 |  37.335 |     18.956 |      5.082 |     44.54  |  0.966 |  0.93  |  0.907 | -4.896 | 252462     |
| RVOL       | 2913 |  14.769 |      9.661 |      3.675 |     20.19  |  0.996 |  0.99  |  0.981 | -6.667 |  55847     |
| Returns60  | 2913 |   0.023 |      0.065 |     -1.046 |      3.379 |  0.971 |  0.951 |  0.923 | -5.853 |   1910.34  |

## 3. VIF (Variance Inflation Factor)

| Variable   |      VIF |
|:-----------|---------:|
| VIX3M      | 2619.89  |
| VIX6M      | 1277.7   |
| VIX        | 1143.52  |
| VIX9D      |  211.145 |
| VXN        |  158.932 |
| VVIX       |  116.066 |
| SKEW       |   82.123 |
| GVZ        |   30.637 |
| RVOL       |   16.598 |
| OVX        |   14.972 |

## 4. 모델 성능 비교 (Feature Selection 전)

### 4.1 분류 모델

| Model                   |   Accuracy |    AUC |   F-measure |
|:------------------------|-----------:|-------:|------------:|
| Logistic Regression     |     0.645  | 0.5866 |      0.7832 |
| LDA                     |     0.6318 | 0.5938 |      0.7732 |
| Random Forest (Clf)     |     0.6609 | 0.5413 |      0.7922 |
| Bagging (Clf)           |     0.6384 | 0.5412 |      0.7749 |
| Gradient Boosting (Clf) |     0.6556 | 0.5455 |      0.7876 |

### 4.2 회귀 모델

| Model                   |   Accuracy |    AUC |   F-measure |
|:------------------------|-----------:|-------:|------------:|
| Linear Regression       |     0.6556 | 0.5927 |      0.7883 |
| Ridge Regression        |     0.6556 | 0.5887 |      0.7883 |
| Lasso Regression        |     0.6424 | 0.5583 |      0.7816 |
| Random Forest (Reg)     |     0.6596 | 0.503  |      0.7902 |
| Bagging (Reg)           |     0.6437 | 0.5014 |      0.7786 |
| Gradient Boosting (Reg) |     0.6556 | 0.5028 |      0.7879 |

## 5. 모델 성능 비교 (Feature Selection 후)

### 5.1 분류 모델

| Model                   |   Accuracy |    AUC |   F-measure |
|:------------------------|-----------:|-------:|------------:|
| Logistic Regression     |     0.645  | 0.5829 |      0.7832 |
| LDA                     |     0.6291 | 0.5846 |      0.7712 |
| Random Forest (Clf)     |     0.6675 | 0.5476 |      0.7971 |
| Bagging (Clf)           |     0.657  | 0.5556 |      0.7875 |
| Gradient Boosting (Clf) |     0.6596 | 0.5501 |      0.7902 |

### 5.2 회귀 모델

| Model                   |   Accuracy |    AUC |   F-measure |
|:------------------------|-----------:|-------:|------------:|
| Linear Regression       |     0.6464 | 0.5571 |      0.7824 |
| Ridge Regression        |     0.6464 | 0.5568 |      0.7824 |
| Lasso Regression        |     0.6424 | 0.5583 |      0.7816 |
| Random Forest (Reg)     |     0.6556 | 0.5303 |      0.7893 |
| Bagging (Reg)           |     0.6199 | 0.5319 |      0.7626 |
| Gradient Boosting (Reg) |     0.6583 | 0.5197 |      0.7906 |

## 6. Diebold-Mariano 통계 검정

### 6.1 분류 모델 쌍별 비교

**통계적으로 유의한 차이 (p < 0.05):**

| Model 1             | Model 2                 |   DM Statistic |   p-value | Significant (5%)   |
|:--------------------|:------------------------|---------------:|----------:|:-------------------|
| Logistic Regression | LDA                     |        -3.2271 |    0.0013 | True               |
| Logistic Regression | Random Forest (Clf)     |         3.9373 |    0.0001 | True               |
| Logistic Regression | Gradient Boosting (Clf) |         1.9795 |    0.0478 | True               |
| LDA                 | Random Forest (Clf)     |         5.3012 |    0      | True               |
| LDA                 | Bagging (Clf)           |         2.9556 |    0.0031 | True               |
| LDA                 | Gradient Boosting (Clf) |         3.5341 |    0.0004 | True               |

### 6.2 회귀 모델 쌍별 비교

**통계적으로 유의한 차이 (p < 0.05):**

| Model 1             | Model 2                 |   DM Statistic |   p-value | Significant (5%)   |
|:--------------------|:------------------------|---------------:|----------:|:-------------------|
| Linear Regression   | Bagging (Reg)           |        -3.1037 |    0.0019 | True               |
| Ridge Regression    | Bagging (Reg)           |        -3.1037 |    0.0019 | True               |
| Lasso Regression    | Random Forest (Reg)     |         2.242  |    0.025  | True               |
| Lasso Regression    | Bagging (Reg)           |        -2.6024 |    0.0093 | True               |
| Lasso Regression    | Gradient Boosting (Reg) |         2.274  |    0.023  | True               |
| Random Forest (Reg) | Bagging (Reg)           |        -4.9234 |    0      | True               |
| Bagging (Reg)       | Gradient Boosting (Reg) |         4.5888 |    0      | True               |

## 7. 모델 성능 요약

### 7.1 Feature Selection 전후 비교

**분류 모델:**
- Feature Selection 전: Random Forest (Clf) (Accuracy: 0.6609)
- Feature Selection 후: Random Forest (Clf) (Accuracy: 0.6675)

**회귀 모델:**
- Feature Selection 전: Random Forest (Reg) (Accuracy: 0.6596)
- Feature Selection 후: Gradient Boosting (Reg) (Accuracy: 0.6583)

### 7.2 전체 최고 성능 모델

**최고 성능**: Random Forest (Clf)
- Accuracy: 0.6675
- AUC: 0.5476
- F-measure: 0.7971

## 8. 주요 인사이트

**1. Feature Selection 효과**
- 전체 평균 Accuracy: 0.6495 → 0.6479
- Feature Selection으로 성능 변화 (-0.0016)

**2. 분류 vs 회귀 모델**
- 분류 모델 평균 Accuracy: 0.6517
- 회귀 모델 평균 Accuracy: 0.6448
- 분류 모델이 방향 예측에 더 효과적

**3. Data Leakage 문제 해결**
- ✅ Standardization을 CV loop 내부로 이동 (Pipeline 사용)
- ✅ Feature Selection을 CV loop 내부로 이동 (SelectFromModel)
- ✅ 이로 인해 원본 코드 대비 성능이 낮아질 수 있으나, 이것이 정확한 out-of-sample 성능임

---

## 9. 시각화

- `figures/correlation_heatmap.png`: 상관관계 히트맵
- `figures/roc_curves.png`: ROC 곡선
- `figures/returns_timeseries.png`: 수익률 시계열
