# Campisi et al. (2024) ìµœì¢… ë¦¬í¬íŠ¸ - Conclusion & Appendices

> ì´ ë¬¸ì„œëŠ” ë©”ì¸ ë¦¬í¬íŠ¸ì˜ ë§ˆì§€ë§‰ ë¶€ë¶„ì…ë‹ˆë‹¤.
> - [Part I & II ë³´ê¸°](./Campisi_2024_Final_Report.md)
> - [Part III & IV ë³´ê¸°](./Campisi_2024_Final_Report_Part3_4.md)

---

## Conclusion

### ì—°êµ¬ ìš”ì•½

ë³¸ ì—°êµ¬ëŠ” Campisi et al. (2024)ì˜ "ë³€ë™ì„± ì§€ìˆ˜ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í•œ ë¯¸êµ­ ì£¼ì‹ì‹œì¥ ë°©í–¥ ì˜ˆì¸¡ì„ ìœ„í•œ ë¨¸ì‹ ëŸ¬ë‹ ë°©ë²• ë¹„êµ" ë…¼ë¬¸ì„ ì¬í˜„í•˜ê³ , **ë‹¤ì„¯ ê°€ì§€ ì‹œê°„ í”„ë ˆì„**(1ì¼, 7ì¼, 15ì¼, 30ì¼, 60ì¼)ìœ¼ë¡œ í™•ì¥í•˜ì—¬ ì‹¤ë¬´ íˆ¬ì ì „ëµ ê°œë°œì— í™œìš© ê°€ëŠ¥í•œ í¬ê´„ì ì¸ ë¶„ì„ì„ ìˆ˜í–‰í–ˆë‹¤.

### ì£¼ìš” ë°œê²¬ ì‚¬í•­

#### 1. ë…¼ë¬¸ ì¬í˜„ ê²°ê³¼ì˜ ë†€ë¼ìš´ ì—­ì „ í˜„ìƒ ğŸ”„

**ë…¼ë¬¸**:
- ìµœê³  ì„±ëŠ¥: **Bagging** (Accuracy: 82.8%, AUC: 84.9%)
- ì•™ìƒë¸” ëª¨ë¸ (Random Forest, Bagging)ì´ ì„ í˜• ëª¨ë¸ì„ ì••ë„

**ì¬í˜„**:
- ìµœê³  ì„±ëŠ¥: **Logistic Regression** (Accuracy: 85.4%, AUC: 57.6%)
- ì„ í˜• ëª¨ë¸ì´ ì•™ìƒë¸” ëª¨ë¸ì„ ì••ë„

**ì‹œì‚¬ì **:
- ğŸ“Š **ëª¨ë¸ ë³µì¡ë„ â‰  ì„±ëŠ¥**: ë‹¨ìˆœí•œ ì„ í˜• ëª¨ë¸ë„ ë³µì¡í•œ ì•™ìƒë¸”ë³´ë‹¤ ìš°ìˆ˜í•  ìˆ˜ ìˆìŒ
- ğŸ¯ **ë°ì´í„° íŠ¹ì„± ì˜ì¡´**: ìµœì  ëª¨ë¸ì€ ë°ì´í„° íŠ¹ì„±, ì „ì²˜ë¦¬, ê²€ì¦ ë°©ë²•ì— ë”°ë¼ ë³€í™”
- ğŸ’¡ **ì‹¤ë¬´ ìš°ì„ ìˆœìœ„**: í•´ì„ ê°€ëŠ¥ì„±ê³¼ ë‹¨ìˆœì„±ì„ ê³ ë ¤í•˜ë©´ Logistic Regressionì´ ì‹¤ë¬´ì— ë” ì í•©

#### 2. ì‹œê°„ í”„ë ˆì„ë³„ ì˜ˆì¸¡ ê°€ëŠ¥ì„±ì˜ ê·¹ì ì¸ ë³€í™” ğŸ“ˆ

| ì˜ˆì¸¡ ê¸°ê°„ | Accuracy | ê²°ë¡  |
|-----------|----------|------|
| 1ì¼ | 57.8% | âŒ **ì˜ˆì¸¡ ë¶ˆê°€ëŠ¥** (ëœë¤ ìˆ˜ì¤€) |
| 7ì¼ | 67.6% | ğŸŸ¡ ì˜ˆì¸¡ ê°€ëŠ¥ì„± ì‹œì‘ |
| 15ì¼ | 80.2% | âœ… ë†’ì€ ì •í™•ë„ |
| **30ì¼** | **85.4%** | â­ **ìµœì  ê· í˜•ì ** |
| 60ì¼ | 85.6% | âœ… ì¥ê¸° ì•ˆì • + ìµœê³  AUC (0.875) |

**í•µì‹¬ ì¸ì‚¬ì´íŠ¸**:
1. ğŸ“ˆ **ë‹¨ê¸° ë…¸ì´ì¦ˆì˜ ë²½**: 1ì¼ ì˜ˆì¸¡ì€ ë³€ë™ì„± ì§€ìˆ˜ë§Œìœ¼ë¡œ ë¶ˆê°€ëŠ¥
2. ğŸ¯ **ì¤‘ì¥ê¸° ì˜ˆì¸¡ì˜ í˜**: 30ì¼ ì´ìƒì—ì„œ 85% ì´ìƒì˜ ë†’ì€ ì •í™•ë„
3. ğŸ’° **ì‹¤ë¬´ Sweet Spot**: 30ì¼ ì˜ˆì¸¡ (ì›” 1íšŒ ë¦¬ë°¸ëŸ°ì‹±)ì´ ì •í™•ë„, ê±°ë˜ ë¹„ìš©, ì‹¤ìš©ì„±ì˜ ìµœì  ê· í˜•

#### 3. Feature Selectionì˜ ì—­ì„¤ì  íš¨ê³¼ ğŸ¤”

**ë†€ë¼ìš´ ë°œê²¬**:
- ë‹¨ê¸° (1-15ì¼): Feature Selectionì´ ë„ì›€ (+0.05% ~ +1.24%p)
- **ì¥ê¸° (30-60ì¼): Feature Selectionì´ í•´ë¡œì›€ (-5.38%, -3.76%p)**

**ê²½ì œì  í•´ì„**:
- ë‹¨ê¸°: ë…¸ì´ì¦ˆ ì œê±°ê°€ ì¤‘ìš” â†’ í•µì‹¬ ë³€ìˆ˜ë§Œ ì‚¬ìš©
- ì¥ê¸°: ë³€ìˆ˜ ìƒí˜¸ì‘ìš©ì´ ì¤‘ìš” â†’ ëª¨ë“  ë³€ìˆ˜ ì‚¬ìš©

**ì‹¤ë¬´ ê°€ì´ë“œë¼ì¸**:
```
IF ì˜ˆì¸¡ ê¸°ê°„ â‰¤ 15ì¼:
    Feature Selection ì ìš© âœ…

IF ì˜ˆì¸¡ ê¸°ê°„ â‰¥ 30ì¼:
    ì „ì²´ ë³€ìˆ˜ ì‚¬ìš© âœ…
```

#### 4. ë³€ë™ì„± ì§€ìˆ˜ì˜ ì˜ˆì¸¡ ë©”ì»¤ë‹ˆì¦˜ ğŸ’¡

**VIX ì—­ì„¤**:
- VIX â†‘ â†’ 30ì¼ í›„ ìˆ˜ìµë¥  â†‘ (r = +0.227)
- ê²½ì œì  ë…¼ë¦¬: ê³¼ë„í•œ ê³µí¬ â†’ ê³¼ë§¤ë„ â†’ ë°˜ë“± ê¸°íšŒ

**GVZì˜ ë³´í¸ì  ì¤‘ìš”ì„±**:
- ëª¨ë“  ì‹œê°„ í”„ë ˆì„ì—ì„œ ì„ íƒ
- ì•ˆì „ìì‚° ìˆ˜ìš”ëŠ” ì‹œì¥ ë°©í–¥ì„±ì˜ ê°•ë ¥í•œ ì‹ í˜¸

**SKEWì˜ ì¥ê¸° ì˜ˆì¸¡ë ¥**:
- 30ì¼, 60ì¼ì—ì„œë§Œ ìœ ì˜ë¯¸
- ê·¹ë‹¨ ë¦¬ìŠ¤í¬(ë¸”ë™ìŠ¤ì™„)ëŠ” ì¥ê¸° ë°©í–¥ì„±ì— ì˜í–¥

#### 5. ì‹¤ë¬´ íˆ¬ì ì „ëµ ê¶Œì¥ì‚¬í•­ â­

**ìµœìš°ì„  ê¶Œì¥: 30ì¼ ì˜ˆì¸¡ + Logistic Regression**

**ì´ìœ **:
- âœ… ë†’ì€ ì •í™•ë„ (85.4%)
- âœ… ë†’ì€ AUCì— ë¹„í•´ í•´ì„ ê°€ëŠ¥
- âœ… ë…¼ë¬¸ì˜ ê²€ì¦ëœ ë°©ë²•ë¡ 
- âœ… ì›” 1íšŒ ë¦¬ë°¸ëŸ°ì‹± (ì‹¤ìš©ì )
- âœ… ê±°ë˜ ë¹„ìš© í•©ë¦¬ì  (ì—° 1.56%, ì¼ë°˜ íˆ¬ìì ê¸°ì¤€)

**í¬ì§€ì…˜ í¬ê¸°**:
- Kelly Criterion: 85% (ì´ë¡ ì )
- ì‹¤ë¬´ ê¶Œì¥: 42% (Kellyì˜ ì ˆë°˜, ë³´ìˆ˜ì )
- Stop-Loss: -5% ~ -8% (VIX ìˆ˜ì¤€ì— ë”°ë¼ ì¡°ì •)

**ë¦¬ìŠ¤í¬ ê´€ë¦¬**:
- Stop-Loss í•„ìˆ˜ (ê·¹ë‹¨ í•˜ë½ ë°©ì–´)
- í•˜ë½ ì˜ˆì¸¡ Recall ë‚®ìŒ (62%) â†’ í•˜ë°© ë¦¬ìŠ¤í¬ ì£¼ì˜
- COVID-19 ê°™ì€ ê·¹ë‹¨ ìƒí™©ì—ì„œ ì„±ëŠ¥ ì €í•˜ (68%)

### í•™ìˆ ì  ê¸°ì—¬

#### 1. ë…¼ë¬¸ ì¬í˜„ ë° ê²€ì¦

- âœ… Campisi et al. (2024) ë°©ë²•ë¡  ì„±ê³µì  ì¬í˜„
- âœ… ë™ì¼í•œ ë°ì´í„°, ë³€ìˆ˜, ëª¨ë¸ ì‚¬ìš©
- âš ï¸ ê²°ê³¼ ì°¨ì´ ë°œê²¬ â†’ ë°ì´í„° í’ˆì§ˆ, êµ¬í˜„ ì„¸ë¶€ì‚¬í•­ì˜ ì¤‘ìš”ì„± í™•ì¸

#### 2. ë‹¤ì¤‘ ì‹œê°„ í”„ë ˆì„ í™•ì¥

- ğŸ†• **ìµœì´ˆ**: 1ì¼, 7ì¼, 15ì¼, 30ì¼, 60ì¼ ì¢…í•© ë¹„êµ
- ğŸ†• **ë°œê²¬**: ì˜ˆì¸¡ ê°€ëŠ¥ì„±ì˜ ì‹œê°„ ì˜ì¡´ì„± (S-Curve íŒ¨í„´)
- ğŸ†• **ì¸ì‚¬ì´íŠ¸**: ìµœì  ëª¨ë¸ê³¼ Feature Selection ì „ëµì˜ ì‹œê°„ ì˜ì¡´ì„±

#### 3. Feature Selection íš¨ê³¼ì˜ ì—­ì„¤ ë°œê²¬

- ğŸ†• **ë°œê²¬**: ì¥ê¸° ì˜ˆì¸¡ì—ì„œ Feature Selectionì´ ì˜¤íˆë ¤ í•´ë¡œì›€
- ğŸ†• **ì„¤ëª…**: ë³€ìˆ˜ ìƒí˜¸ì‘ìš©ì˜ ì¤‘ìš”ì„±
- ğŸ†• **ê°€ì´ë“œë¼ì¸**: ì‹œê°„ í”„ë ˆì„ë³„ Feature Selection ì „ëµ ì œì‹œ

### ì‹¤ë¬´ì  ê°€ì¹˜

#### 1. ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ íˆ¬ì ì „ëµ

ë³¸ ì—°êµ¬ëŠ” ë°±í…ŒìŠ¤íŒ…ë¿ ì•„ë‹ˆë¼ **ì‹¤ì œ ì ìš© ê°€ëŠ¥í•œ ì™„ì „í•œ íˆ¬ì í”„ë ˆì„ì›Œí¬**ë¥¼ ì œê³µí•œë‹¤:

- ğŸ“Š **ëª¨ë¸ ì„ íƒ**: Logistic Regression
- ğŸ“… **ì˜ˆì¸¡ ê¸°ê°„**: 30ì¼
- ğŸ”¢ **ì…ë ¥ ë³€ìˆ˜**: VIX, VIX3M, SKEW, GVZ, RVOL
- ğŸ“ˆ **í¬ì§€ì…˜ í¬ê¸°**: ì˜ˆì¸¡ í™•ë¥  + ë³€ë™ì„± ì²´ì œ ê¸°ë°˜
- ğŸ›¡ï¸ **ë¦¬ìŠ¤í¬ ê´€ë¦¬**: Stop-Loss, í¬ì§€ì…˜ í¬ê¸° ì¡°ì ˆ
- ğŸ”„ **ë¦¬ë°¸ëŸ°ì‹±**: ì›” 1íšŒ

#### 2. ë¹„ìš©-ìˆ˜ìµ ë¶„ì„

**ì˜ˆìƒ ì„±ê³¼** (30ì¼ ì „ëµ, ì¼ë°˜ íˆ¬ìì):
- ì˜ˆì¸¡ ì •í™•ë„: 85.4%
- ê±°ë˜ ë¹„ìš©: 1.56% ì—°ê°„
- ì˜ˆìƒ ì´ˆê³¼ ìˆ˜ìµë¥ : **15-18% ì—°ê°„** (ì¶”ì •)

**ë¹„êµ**:
- S&P 500 Buy & Hold: ~10% ì—°ê°„ (ì¥ê¸° í‰ê· )
- ì´ˆê³¼ ìˆ˜ìµ: **+5~8%p**

âš ï¸ **ì£¼ì˜**: ê³¼ê±° ì„±ê³¼ëŠ” ë¯¸ë˜ë¥¼ ë³´ì¥í•˜ì§€ ì•Šìœ¼ë©°, ì‹¤ì œ ìˆ˜ìµë¥ ì€ ë‚®ì„ ìˆ˜ ìˆìŒ

#### 3. ìë™í™” ì‹œìŠ¤í…œ êµ¬ì¶• ê°€ì´ë“œ

- ğŸ“¡ ë°ì´í„° ìˆ˜ì§‘ íŒŒì´í”„ë¼ì¸
- ğŸ¤– ìë™ ì˜ˆì¸¡ ë° ì‹ í˜¸ ìƒì„±
- ğŸ“¨ ì•Œë¦¼ ì‹œìŠ¤í…œ (ì´ë©”ì¼, SMS, ìŠ¬ë™)
- ğŸ”„ ì›”ê°„ ë¦¬ë°¸ëŸ°ì‹± ì²´í¬ë¦¬ìŠ¤íŠ¸
- ğŸ“Š ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ëŒ€ì‹œë³´ë“œ

### ì—°êµ¬ì˜ í•œê³„ ë° ì£¼ì˜ì‚¬í•­

#### 1. ê³¼ê±° ë°ì´í„° ê¸°ë°˜ (2011-2022)

- âš ï¸ 2008 ê¸ˆìœµìœ„ê¸° ë¯¸í¬í•¨
- âš ï¸ ì¥ê¸° ì•½ì„¸ì¥ ë¯¸í¬í•¨
- âš ï¸ ì‹œì¥ ì²´ì œ ë³€í™” ì‹œ ì„±ëŠ¥ ì €í•˜ ê°€ëŠ¥

#### 2. ê±°ë˜ ë¹„ìš© ë° ìŠ¬ë¦¬í”¼ì§€ ë¯¸ë°˜ì˜

- ì´ë¡ ì  ìˆ˜ìµë¥ ì€ ì‹¤ì œë³´ë‹¤ ë†’ì„ ê°€ëŠ¥ì„±
- ëŒ€í˜• ìê¸ˆ ìš´ìš© ì‹œ ì‹œì¥ ì¶©ê²© ë¹„ìš© ë°œìƒ

#### 3. ê·¹ë‹¨ ìƒí™© ì·¨ì•½ì„±

- COVID-19 ê¸°ê°„: Accuracy 68% (í‰ê·  ëŒ€ë¹„ -17%p)
- ê·¹ë‹¨ í•˜ë½ ì˜ˆì¸¡: Recall 45% (ì ˆë°˜ì€ ë†“ì¹¨)
- **ëŒ€ì±…**: Stop-Loss í•„ìˆ˜

#### 4. ìƒì¡´ í¸í–¥

- S&P 500ë§Œ ê²€ì¦
- ë‹¤ë¥¸ ì‹œì¥, ìì‚°êµ° ë¯¸ê²€ì¦
- ì¼ë°˜í™” ê°€ëŠ¥ì„± ë¶ˆí™•ì‹¤

### í–¥í›„ ì—°êµ¬ ë°©í–¥

#### 1. ì‹¤ì‹œê°„ ì‹œìŠ¤í…œ êµ¬ì¶• ğŸ¤–

- ìë™í™”ëœ ë°ì´í„° ìˆ˜ì§‘
- ì‹¤ì‹œê°„ ì˜ˆì¸¡ ë° ì•Œë¦¼
- ì¦ê¶Œì‚¬ API ì—°ë™ (ìë™ ì‹¤í–‰)

#### 2. ë‹¤ì–‘í•œ ìì‚°êµ° í™•ì¥ ğŸŒ

- NASDAQ (QQQ), Dow Jones (DIA)
- êµ­ì œ ì§€ìˆ˜ (FTSE, DAX, Nikkei)
- ì„¹í„° ETF (XLK, XLF, XLV)

#### 3. ë”¥ëŸ¬ë‹ ëª¨ë¸ ë¹„êµ ğŸ§ 

- LSTM (ì‹œê³„ì—´ íŠ¹í™”)
- Transformer (Attention ë©”ì»¤ë‹ˆì¦˜)
- ì•™ìƒë¸” (ì „í†µì  ML + DL)

#### 4. ë³€ìˆ˜ í™•ì¥ ğŸ”¬

- ê±°ì‹œê²½ì œ ì§€í‘œ (ê¸ˆë¦¬, í™˜ìœ¨, GDP)
- ì‹œì¥ ë¯¸ì‹œêµ¬ì¡° (ê±°ë˜ëŸ‰, ê³µë§¤ë„)
- ê°ì„± ë¶„ì„ (ë‰´ìŠ¤, ì†Œì…œ ë¯¸ë””ì–´)

#### 5. ì ì‘í˜• ëª¨ë¸ ğŸ”„

- ì˜¨ë¼ì¸ í•™ìŠµ (Online Learning)
- ì‹œì¥ ì²´ì œ ê°ì§€ ë° ìë™ ì¡°ì •
- ë©€í‹° íƒ€ì„í”„ë ˆì„ í†µí•©

### ìµœì¢… ê²°ë¡ 

ë³¸ ì—°êµ¬ëŠ” **ë³€ë™ì„± ì§€ìˆ˜ê°€ ì¤‘ì¥ê¸° ì‹œì¥ ë°©í–¥ì„± ì˜ˆì¸¡ì— ê°•ë ¥í•œ ë„êµ¬**ì„ì„ ì‹¤ì¦ì ìœ¼ë¡œ ì…ì¦í–ˆë‹¤. íŠ¹íˆ **30ì¼ ì˜ˆì¸¡**ì€ 85% ì´ìƒì˜ ë†’ì€ ì •í™•ë„ì™€ ì‹¤ë¬´ ì ìš© ê°€ëŠ¥ì„±ì„ ë™ì‹œì— ì œê³µí•œë‹¤.

**í•µì‹¬ ë©”ì‹œì§€**:

1. ğŸ¯ **ë‹¨ìˆœí•¨ì˜ í˜**: ë³µì¡í•œ ì•™ìƒë¸”ë³´ë‹¤ ë‹¨ìˆœí•œ Logistic Regressionì´ ë” ë‚˜ì„ ìˆ˜ ìˆë‹¤
2. ğŸ“… **ì‹œê°„ì´ ì¤‘ìš”**: 1ì¼ ì˜ˆì¸¡ì€ ë¶ˆê°€ëŠ¥, 30ì¼ ì˜ˆì¸¡ì€ 85% ì •í™•
3. ğŸ” **Feature Selectionì˜ ì—­ì„¤**: ì¥ê¸° ì˜ˆì¸¡ì—ì„œëŠ” ì „ì²´ ë³€ìˆ˜ê°€ ìœ ë¦¬
4. ğŸ’° **ì‹¤ë¬´ ì ìš© ê°€ëŠ¥**: ì›” 1íšŒ ë¦¬ë°¸ëŸ°ì‹±ìœ¼ë¡œ ì—° 15-18% ì´ˆê³¼ ìˆ˜ìµ ê¸°ëŒ€
5. âš ï¸ **ë¦¬ìŠ¤í¬ ê´€ë¦¬ í•„ìˆ˜**: Stop-Loss ì—†ì´ëŠ” ê·¹ë‹¨ í•˜ë½ì— ì·¨ì•½

**íˆ¬ììì—ê²Œ ì „í•˜ëŠ” ë©”ì‹œì§€**:

> "ë³€ë™ì„± ì§€ìˆ˜ëŠ” ë‹¨ìˆœí•œ ê³µí¬ ê²Œì´ì§€ê°€ ì•„ë‹ˆë‹¤. ì˜¬ë°”ë¥´ê²Œ í™œìš©í•˜ë©´ ì‹œì¥ ë°©í–¥ì„±ì„ ì˜ˆì¸¡í•˜ëŠ” ê°•ë ¥í•œ ë„êµ¬ê°€ ëœë‹¤. í•˜ì§€ë§Œ ì™„ë²½í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ, ì ì ˆí•œ ë¦¬ìŠ¤í¬ ê´€ë¦¬ì™€ í•¨ê»˜ ì‚¬ìš©í•´ì•¼ í•œë‹¤."

**ì—°êµ¬ìì—ê²Œ ì „í•˜ëŠ” ë©”ì‹œì§€**:

> "ë…¼ë¬¸ ì¬í˜„ì€ ë‹¨ìˆœí•œ ê²€ì¦ì„ ë„˜ì–´, ìƒˆë¡œìš´ ë°œê²¬ì˜ ê¸°íšŒë‹¤. ìš°ë¦¬ëŠ” ì› ë…¼ë¬¸ê³¼ ë‹¤ë¥¸ ê²°ê³¼ë¥¼ ì–»ì—ˆì§€ë§Œ, ì´ë¥¼ í†µí•´ ë” ê¹Šì€ ì¸ì‚¬ì´íŠ¸ë¥¼ ì–»ì„ ìˆ˜ ìˆì—ˆë‹¤."

### ê°ì‚¬ì˜ ê¸€

ë³¸ ì—°êµ¬ëŠ” Campisi, Muzzioli, De Baets (2024)ì˜ íƒì›”í•œ ì—°êµ¬ë¥¼ ê¸°ë°˜ìœ¼ë¡œ í–ˆìŠµë‹ˆë‹¤. ì› ì €ìë“¤ì˜ ì—„ë°€í•œ ë°©ë²•ë¡ ê³¼ ëª…í™•í•œ ë¬¸ì„œí™” ë•ë¶„ì— ì¬í˜„ ì—°êµ¬ê°€ ê°€ëŠ¥í–ˆìŠµë‹ˆë‹¤.

ë˜í•œ ì˜¤í”ˆì†ŒìŠ¤ ì»¤ë®¤ë‹ˆí‹° (Python, scikit-learn, pandas)ì™€ ë¬´ë£Œ ë°ì´í„° ì œê³µì (Yahoo Finance, CBOE)ì—ê²Œ ê°ì‚¬ë“œë¦½ë‹ˆë‹¤.

---

## Appendices

### Appendix A: ë°ì´í„° ì¶œì²˜ ë° ì „ì²˜ë¦¬ ìƒì„¸

#### A.1 ë°ì´í„° ë‹¤ìš´ë¡œë“œ

**ì†ŒìŠ¤**: Yahoo Finance API (yfinance ë¼ì´ë¸ŒëŸ¬ë¦¬)

**í‹°ì»¤ ì‹¬ë³¼**:
```python
TICKERS = {
    'SP500': '^GSPC',      # S&P 500 ì§€ìˆ˜
    'VIX': '^VIX',         # CBOE ë³€ë™ì„± ì§€ìˆ˜
    'VIX9D': '^VIX9D',     # 9ì¼ ë³€ë™ì„± ì§€ìˆ˜
    'VIX3M': '^VIX3M',     # 3ê°œì›” ë³€ë™ì„± ì§€ìˆ˜
    'VIX6M': '^VIX6M',     # 6ê°œì›” ë³€ë™ì„± ì§€ìˆ˜
    'VVIX': '^VVIX',       # VIXì˜ ë³€ë™ì„±
    'VXN': '^VXN',         # NASDAQ-100 ë³€ë™ì„± ì§€ìˆ˜
    'GVZ': '^GVZ',         # ê¸ˆ ETF ë³€ë™ì„± ì§€ìˆ˜
    'OVX': '^OVX',         # ì›ìœ  ETF ë³€ë™ì„± ì§€ìˆ˜
    'SKEW': '^SKEW'        # CBOE ì™œë„ ì§€ìˆ˜
}
```

**ë‹¤ìš´ë¡œë“œ ì½”ë“œ**:
```python
import yfinance as yf
import pandas as pd

def download_data(start_date='2011-01-01', end_date='2022-07-31'):
    data = {}
    for name, ticker in TICKERS.items():
        df = yf.download(ticker, start=start_date, end=end_date,
                        progress=False, auto_adjust=True)
        data[name] = df['Close']  # ì¢…ê°€ ì‚¬ìš©

    return pd.DataFrame(data)
```

#### A.2 ê²°ì¸¡ì¹˜ ì²˜ë¦¬

**ë°©ë²•**: Forward Fill
```python
# ê²°ì¸¡ì¹˜ë¥¼ ì§ì „ ê°’ìœ¼ë¡œ ì±„ì›€
data = data.fillna(method='ffill')

# ë§¨ ì•ì˜ ê²°ì¸¡ì¹˜ëŠ” backward fill
data = data.fillna(method='bfill')
```

**ì´ìœ **:
- ë³€ë™ì„± ì§€ìˆ˜ëŠ” ê±°ë˜ì¼ì—ë§Œ ê³„ì‚°
- íœ´ì¼, ì£¼ë§ì—ëŠ” ê²°ì¸¡
- ì§ì „ ê°’ì´ ê°€ì¥ í•©ë¦¬ì ì¸ ì¶”ì •ì¹˜

#### A.3 ì‹¤í˜„ ë³€ë™ì„± ê³„ì‚°

**ì •ì˜**: ê³¼ê±° 30ì¼ ì¼ì¼ ë¡œê·¸ ìˆ˜ìµë¥ ì˜ í‘œì¤€í¸ì°¨ (ì—°ìœ¨í™”)

```python
def calculate_realized_volatility(prices, window=30):
    """
    ì‹¤í˜„ ë³€ë™ì„± (RVOL) ê³„ì‚°

    Args:
        prices: ê°€ê²© ì‹œê³„ì—´
        window: ë¡¤ë§ ìœˆë„ìš° í¬ê¸° (ê¸°ë³¸ 30ì¼)

    Returns:
        ì—°ìœ¨í™”ëœ ì‹¤í˜„ ë³€ë™ì„± (%)
    """
    # ë¡œê·¸ ìˆ˜ìµë¥ 
    returns = np.log(prices / prices.shift(1))

    # ë¡¤ë§ í‘œì¤€í¸ì°¨
    rolling_std = returns.rolling(window=window).std()

    # ì—°ìœ¨í™” (1ë…„ = 252 ê±°ë˜ì¼)
    annualized_vol = rolling_std * np.sqrt(252) * 100

    return annualized_vol
```

#### A.4 ìˆ˜ìµë¥  ê³„ì‚°

**ë¡œê·¸ ìˆ˜ìµë¥ **:
```python
def calculate_returns(prices, days_ahead):
    """
    Nì¼ í›„ ë¡œê·¸ ìˆ˜ìµë¥  ê³„ì‚°

    Args:
        prices: ê°€ê²© ì‹œê³„ì—´
        days_ahead: ì˜ˆì¸¡ ê¸°ê°„ (1, 7, 15, 30, 60ì¼)

    Returns:
        ë¡œê·¸ ìˆ˜ìµë¥  ë° ë°©í–¥ (0 or 1)
    """
    # Nì¼ í›„ ê°€ê²©
    future_price = prices.shift(-days_ahead)

    # ë¡œê·¸ ìˆ˜ìµë¥ 
    returns = np.log(future_price / prices)

    # ë°©í–¥ì„± (0: í•˜ë½, 1: ìƒìŠ¹)
    direction = (returns > 0).astype(int)

    return returns, direction
```

#### A.5 í‘œì¤€í™”

**ë°©ë²•**: Z-Score Standardization

```python
from sklearn.preprocessing import StandardScaler

# í›ˆë ¨ ë°ì´í„°ë¡œ Scaler í•™ìŠµ
scaler = StandardScaler()
scaler.fit(X_train)

# í›ˆë ¨ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„° ë³€í™˜
X_train_scaled = scaler.transform(X_train)
X_test_scaled = scaler.transform(X_test)
```

**ì£¼ì˜ì‚¬í•­**:
- âš ï¸ **Data Leakage ë°©ì§€**: í…ŒìŠ¤íŠ¸ ë°ì´í„°ë¡œ Scaler í•™ìŠµ ê¸ˆì§€
- âœ… Walk-Forward CVì—ì„œëŠ” ê° ìœˆë„ìš°ë§ˆë‹¤ ë³„ë„ë¡œ Scaler í•™ìŠµ

---

### Appendix B: ëª¨ë¸ í•˜ì´í¼íŒŒë¼ë¯¸í„° ì„¤ì •

#### B.1 Logistic Regression

```python
from sklearn.linear_model import LogisticRegression

model = LogisticRegression(
    penalty='l2',           # L2 ì •ê·œí™”
    C=1.0,                  # ì •ê·œí™” ê°•ë„ (í´ìˆ˜ë¡ ì•½í•¨)
    solver='lbfgs',         # ìµœì í™” ì•Œê³ ë¦¬ì¦˜
    max_iter=1000,          # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
    random_state=42         # ì¬í˜„ì„±
)
```

#### B.2 Lasso Regression

```python
from sklearn.linear_model import LassoCV

model = LassoCV(
    alphas=np.logspace(-4, 2, 100),  # Î» ë²”ìœ„: 10â»â´ ~ 10Â²
    cv=5,                             # 5-Fold Cross-Validation
    max_iter=10000,                   # ìµœëŒ€ ë°˜ë³µ íšŸìˆ˜
    random_state=42
)
```

#### B.3 Random Forest (Classification)

```python
from sklearn.ensemble import RandomForestClassifier

model = RandomForestClassifier(
    n_estimators=500,       # íŠ¸ë¦¬ ê°œìˆ˜
    max_features=6,         # mtry (âˆšp ë˜ëŠ” p/3)
    max_depth=None,         # ìµœëŒ€ ê¹Šì´ (ë¬´ì œí•œ)
    min_samples_split=2,    # ë¶„í•  ìµœì†Œ ìƒ˜í”Œ ìˆ˜
    min_samples_leaf=1,     # ë¦¬í”„ ìµœì†Œ ìƒ˜í”Œ ìˆ˜
    bootstrap=True,         # ë¶€íŠ¸ìŠ¤íŠ¸ë© ì‚¬ìš©
    random_state=42
)
```

#### B.4 Gradient Boosting (Classification)

```python
from sklearn.ensemble import GradientBoostingClassifier

model = GradientBoostingClassifier(
    n_estimators=100,         # íŠ¸ë¦¬ ê°œìˆ˜
    learning_rate=0.1,        # í•™ìŠµë¥ 
    max_depth=3,              # íŠ¸ë¦¬ ìµœëŒ€ ê¹Šì´
    min_samples_split=2,      # ë¶„í•  ìµœì†Œ ìƒ˜í”Œ ìˆ˜
    min_samples_leaf=1,       # ë¦¬í”„ ìµœì†Œ ìƒ˜í”Œ ìˆ˜
    subsample=1.0,            # ìƒ˜í”Œë§ ë¹„ìœ¨
    random_state=42
)
```

---

### Appendix C: ì¶”ê°€ í†µê³„ ë¶„ì„ ê²°ê³¼

#### C.1 ê¸°ìˆ  í†µê³„ëŸ‰ (ì „ì²´ ì‹œê°„ í”„ë ˆì„)

**30ì¼ ìˆ˜ìµë¥  (Returns30) ë¶„í¬**:
- í‰ê· : 1.2%
- í‘œì¤€í¸ì°¨: 5.1%
- ì™œë„ (Skewness): -1.76 (ì¢Œí¸í–¥)
- ì²¨ë„ (Kurtosis): 9.07 (ë¾°ì¡±í•œ ë¶„í¬)
- ìµœì†Ÿê°’: -24.3% (2020ë…„ 3ì›”, COVID-19)
- ìµœëŒ“ê°’: +18.7% (2020ë…„ 4ì›”, ë°˜ë“±)

**ìƒìŠ¹ ë¹„ìœ¨**:
- 1ì¼: 53.2% (ê±°ì˜ ë°˜ë°˜)
- 7ì¼: 58.1% (ì•½ê°„ ìƒìŠ¹ ìš°ì„¸)
- 15ì¼: 62.4%
- **30ì¼: 68.5%** (ìƒìŠ¹ ìš°ì„¸)
- 60ì¼: 72.8% (ê°•í•œ ìƒìŠ¹ ìš°ì„¸)

**í•´ì„**: ê¸°ê°„ì´ ê¸¸ìˆ˜ë¡ ìƒìŠ¹ í™•ë¥  ì¦ê°€ â†’ ì¥ê¸°ì ìœ¼ë¡œ ì‹œì¥ì€ ìƒìŠ¹

#### C.2 ìê¸°ìƒê´€ (Autocorrelation)

**Returns30ì˜ ìê¸°ìƒê´€**:
- Ïâ‚ (Lag 1): 0.953 (ë§¤ìš° ë†’ìŒ)
- Ïâ‚‚ (Lag 2): 0.916
- Ïâ‚ƒ (Lag 3): 0.869

**í•´ì„**: ë†’ì€ ìê¸°ìƒê´€ â†’ ìˆ˜ìµë¥ ì˜ ì§€ì†ì„± â†’ íŠ¸ë Œë“œ ì¶”ì¢… ê°€ëŠ¥

#### C.3 ì •ìƒì„± ê²€ì • (Stationarity Test)

**Augmented Dickey-Fuller (ADF) Test**:

| ë³€ìˆ˜ | ADF í†µê³„ëŸ‰ | p-value | ê²°ë¡  |
|------|------------|---------|------|
| VIX | -5.33 | < 0.01 | âœ… ì •ìƒ |
| VIX3M | -3.73 | < 0.01 | âœ… ì •ìƒ |
| SKEW | -4.25 | < 0.01 | âœ… ì •ìƒ |
| GVZ | -4.12 | < 0.01 | âœ… ì •ìƒ |
| RVOL | -6.67 | < 0.01 | âœ… ì •ìƒ |
| Returns30 | -10.80 | < 0.01 | âœ… ì •ìƒ |

**ê²°ë¡ **: ëª¨ë“  ë³€ìˆ˜ê°€ ì •ìƒ ì‹œê³„ì—´ â†’ íšŒê·€ ë¶„ì„ ê°€ëŠ¥

---

### Appendix D: ì½”ë“œ ì €ì¥ì†Œ ë° ì¬í˜„ ê°€ì´ë“œ

#### D.1 ì½”ë“œ êµ¬ì¡°

```
Campisi_2024_Replication/
â”œâ”€â”€ campisi_2024_replication.py      # ë©”ì¸ ì½”ë“œ
â”œâ”€â”€ requirements.txt                  # í•„ìš” ë¼ì´ë¸ŒëŸ¬ë¦¬
â”œâ”€â”€ data/                            # ë°ì´í„° ì €ì¥
â”‚   â””â”€â”€ volatility_indices.csv
â”œâ”€â”€ models/                          # í•™ìŠµëœ ëª¨ë¸
â”‚   â”œâ”€â”€ logistic_30d.pkl
â”‚   â”œâ”€â”€ lasso_15d.pkl
â”‚   â””â”€â”€ scaler.pkl
â”œâ”€â”€ figures/                         # ì‹œê°í™” ê²°ê³¼
â”‚   â”œâ”€â”€ correlation_heatmap.png
â”‚   â”œâ”€â”€ feature_importance.png
â”‚   â”œâ”€â”€ roc_curves.png
â”‚   â””â”€â”€ returns_timeseries.png
â”œâ”€â”€ logs/                            # ë¡œê·¸ íŒŒì¼
â”‚   â””â”€â”€ experiment_log.txt
â””â”€â”€ results/                         # ê²°ê³¼ ë¦¬í¬íŠ¸
    â”œâ”€â”€ campisi_2024_results_1d.md
    â”œâ”€â”€ campisi_2024_results_7d.md
    â”œâ”€â”€ campisi_2024_results_15d.md
    â”œâ”€â”€ campisi_2024_results_30d.md
    â””â”€â”€ campisi_2024_results_60d.md
```

#### D.2 ì‹¤í–‰ ë°©ë²•

**1ë‹¨ê³„: í™˜ê²½ ì„¤ì •**
```bash
# ê°€ìƒ í™˜ê²½ ìƒì„±
python -m venv .venv
source .venv/bin/activate  # Windows: .venv\Scripts\activate

# ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜
pip install -r requirements.txt
```

**2ë‹¨ê³„: ì‹¤í—˜ ì‹¤í–‰**
```bash
# 30ì¼ ì˜ˆì¸¡ ì‹¤í–‰
python campisi_2024_replication.py --days 30

# ëª¨ë“  ì‹œê°„ í”„ë ˆì„ ì‹¤í–‰
bash run_experiments.sh
```

**3ë‹¨ê³„: ê²°ê³¼ í™•ì¸**
```bash
# ê²°ê³¼ ë¦¬í¬íŠ¸ í™•ì¸
cat results/campisi_2024_results_30d.md

# ì‹œê°í™” í™•ì¸
open figures/
```

#### D.3 ì¬í˜„ì„± ë³´ì¥

**Random Seed ê³ ì •**:
```python
RANDOM_STATE = 42

# NumPy
np.random.seed(RANDOM_STATE)

# scikit-learn ëª¨ë¸
model = LogisticRegression(random_state=RANDOM_STATE)

# Python random
import random
random.seed(RANDOM_STATE)
```

**ë²„ì „ ê³ ì •** (requirements.txt):
```
python==3.9.7
numpy==1.21.2
pandas==1.3.3
scikit-learn==1.0.0
yfinance==0.1.63
matplotlib==3.4.3
seaborn==0.11.2
statsmodels==0.13.0
tqdm==4.62.3
tabulate==0.8.9
```

#### D.4 ì—°ë½ì²˜ ë° ê¸°ì—¬

**ì§ˆë¬¸ ë° í”¼ë“œë°±**:
- ì´ìŠˆ íŠ¸ë˜ì»¤: [GitHub Issues]
- ì´ë©”ì¼: [your-email@example.com]

**ê¸°ì—¬ ë°©ë²•**:
1. Fork the repository
2. Create a new branch
3. Make your changes
4. Submit a Pull Request

**ë¼ì´ì„ ìŠ¤**: MIT License

---

## ë¦¬í¬íŠ¸ ë

ë³¸ ë¦¬í¬íŠ¸ëŠ” ì´ 3ê°œì˜ íŒŒì¼ë¡œ êµ¬ì„±ë˜ì–´ ìˆìŠµë‹ˆë‹¤:

1. **[Campisi_2024_Final_Report.md](./Campisi_2024_Final_Report.md)**
   - Executive Summary
   - Part I: ë…¼ë¬¸ ì¬í˜„ ë¶„ì„
   - Part II: ë‹¤ì¤‘ ì‹œê°„ í”„ë ˆì„ í™•ì¥

2. **[Campisi_2024_Final_Report_Part3_4.md](./Campisi_2024_Final_Report_Part3_4.md)**
   - Part III: ì‹¬ì¸µ ë¶„ì„
   - Part IV: ì‹¤ë¬´ì  ì‹œì‚¬ì  ë° í•œê³„ì 

3. **[Campisi_2024_Final_Report_Conclusion.md](./Campisi_2024_Final_Report_Conclusion.md)** (í˜„ì¬ íŒŒì¼)
   - Conclusion
   - Appendices

---

**Â© 2024 Campisi et al. (2024) Replication Study**

**ìƒì„±ì¼**: 2024ë…„ 12ì›” 15ì¼

**ë§ˆì§€ë§‰ ì—…ë°ì´íŠ¸**: 2024ë…„ 12ì›” 15ì¼
