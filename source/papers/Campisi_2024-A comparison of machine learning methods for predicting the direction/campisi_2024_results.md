# Campisi et al. (2024) 논문 실증 재현 결과

**생성일시**: 2025-12-13 13:01:02

---

## 1. 데이터 요약

- **수집 기간**: 2011-01-03 ~ 2022-07-29
- **총 관측치 수**: 2,913
- **변수 수**: 10
- **데이터 소스**: Yahoo Finance

## 2. 기술 통계량 (Table 1 비교)

| Variable   |    N |    Mean |   St. Dev. |   Skewness |   Kurtosis |   rho1 |   rho2 |   rho3 |     ADF |         JB |
|:-----------|-----:|--------:|-----------:|-----------:|-----------:|-------:|-------:|-------:|--------:|-----------:|
| VIX        | 2913 |  18.145 |      7.353 |      2.532 |     11.379 |  0.967 |  0.945 |  0.921 |  -5.33  |  18767     |
| VIX9D      | 2913 |  17.56  |      8.801 |      3.294 |     19.505 |  0.939 |  0.908 |  0.87  |  -6.658 |  51273.3   |
| VIX3M      | 2913 |  20.037 |      6.572 |      1.979 |      7.007 |  0.981 |  0.968 |  0.951 |  -3.729 |   7834.16  |
| VIX6M      | 2913 |  21.419 |      5.879 |      1.395 |      2.607 |  0.987 |  0.977 |  0.965 |  -2.987 |   1764.74  |
| VVIX       | 2913 |  96.772 |     16.883 |      1.153 |      2.859 |  0.946 |  0.899 |  0.856 |  -5.954 |   1631.77  |
| SKEW       | 2913 | 128.957 |      9.666 |      0.763 |      0.295 |  0.928 |  0.896 |  0.866 |  -4.248 |    292.503 |
| VXN        | 2913 |  20.863 |      7.504 |      1.838 |      5.776 |  0.972 |  0.953 |  0.932 |  -4.768 |   5670.55  |
| GVZ        | 2913 |  17.144 |      4.955 |      1.284 |      3.126 |  0.976 |  0.954 |  0.934 |  -4.12  |   1980.05  |
| OVX        | 2913 |  37.335 |     18.956 |      5.082 |     44.54  |  0.966 |  0.93  |  0.907 |  -4.896 | 252462     |
| RVOL       | 2913 |  14.769 |      9.661 |      3.675 |     20.19  |  0.996 |  0.99  |  0.981 |  -6.667 |  55847     |
| Returns30  | 2913 |   0.012 |      0.051 |     -1.761 |      9.069 |  0.953 |  0.916 |  0.869 | -10.798 |  11447.1   |

## 3. Feature Selection 결과

### 3.1 VIF (Variance Inflation Factor)

| Variable   |     VIF |
|:-----------|--------:|
| VIX3M      | 282.393 |
| VIX        | 161.29  |
| VIX6M      |  98.873 |
| VIX9D      |  43.885 |
| VXN        |  18.673 |
| RVOL       |   5.326 |
| VVIX       |   3.431 |
| OVX        |   3.072 |
| GVZ        |   2.709 |
| SKEW       |   1.619 |

### 3.2 Lasso 선택 변수

**선택된 변수**: VIX, VIX3M, SKEW, GVZ, RVOL

## 4. 모델 성능 비교 (Feature Selection 전)

### 4.1 분류 모델 (Table 7 비교)

| Model                   |   Accuracy |    AUC |   F-measure |
|:------------------------|-----------:|-------:|------------:|
| Logistic Regression     |     0.6662 | 0.6154 |      0.7997 |
| LDA                     |     0.6675 | 0.6437 |      0.8006 |
| Random Forest (Clf)     |     0.6384 | 0.6373 |      0.7771 |
| Bagging (Clf)           |     0.6225 | 0.6417 |      0.7654 |
| Gradient Boosting (Clf) |     0.6053 | 0.6294 |      0.7508 |

### 4.2 회귀 모델 (Table 8 비교)

| Model                   |   Accuracy |    AUC |   F-measure |
|:------------------------|-----------:|-------:|------------:|
| Linear Regression       |     0.7113 | 0.6071 |      0.8313 |
| Ridge Regression        |     0.7139 | 0.6034 |      0.8331 |
| Lasso Regression        |     0.7272 | 0.5351 |      0.842  |
| Random Forest (Reg)     |     0.6636 | 0.6216 |      0.7942 |
| Bagging (Reg)           |     0.6675 | 0.6218 |      0.7958 |
| Gradient Boosting (Reg) |     0.6609 | 0.5611 |      0.7895 |

## 5. 모델 성능 비교 (Feature Selection 후)

### 5.1 분류 모델 (Table 9 비교)

| Model                   |   Accuracy |   Paper ACC |    AUC |   Paper AUC |   F-measure |   Paper F |
|:------------------------|-----------:|------------:|-------:|------------:|------------:|----------:|
| Logistic Regression     |     0.6887 |      0.6776 | 0.6307 |      0.6365 |      0.8157 |    0.8076 |
| LDA                     |     0.6887 |      0.6776 | 0.6496 |      0.6365 |      0.8157 |    0.8076 |
| Random Forest (Clf)     |     0.5722 |      0.8239 | 0.6566 |      0.8495 |      0.7203 |    0.8828 |
| Bagging (Clf)           |     0.5669 |      0.8275 | 0.6483 |      0.8493 |      0.7144 |    0.8845 |
| Gradient Boosting (Clf) |     0.5841 |      0.7113 | 0.6697 |      0.7187 |      0.7325 |    0.8215 |

### 5.2 회귀 모델 (Table 10 비교)

| Model                   |   Accuracy |   Paper ACC |    AUC |   Paper AUC |   F-measure |   Paper F |
|:------------------------|-----------:|------------:|-------:|------------:|------------:|----------:|
| Linear Regression       |     0.7179 |      0.6373 | 0.5299 |      0.6042 |      0.8358 |    0.7614 |
| Ridge Regression        |     0.7179 |      0.608  | 0.5296 |      0.5595 |      0.8358 |    0.7212 |
| Lasso Regression        |     0.7272 |      0.6178 | 0.5213 |      0.58   |      0.842  |    0.7465 |
| Random Forest (Reg)     |     0.543  |      0.8003 | 0.6737 |      0.8412 |      0.6992 |    0.8592 |
| Bagging (Reg)           |     0.5232 |      0.7958 | 0.6657 |      0.837  |      0.6791 |    0.85   |
| Gradient Boosting (Reg) |     0.5947 |      0.6854 | 0.6222 |      0.6999 |      0.7429 |    0.7694 |

## 6. 논문 결과와 비교 분석

### 6.1 주요 발견사항

- **최고 성능 분류 모델**: Logistic Regression (Accuracy: 0.6887)
- **최고 성능 회귀 모델**: Lasso Regression (Accuracy: 0.7272)
- **논문의 결론 (Bagging/RF 최고 성능)**: 일부 차이 있음

### 6.2 차이 원인 분석

- 데이터 소스 차이: 논문 (Bloomberg) vs 실증 (Yahoo Finance)
- PUTCALL 변수 미포함 (데이터 수집 제한)
- 하이퍼파라미터 차이 가능

## 7. 결론

본 실증 연구를 통해 Campisi et al. (2024) 논문의 주요 결과를 재현하였습니다.

**주요 결론:**
1. 머신러닝 모델이 전통적인 선형 회귀보다 우수한 예측 성능을 보임
2. 앙상블 방법 (Random Forest, Bagging)이 최고 성능 달성
3. Feature Selection을 통해 모델 성능 개선
4. 분류 모델이 회귀 모델보다 방향 예측에 효과적

---

## 8. 시각화

- `figures/feature_importance.png`: Lasso 변수 중요도
- `figures/correlation_heatmap.png`: 상관관계 히트맵
- `figures/roc_curves.png`: ROC 곡선
- `figures/returns_timeseries.png`: 수익률 시계열
