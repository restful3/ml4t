# 머신러닝 기반 S&P 500 방향성 예측 성능 분석 (FIXED VERSION)

**생성일시**: 2025-12-20 16:05:17

**예측 기간**: 15일 후 방향성

**사용 방법론**: Volatility Indices 기반 머신러닝 모델 (Campisi et al., 2024)

**주요 개선사항**:
- ✅ Data Leakage 문제 해결 (Pipeline 사용)
- ✅ Diebold-Mariano 통계 검정 추가
- ✅ Performance 최적화 (Refit Frequency)

---

## 1. 데이터 요약

- **수집 기간**: 2011-01-03 ~ 2022-07-29
- **총 관측치 수**: 2,913
- **변수 수**: 10
- **Walk-Forward CV 이터레이션**: 755개
- **Refit Frequency**: 매 1일
- **데이터 소스**: Yahoo Finance

## 2. 기술 통계량

| Variable   |    N |    Mean |   St. Dev. |   Skewness |   Kurtosis |   rho1 |   rho2 |   rho3 |    ADF |         JB |
|:-----------|-----:|--------:|-----------:|-----------:|-----------:|-------:|-------:|-------:|-------:|-----------:|
| VIX        | 2913 |  18.145 |      7.353 |      2.532 |     11.379 |  0.967 |  0.945 |  0.921 | -5.33  |  18767     |
| VIX9D      | 2913 |  17.56  |      8.801 |      3.294 |     19.505 |  0.939 |  0.908 |  0.87  | -6.658 |  51273.3   |
| VIX3M      | 2913 |  20.037 |      6.572 |      1.979 |      7.007 |  0.981 |  0.968 |  0.951 | -3.729 |   7834.16  |
| VIX6M      | 2913 |  21.419 |      5.879 |      1.395 |      2.607 |  0.987 |  0.977 |  0.965 | -2.987 |   1764.74  |
| VVIX       | 2913 |  96.772 |     16.883 |      1.153 |      2.859 |  0.946 |  0.899 |  0.856 | -5.954 |   1631.77  |
| SKEW       | 2913 | 128.957 |      9.666 |      0.763 |      0.295 |  0.928 |  0.896 |  0.866 | -4.248 |    292.503 |
| VXN        | 2913 |  20.863 |      7.504 |      1.838 |      5.776 |  0.972 |  0.953 |  0.932 | -4.768 |   5670.55  |
| GVZ        | 2913 |  17.144 |      4.955 |      1.284 |      3.126 |  0.976 |  0.954 |  0.934 | -4.12  |   1980.05  |
| OVX        | 2913 |  37.335 |     18.956 |      5.082 |     44.54  |  0.966 |  0.93  |  0.907 | -4.896 | 252462     |
| RVOL       | 2913 |  14.769 |      9.661 |      3.675 |     20.19  |  0.996 |  0.99  |  0.981 | -6.667 |  55847     |
| Returns15  | 2913 |   0.006 |      0.038 |     -1.712 |     10.747 |  0.907 |  0.848 |  0.766 | -9.872 |  15387.7   |

## 3. VIF (Variance Inflation Factor)

| Variable   |      VIF |
|:-----------|---------:|
| VIX3M      | 2619.89  |
| VIX6M      | 1277.7   |
| VIX        | 1143.52  |
| VIX9D      |  211.145 |
| VXN        |  158.932 |
| VVIX       |  116.066 |
| SKEW       |   82.123 |
| GVZ        |   30.637 |
| RVOL       |   16.598 |
| OVX        |   14.972 |

## 4. 모델 성능 비교 (Feature Selection 전)

### 4.1 분류 모델

| Model                   |   Accuracy |    AUC |   F-measure |
|:------------------------|-----------:|-------:|------------:|
| Logistic Regression     |     0.649  | 0.5755 |      0.7868 |
| LDA                     |     0.649  | 0.5881 |      0.7865 |
| Random Forest (Clf)     |     0.5841 | 0.6388 |      0.7307 |
| Bagging (Clf)           |     0.5523 | 0.6135 |      0.7025 |
| Gradient Boosting (Clf) |     0.6026 | 0.6199 |      0.747  |

### 4.2 회귀 모델

| Model                   |   Accuracy |    AUC |   F-measure |
|:------------------------|-----------:|-------:|------------:|
| Linear Regression       |     0.6834 | 0.5844 |      0.8111 |
| Ridge Regression        |     0.6821 | 0.5824 |      0.8104 |
| Lasso Regression        |     0.698  | 0.5353 |      0.8222 |
| Random Forest (Reg)     |     0.5748 | 0.5574 |      0.7111 |
| Bagging (Reg)           |     0.5921 | 0.5298 |      0.7255 |
| Gradient Boosting (Reg) |     0.6132 | 0.5285 |      0.7443 |

## 5. 모델 성능 비교 (Feature Selection 후)

### 5.1 분류 모델

| Model                   |   Accuracy |    AUC |   F-measure |
|:------------------------|-----------:|-------:|------------:|
| Logistic Regression     |     0.6503 | 0.567  |      0.7874 |
| LDA                     |     0.649  | 0.5701 |      0.7865 |
| Random Forest (Clf)     |     0.5947 | 0.6186 |      0.7407 |
| Bagging (Clf)           |     0.5934 | 0.603  |      0.7365 |
| Gradient Boosting (Clf) |     0.6344 | 0.6156 |      0.7708 |

### 5.2 회귀 모델

| Model                   |   Accuracy |    AUC |   F-measure |
|:------------------------|-----------:|-------:|------------:|
| Linear Regression       |     0.698  | 0.5506 |      0.8219 |
| Ridge Regression        |     0.698  | 0.5506 |      0.8219 |
| Lasso Regression        |     0.698  | 0.5353 |      0.8222 |
| Random Forest (Reg)     |     0.5868 | 0.5121 |      0.7084 |
| Bagging (Reg)           |     0.5775 | 0.51   |      0.6942 |
| Gradient Boosting (Reg) |     0.6278 | 0.513  |      0.752  |

## 6. Diebold-Mariano 통계 검정

### 6.1 분류 모델 쌍별 비교

**통계적으로 유의한 차이 (p < 0.05):**

| Model 1             | Model 2                 |   DM Statistic |   p-value | Significant (5%)   |
|:--------------------|:------------------------|---------------:|----------:|:-------------------|
| Logistic Regression | Random Forest (Clf)     |        -4.9581 |    0      | True               |
| Logistic Regression | Bagging (Clf)           |        -4.6733 |    0      | True               |
| LDA                 | Random Forest (Clf)     |        -4.803  |    0      | True               |
| LDA                 | Bagging (Clf)           |        -4.5349 |    0      | True               |
| Random Forest (Clf) | Gradient Boosting (Clf) |         3.7829 |    0.0002 | True               |
| Bagging (Clf)       | Gradient Boosting (Clf) |         3.71   |    0.0002 | True               |

### 6.2 회귀 모델 쌍별 비교

**통계적으로 유의한 차이 (p < 0.05):**

| Model 1             | Model 2                 |   DM Statistic |   p-value | Significant (5%)   |
|:--------------------|:------------------------|---------------:|----------:|:-------------------|
| Linear Regression   | Random Forest (Reg)     |        -5.6769 |    0      | True               |
| Linear Regression   | Bagging (Reg)           |        -5.8454 |    0      | True               |
| Linear Regression   | Gradient Boosting (Reg) |        -4.1706 |    0      | True               |
| Ridge Regression    | Random Forest (Reg)     |        -5.6769 |    0      | True               |
| Ridge Regression    | Bagging (Reg)           |        -5.8454 |    0      | True               |
| Ridge Regression    | Gradient Boosting (Reg) |        -4.1706 |    0      | True               |
| Lasso Regression    | Random Forest (Reg)     |        -5.6769 |    0      | True               |
| Lasso Regression    | Bagging (Reg)           |        -5.8214 |    0      | True               |
| Lasso Regression    | Gradient Boosting (Reg) |        -4.1967 |    0      | True               |
| Random Forest (Reg) | Gradient Boosting (Reg) |         2.905  |    0.0037 | True               |
| Bagging (Reg)       | Gradient Boosting (Reg) |         3.3554 |    0.0008 | True               |

## 7. 모델 성능 요약

### 7.1 Feature Selection 전후 비교

**분류 모델:**
- Feature Selection 전: Logistic Regression (Accuracy: 0.6490)
- Feature Selection 후: Logistic Regression (Accuracy: 0.6503)

**회귀 모델:**
- Feature Selection 전: Lasso Regression (Accuracy: 0.6980)
- Feature Selection 후: Linear Regression (Accuracy: 0.6980)

### 7.2 전체 최고 성능 모델

**최고 성능**: Linear Regression
- Accuracy: 0.6980
- AUC: 0.5506
- F-measure: 0.8219

## 8. 주요 인사이트

**1. Feature Selection 효과**
- 전체 평균 Accuracy: 0.6255 → 0.6371
- Feature Selection을 통해 성능 향상 (+0.0116)

**2. 분류 vs 회귀 모델**
- 분류 모델 평균 Accuracy: 0.6244
- 회귀 모델 평균 Accuracy: 0.6477
- 회귀 모델이 방향 예측에 더 효과적

**3. Data Leakage 문제 해결**
- ✅ Standardization을 CV loop 내부로 이동 (Pipeline 사용)
- ✅ Feature Selection을 CV loop 내부로 이동 (SelectFromModel)
- ✅ 이로 인해 원본 코드 대비 성능이 낮아질 수 있으나, 이것이 정확한 out-of-sample 성능임

---

## 9. 시각화

- `figures/correlation_heatmap.png`: 상관관계 히트맵
- `figures/roc_curves.png`: ROC 곡선
- `figures/returns_timeseries.png`: 수익률 시계열
