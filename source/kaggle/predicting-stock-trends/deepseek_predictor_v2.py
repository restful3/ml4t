#!/usr/bin/env python3
"""
====================================================================
Kaggle ì£¼ì‹ íŠ¸ë Œë“œ ì˜ˆì¸¡ - DeepSeek-R1 ê¸°ë°˜ ëª¨ë¸
====================================================================

ëª©ì  (Purpose):
    DeepSeek-R1 ëŒ€í˜• ì–¸ì–´ ëª¨ë¸ì˜ Chain-of-Thought ì¶”ë¡  ëŠ¥ë ¥ì„ í™œìš©í•˜ì—¬
    ì£¼ì‹ ê°€ê²©ì´ 30 ê±°ë˜ì¼ í›„ ìƒìŠ¹(1) ë˜ëŠ” í•˜ë½(0)í• ì§€ ì˜ˆì¸¡

ëŒ€íšŒ ì •ë³´ (Competition):
    - ì´ë¦„: Predicting Stock Trends: Rise or Fall?
    - ë°ì´í„°: 5,000ê°œ ì¢…ëª©ì˜ OHLCV + ë°°ë‹¹/ë¶„í•  ë°ì´í„°
    - ëª©í‘œ: 30 ê±°ë˜ì¼ í›„ ì¢…ê°€ ìƒìŠ¹/í•˜ë½ ì˜ˆì¸¡
    - í‰ê°€ ì§€í‘œ: Accuracy (ì •í™•ë„)

ëª¨ë¸ êµ¬ì¡° (Model Architecture):
    - ì•Œê³ ë¦¬ì¦˜: DeepSeek-R1:14B (Ollamaë¥¼ í†µí•œ ë¡œì»¬ ì¶”ë¡ )
    - ì ‘ê·¼ë²•: í•˜ì´ë¸Œë¦¬ë“œ (Traditional Feature Engineering + LLM Reasoning)
    - íŠ¹ì§•: 16ê°œ ê¸°ìˆ ì  ì§€í‘œ â†’ ìì—°ì–´ ìš”ì•½ â†’ LLM ì¶”ë¡ 
    - ì¶œë ¥: êµ¬ì¡°í™”ëœ ì˜ˆì¸¡ (ìƒìŠ¹/í•˜ë½ + ì‹ ë¢°ë„ + ì¶”ë¡  ê³¼ì •)

í•µì‹¬ ì¥ì  (Key Advantages):
    1. Chain-of-Thought ì¶”ë¡ ìœ¼ë¡œ ë³µì¡í•œ íŒ¨í„´ ì¸ì‹
    2. ì„¤ëª… ê°€ëŠ¥í•œ ì˜ˆì¸¡ (reasoning ì œê³µ)
    3. Few-shot learningìœ¼ë¡œ ì‚¬ë¡€ ê¸°ë°˜ í•™ìŠµ

ì‘ì„±ì: ML4T Project
ë‚ ì§œ: 2025
====================================================================
"""

import pandas as pd
import numpy as np
import json
import re
import warnings
from tqdm import tqdm
import os
from typing import Dict, Tuple, List
from datetime import datetime
import asyncio
from concurrent.futures import ThreadPoolExecutor

# OpenAI í´ë¼ì´ì–¸íŠ¸ (vLLMê³¼ í˜¸í™˜)
try:
    from openai import OpenAI, AsyncOpenAI
except ImportError:
    print("âš ï¸  Error: openai íŒ¨í‚¤ì§€ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")
    print("   ì‹¤í–‰: pip install openai")
    exit(1)

# baseline.pyì˜ í•¨ìˆ˜ë“¤ì„ ì¬ì‚¬ìš©í•˜ê¸° ìœ„í•œ import
import sys
sys.path.insert(0, os.path.dirname(__file__))

# ê²½ê³  ë©”ì‹œì§€ ìˆ¨ê¸°ê¸°
warnings.filterwarnings('ignore')

# ====================================================================
# ì„¤ì • ìƒìˆ˜ (Configuration Constants)
# ====================================================================
DATA_DIR = 'data'
OUTPUT_DIR = 'outputs'
RANDOM_STATE = 42

# vLLM ì„œë²„ ì„¤ì •
VLLM_API_BASE = "http://localhost:8000/v1"  # vLLM ì„œë²„ ì£¼ì†Œ
VLLM_API_KEY = "EMPTY"  # vLLMì€ ê¸°ë³¸ì ìœ¼ë¡œ ì¸ì¦ ë¶ˆí•„ìš”

# DeepSeek-R1 ëª¨ë¸ ì„¤ì •
DEEPSEEK_MODEL = './hf_models/DeepSeek-R1-Distill-Qwen-7B'  # vLLMì— ë¡œë“œëœ ëª¨ë¸ ê²½ë¡œ
DEEPSEEK_TEMPERATURE = 0.2  # 0.2ë¡œ ì¦ê°€ (ë” ë‹¤ì–‘í•œ ì‘ë‹µ ìƒì„±)
DEEPSEEK_MAX_TOKENS = 500  # 500ìœ¼ë¡œ ë³µì› (ì¶©ë¶„í•œ ì¶”ë¡  ê¸¸ì´)

# ë°°ì¹˜ ì²˜ë¦¬ ì„¤ì • (ì†ë„ ê°œì„ )
CONCURRENT_REQUESTS = 10  # vLLMì€ ë” ë§ì€ ë™ì‹œ ì²˜ë¦¬ ê°€ëŠ¥ (10ê°œ ë™ì‹œ ì¶”ë¡ )
SAVE_REASONING = True  # ì¶”ë¡  ê³¼ì • ì €ì¥ ì—¬ë¶€

# ====================================================================
# ë°ì´í„° ë¡œë”© í•¨ìˆ˜ (baseline.py ì¬ì‚¬ìš©)
# ====================================================================

def load_data():
    """CSV íŒŒì¼ì—ì„œ í•™ìŠµ ë° í…ŒìŠ¤íŠ¸ ë°ì´í„°ì…‹ì„ ë¡œë“œí•©ë‹ˆë‹¤."""
    print("ğŸ“‚ ë°ì´í„° ë¡œë”© ì¤‘...")

    train_df = pd.read_csv(os.path.join(DATA_DIR, 'train.csv'))
    test_df = pd.read_csv(os.path.join(DATA_DIR, 'test.csv'))
    sample_submission = pd.read_csv(os.path.join(DATA_DIR, 'sample_submission.csv'))

    print(f"   Train: {train_df.shape}")
    print(f"   Test: {test_df.shape}")

    return train_df, test_df, sample_submission


def create_features(df):
    """OHLCV ë°ì´í„°ë¡œë¶€í„° ê¸°ìˆ ì  íŠ¹ì§•ì„ ìƒì„±í•©ë‹ˆë‹¤ (baseline.pyì™€ ë™ì¼)."""
    features = pd.DataFrame()

    # ë©”íƒ€ë°ì´í„°
    features['ticker'] = df['Ticker']
    features['date'] = pd.to_datetime(df['Date'])

    # ê°€ê²© ê¸°ë°˜ íŠ¹ì§•
    features['returns'] = (df['Close'] - df['Open']) / df['Open']
    features['high_low_ratio'] = df['High'] / df['Low']
    features['close_open_ratio'] = df['Close'] / df['Open']

    # ê±°ë˜ëŸ‰ íŠ¹ì§•
    features['volume'] = df['Volume']
    features['volume_log'] = np.log1p(df['Volume'])

    # ë³€ë™ì„± íŠ¹ì§•
    features['daily_range'] = (df['High'] - df['Low']) / df['Open']

    # ê¸°ì—… í™œë™ íŠ¹ì§•
    features['has_dividend'] = (df['Dividends'] > 0).astype(int)
    features['has_split'] = (df['Stock Splits'] > 0).astype(int)

    return features


# ====================================================================
# íŠ¹ì§• â†’ í…ìŠ¤íŠ¸ ë³€í™˜ê¸° (Feature to Text Converter)
# ====================================================================

class FeatureToTextConverter:
    """
    ìˆ˜ì¹˜í˜• íŠ¹ì§• ë²¡í„°ë¥¼ ìì—°ì–´ ì„¤ëª…ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” í´ë˜ìŠ¤.

    DeepSeek-R1ì´ ì´í•´í•˜ê¸° ì‰¬ìš´ í˜•íƒœë¡œ ê¸°ìˆ ì  ì§€í‘œë¥¼ ì„œìˆ í•©ë‹ˆë‹¤.
    """

    @staticmethod
    def convert(features: Dict[str, float], ticker: str) -> str:
        """
        íŠ¹ì§• ë”•ì…”ë„ˆë¦¬ë¥¼ ìì—°ì–´ ì„¤ëª…ìœ¼ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.

        Args:
            features: 16ê°œ ê¸°ìˆ ì  ì§€í‘œë¥¼ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
            ticker: ì¢…ëª© ì½”ë“œ (ì˜ˆ: ticker_1)

        Returns:
            ìì—°ì–´ë¡œ ì‘ì„±ëœ ì¢…ëª© ë¶„ì„ ìš”ì•½
        """
        # ì•ˆì „í•œ ê°’ ì¶”ì¶œ (NaN ì²˜ë¦¬)
        def safe_get(key, default=0):
            val = features.get(key, default)
            return default if pd.isna(val) else val

        # ì£¼ìš” ì§€í‘œ ì¶”ì¶œ
        returns = safe_get('returns', 0) * 100
        close_open = (safe_get('close_open_ratio', 1) - 1) * 100
        daily_range = safe_get('daily_range', 0) * 100
        volume_log = safe_get('volume_log', 0)

        ma_5 = safe_get('ma_5', 0)
        ma_20 = safe_get('ma_20', 0)
        close = safe_get('close', 0)

        price_to_ma5 = safe_get('price_to_ma5', 1)
        price_to_ma20 = safe_get('price_to_ma20', 1)

        volume_ma_5 = safe_get('volume_ma_5', 0)
        volume = safe_get('volume', 0)

        # ì¶”ì„¸ íŒë‹¨
        trend_short = "ìƒìŠ¹" if price_to_ma5 > 1.02 else "í•˜ë½" if price_to_ma5 < 0.98 else "íš¡ë³´"
        trend_long = "ìƒìŠ¹" if price_to_ma20 > 1.02 else "í•˜ë½" if price_to_ma20 < 0.98 else "íš¡ë³´"

        # ê±°ë˜ëŸ‰ íŒë‹¨
        volume_status = "í‰ê·  ì´ìƒ" if volume > volume_ma_5 * 1.2 else "í‰ê·  ì´í•˜" if volume < volume_ma_5 * 0.8 else "í‰ê·  ìˆ˜ì¤€"

        # ë³€ë™ì„± íŒë‹¨
        volatility = "ë†’ìŒ" if daily_range > 5 else "ë‚®ìŒ" if daily_range < 2 else "ë³´í†µ"

        # ìì—°ì–´ ìš”ì•½ ìƒì„±
        summary = f"""ì¢…ëª©: {ticker}

ã€ê°€ê²© ë™í–¥ã€‘
- ì¼ì¤‘ ìˆ˜ìµë¥ : {returns:.2f}%
- ì¢…ê°€ ë³€í™”: ì‹œê°€ ëŒ€ë¹„ {close_open:+.2f}%
- ì¼ì¤‘ ë³€ë™í­: {daily_range:.2f}% ({volatility})

ã€ì´ë™í‰ê·  ë¶„ì„ã€‘
- 5ì¼ ì´ë™í‰ê· : ${ma_5:.2f} (í˜„ì¬ ê°€ê²©: ${close:.2f})
  â†’ ë‹¨ê¸° ì¶”ì„¸: {trend_short} (ê°€ê²©/MA5 = {price_to_ma5:.3f})
- 20ì¼ ì´ë™í‰ê· : ${ma_20:.2f}
  â†’ ì¥ê¸° ì¶”ì„¸: {trend_long} (ê°€ê²©/MA20 = {price_to_ma20:.3f})

ã€ê±°ë˜ëŸ‰ ë¶„ì„ã€‘
- í˜„ì¬ ê±°ë˜ëŸ‰: {volume:,.0f}ì£¼ (ë¡œê·¸ ìŠ¤ì¼€ì¼: {volume_log:.2f})
- 5ì¼ í‰ê·  ê±°ë˜ëŸ‰: {volume_ma_5:,.0f}ì£¼
- ê±°ë˜ í™œë™: {volume_status}

ã€ê¸°ìˆ ì  ì‹ í˜¸ã€‘
- ë‹¨ê¸°/ì¥ê¸° ì¶”ì„¸ ì •ë ¬: {'ì¼ì¹˜' if (price_to_ma5 > 1) == (price_to_ma20 > 1) else 'ë¶ˆì¼ì¹˜'}
- ê³¨ë“ í¬ë¡œìŠ¤/ë°ë“œí¬ë¡œìŠ¤: {'ê³¨ë“ í¬ë¡œìŠ¤' if ma_5 > ma_20 else 'ë°ë“œí¬ë¡œìŠ¤' if ma_5 < ma_20 else 'ì¤‘ë¦½'}
"""

        return summary.strip()


# ====================================================================
# DeepSeek-R1 ì£¼ì‹ ì˜ˆì¸¡ê¸° (Main Predictor Class)
# ====================================================================

class DeepSeekStockPredictor:
    """
    DeepSeek-R1 ëª¨ë¸ì„ ì‚¬ìš©í•œ ì£¼ì‹ íŠ¸ë Œë“œ ì˜ˆì¸¡ê¸°.

    Chain-of-Thought ì¶”ë¡ ì„ í™œìš©í•˜ì—¬ ê¸°ìˆ ì  ì§€í‘œë¥¼ ë¶„ì„í•˜ê³ 
    30ì¼ í›„ ì£¼ê°€ ë³€ë™ì„ ì˜ˆì¸¡í•©ë‹ˆë‹¤.
    """

    def __init__(self, model_name: str = DEEPSEEK_MODEL):
        """
        Args:
            model_name: vLLM ëª¨ë¸ ì´ë¦„ (ê¸°ë³¸: DeepSeek-R1-Distill-Qwen-7B)
        """
        self.model_name = model_name
        self.converter = FeatureToTextConverter()

        # OpenAI ë™ê¸°/ë¹„ë™ê¸° í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” (vLLM ì„œë²„ ì—°ê²°)
        try:
            self.client = OpenAI(
                api_key=VLLM_API_KEY,
                base_url=VLLM_API_BASE
            )
            self.async_client = AsyncOpenAI(
                api_key=VLLM_API_KEY,
                base_url=VLLM_API_BASE
            )

            # vLLM ì„œë²„ ì—°ê²° í™•ì¸
            models = self.client.models.list()
            print(f"âœ… vLLM ì„œë²„ ì—°ê²° ì„±ê³µ")
            print(f"   ì‚¬ìš© ê°€ëŠ¥í•œ ëª¨ë¸: {[m.id for m in models.data]}")
        except Exception as e:
            print(f"âŒ vLLM ì—°ê²° ì‹¤íŒ¨: {e}")
            print(f"   ìƒì„¸ ì˜¤ë¥˜: {type(e).__name__}")
            import traceback
            traceback.print_exc()
            print(f"   vLLM ì„œë²„ê°€ {VLLM_API_BASE}ì—ì„œ ì‹¤í–‰ ì¤‘ì¸ì§€ í™•ì¸í•˜ì„¸ìš”")
            raise

        print(f"âœ… DeepSeek-R1 ì˜ˆì¸¡ê¸° ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë¸: {model_name})")
        print(f"   ë™ì‹œ ì²˜ë¦¬ ìš”ì²­ ìˆ˜: {CONCURRENT_REQUESTS}ê°œ (ì˜ˆìƒ ì†ë„ í–¥ìƒ: {CONCURRENT_REQUESTS}ë°°)")

    def _create_system_prompt(self) -> str:
        """ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (2025 Best Practices ì ìš©)."""
        return """You are a professional quantitative analyst with 20 years of experience.

Based on the given technical indicators, predict whether the stock price will RISE (1) or FALL (0) after 30 trading days (~6 weeks).

ã€CRITICAL RULESã€‘
1. You MUST choose either "ìƒìŠ¹" (RISE) or "í•˜ë½" (FALL) - NO other options allowed
2. "íš¡ë³´", "ì¤‘ë¦½", "æŒå¹³", "íŒë‹¨ë¶ˆê°€" or any neutral predictions are FORBIDDEN
3. If uncertain, follow the recent trend direction
4. Write your reasoning in <think> tags
5. Write your final answer in <answer> tags

ã€DECISION CRITERIAã€‘
âœ… BULLISH (ìƒìŠ¹) signals:
- Golden cross (5-day MA > 20-day MA)
- Price above both moving averages
- Volume increase with price rise
- Positive momentum

âœ… BEARISH (í•˜ë½) signals:
- Death cross (5-day MA < 20-day MA)
- Price below both moving averages
- Volume increase with price fall
- Negative momentum

ã€RESPONSE FORMATã€‘
<think>
- Current trend analysis
- Moving average cross check
- Volume pattern analysis
- Volatility assessment
- Final decision
</think>
<answer>
ì˜ˆì¸¡: [ìƒìŠ¹/í•˜ë½] (MUST be one of these two)
ì‹ ë¢°ë„: [0-100]%
ê·¼ê±°: [Key reasons in 1-2 sentences]
</answer>"""

    def _create_few_shot_examples(self) -> List[Dict[str, str]]:
        """Few-shot í•™ìŠµì„ ìœ„í•œ ì˜ˆì œë¥¼ ìƒì„±í•©ë‹ˆë‹¤ (10ê°œ: 5 ìƒìŠ¹, 5 í•˜ë½)."""
        return [
            # ì˜ˆì‹œ 1: ê°•í•œ ìƒìŠ¹ (ê³¨ë“ í¬ë¡œìŠ¤ + ê±°ë˜ëŸ‰ ì¦ê°€)
            {
                "role": "user",
                "content": """ì¢…ëª©: ticker_ìƒìŠ¹1
ã€ê°€ê²© ë™í–¥ã€‘ì¼ì¤‘ ìˆ˜ìµë¥ : 2.5%, ì¢…ê°€ ë³€í™”: +2.3%, ì¼ì¤‘ ë³€ë™í­: 3.1% (ë³´í†µ)
ã€ì´ë™í‰ê·  ë¶„ì„ã€‘5ì¼MA: $120.50 (í˜„ì¬: $125.00) â†’ ìƒìŠ¹ (1.037), 20ì¼MA: $115.00 â†’ ìƒìŠ¹ (1.087)
ã€ê±°ë˜ëŸ‰ ë¶„ì„ã€‘í˜„ì¬: 1,500,000ì£¼, 5ì¼ í‰ê· : 1,000,000ì£¼ â†’ í‰ê·  ì´ìƒ
ã€ê¸°ìˆ ì  ì‹ í˜¸ã€‘ê³¨ë“ í¬ë¡œìŠ¤, ì¶”ì„¸ ì¼ì¹˜"""
            },
            {
                "role": "assistant",
                "content": """<think>
ê³¨ë“ í¬ë¡œìŠ¤ + ê±°ë˜ëŸ‰ 50% ì¦ê°€ + ì–‘ë´‰ â†’ ê°•í•œ ë§¤ìˆ˜ì„¸
</think>
<answer>
ì˜ˆì¸¡: ìƒìŠ¹
ì‹ ë¢°ë„: 75%
ê·¼ê±°: ê³¨ë“ í¬ë¡œìŠ¤ì™€ ê±°ë˜ëŸ‰ ê¸‰ì¦ìœ¼ë¡œ ìƒìŠ¹ ëª¨ë©˜í…€ ì§€ì† ì˜ˆìƒ
</answer>"""
            },

            # ì˜ˆì‹œ 2: ê°•í•œ í•˜ë½ (ë°ë“œí¬ë¡œìŠ¤ + ê±°ë˜ëŸ‰ ì¦ê°€)
            {
                "role": "user",
                "content": """ì¢…ëª©: ticker_í•˜ë½1
ã€ê°€ê²© ë™í–¥ã€‘ì¼ì¤‘ ìˆ˜ìµë¥ : -1.8%, ì¢…ê°€ ë³€í™”: -2.0%, ì¼ì¤‘ ë³€ë™í­: 4.2% (ë†’ìŒ)
ã€ì´ë™í‰ê·  ë¶„ì„ã€‘5ì¼MA: $95.00 (í˜„ì¬: $92.00) â†’ í•˜ë½ (0.968), 20ì¼MA: $98.00 â†’ í•˜ë½ (0.939)
ã€ê±°ë˜ëŸ‰ ë¶„ì„ã€‘í˜„ì¬: 2,000,000ì£¼, 5ì¼ í‰ê· : 1,200,000ì£¼ â†’ í‰ê·  ì´ìƒ
ã€ê¸°ìˆ ì  ì‹ í˜¸ã€‘ë°ë“œí¬ë¡œìŠ¤, ì¶”ì„¸ ì¼ì¹˜"""
            },
            {
                "role": "assistant",
                "content": """<think>
ë°ë“œí¬ë¡œìŠ¤ + ê±°ë˜ëŸ‰ ì¦ê°€ + ìŒë´‰ â†’ ê°•í•œ ë§¤ë„ì„¸
</think>
<answer>
ì˜ˆì¸¡: í•˜ë½
ì‹ ë¢°ë„: 70%
ê·¼ê±°: ë°ë“œí¬ë¡œìŠ¤ì™€ ê±°ë˜ëŸ‰ ì¦ê°€ë¡œ í•˜ë½ ì¶”ì„¸ ì§€ì† ì˜ˆìƒ
</answer>"""
            },

            # ì˜ˆì‹œ 3: ìƒìŠ¹ (ê°€ê²©ì´ ì´ë™í‰ê·  ìƒíšŒ)
            {
                "role": "user",
                "content": """ì¢…ëª©: ticker_ìƒìŠ¹2
ã€ê°€ê²© ë™í–¥ã€‘ì¼ì¤‘ ìˆ˜ìµë¥ : 1.2%, ì¢…ê°€ ë³€í™”: +1.5%, ì¼ì¤‘ ë³€ë™í­: 2.1% (ë‚®ìŒ)
ã€ì´ë™í‰ê·  ë¶„ì„ã€‘5ì¼MA: $48.50 (í˜„ì¬: $50.00) â†’ ìƒìŠ¹ (1.031), 20ì¼MA: $47.00 â†’ ìƒìŠ¹ (1.064)
ã€ê±°ë˜ëŸ‰ ë¶„ì„ã€‘í˜„ì¬: 800,000ì£¼, 5ì¼ í‰ê· : 750,000ì£¼ â†’ í‰ê·  ìˆ˜ì¤€
ã€ê¸°ìˆ ì  ì‹ í˜¸ã€‘ê°€ê²©ì´ ì–‘ìª½ MA ìƒíšŒ"""
            },
            {
                "role": "assistant",
                "content": """<think>
ê°€ê²©ì´ 5ì¼/20ì¼MA ëª¨ë‘ ìƒíšŒ + ì•ˆì •ì  ìƒìŠ¹
</think>
<answer>
ì˜ˆì¸¡: ìƒìŠ¹
ì‹ ë¢°ë„: 65%
ê·¼ê±°: ì´ë™í‰ê·  ìƒíšŒì™€ ì•ˆì •ì ì¸ ìƒìŠ¹ì„¸ë¡œ ì¶”ì„¸ ì§€ì† ì „ë§
</answer>"""
            },

            # ì˜ˆì‹œ 4: í•˜ë½ (ê°€ê²©ì´ ì´ë™í‰ê·  í•˜íšŒ)
            {
                "role": "user",
                "content": """ì¢…ëª©: ticker_í•˜ë½2
ã€ê°€ê²© ë™í–¥ã€‘ì¼ì¤‘ ìˆ˜ìµë¥ : -0.8%, ì¢…ê°€ ë³€í™”: -1.1%, ì¼ì¤‘ ë³€ë™í­: 2.5% (ë³´í†µ)
ã€ì´ë™í‰ê·  ë¶„ì„ã€‘5ì¼MA: $78.00 (í˜„ì¬: $75.00) â†’ í•˜ë½ (0.962), 20ì¼MA: $80.00 â†’ í•˜ë½ (0.938)
ã€ê±°ë˜ëŸ‰ ë¶„ì„ã€‘í˜„ì¬: 950,000ì£¼, 5ì¼ í‰ê· : 1,000,000ì£¼ â†’ í‰ê·  ì´í•˜
ã€ê¸°ìˆ ì  ì‹ í˜¸ã€‘ê°€ê²©ì´ ì–‘ìª½ MA í•˜íšŒ"""
            },
            {
                "role": "assistant",
                "content": """<think>
ê°€ê²©ì´ 5ì¼/20ì¼MA ëª¨ë‘ í•˜íšŒ + ìŒë´‰
</think>
<answer>
ì˜ˆì¸¡: í•˜ë½
ì‹ ë¢°ë„: 62%
ê·¼ê±°: ì´ë™í‰ê·  í•˜íšŒë¡œ ì•½ì„¸ ì¶”ì„¸ ì§€ì† ì˜ˆìƒ
</answer>"""
            },

            # ì˜ˆì‹œ 5: ìƒìŠ¹ (ê°•í•œ ëª¨ë©˜í…€)
            {
                "role": "user",
                "content": """ì¢…ëª©: ticker_ìƒìŠ¹3
ã€ê°€ê²© ë™í–¥ã€‘ì¼ì¤‘ ìˆ˜ìµë¥ : 3.8%, ì¢…ê°€ ë³€í™”: +3.5%, ì¼ì¤‘ ë³€ë™í­: 5.2% (ë†’ìŒ)
ã€ì´ë™í‰ê·  ë¶„ì„ã€‘5ì¼MA: $32.00 (í˜„ì¬: $35.00) â†’ ìƒìŠ¹ (1.094), 20ì¼MA: $30.00 â†’ ìƒìŠ¹ (1.167)
ã€ê±°ë˜ëŸ‰ ë¶„ì„ã€‘í˜„ì¬: 2,500,000ì£¼, 5ì¼ í‰ê· : 1,500,000ì£¼ â†’ í‰ê·  ì´ìƒ
ã€ê¸°ìˆ ì  ì‹ í˜¸ã€‘ê°•í•œ ìƒìŠ¹ ëª¨ë©˜í…€"""
            },
            {
                "role": "assistant",
                "content": """<think>
+3.8% ê¸‰ë“± + ê±°ë˜ëŸ‰ 67% ì¦ê°€ â†’ ëŒíŒŒ ì‹œë„
</think>
<answer>
ì˜ˆì¸¡: ìƒìŠ¹
ì‹ ë¢°ë„: 80%
ê·¼ê±°: ê°•í•œ ëª¨ë©˜í…€ê³¼ ê±°ë˜ëŸ‰ ê¸‰ì¦ìœ¼ë¡œ ìƒìŠ¹ ì§€ì† ê°€ëŠ¥ì„± ë†’ìŒ
</answer>"""
            },

            # ì˜ˆì‹œ 6: í•˜ë½ (ê¸‰ë½)
            {
                "role": "user",
                "content": """ì¢…ëª©: ticker_í•˜ë½3
ã€ê°€ê²© ë™í–¥ã€‘ì¼ì¤‘ ìˆ˜ìµë¥ : -2.9%, ì¢…ê°€ ë³€í™”: -3.2%, ì¼ì¤‘ ë³€ë™í­: 5.8% (ë†’ìŒ)
ã€ì´ë™í‰ê·  ë¶„ì„ã€‘5ì¼MA: $65.00 (í˜„ì¬: $61.00) â†’ í•˜ë½ (0.938), 20ì¼MA: $68.00 â†’ í•˜ë½ (0.897)
ã€ê±°ë˜ëŸ‰ ë¶„ì„ã€‘í˜„ì¬: 3,200,000ì£¼, 5ì¼ í‰ê· : 1,800,000ì£¼ â†’ í‰ê·  ì´ìƒ
ã€ê¸°ìˆ ì  ì‹ í˜¸ã€‘ê¸‰ë½ + ê³ ê±°ë˜ëŸ‰"""
            },
            {
                "role": "assistant",
                "content": """<think>
-2.9% ê¸‰ë½ + ê±°ë˜ëŸ‰ 78% ì¦ê°€ â†’ íŒ¨ë‹‰ ë§¤ë„
</think>
<answer>
ì˜ˆì¸¡: í•˜ë½
ì‹ ë¢°ë„: 77%
ê·¼ê±°: ê¸‰ë½ê³¼ ê±°ë˜ëŸ‰ í­ì¦ìœ¼ë¡œ ì¶”ê°€ í•˜ë½ ì••ë ¥ ì˜ˆìƒ
</answer>"""
            },

            # ì˜ˆì‹œ 7: ìƒìŠ¹ (ì €ê±°ë˜ëŸ‰ì´ì§€ë§Œ ì¶”ì„¸ ëª…í™•)
            {
                "role": "user",
                "content": """ì¢…ëª©: ticker_ìƒìŠ¹4
ã€ê°€ê²© ë™í–¥ã€‘ì¼ì¤‘ ìˆ˜ìµë¥ : 0.9%, ì¢…ê°€ ë³€í™”: +1.0%, ì¼ì¤‘ ë³€ë™í­: 1.5% (ë‚®ìŒ)
ã€ì´ë™í‰ê·  ë¶„ì„ã€‘5ì¼MA: $102.00 (í˜„ì¬: $104.00) â†’ ìƒìŠ¹ (1.020), 20ì¼MA: $100.00 â†’ ìƒìŠ¹ (1.040)
ã€ê±°ë˜ëŸ‰ ë¶„ì„ã€‘í˜„ì¬: 400,000ì£¼, 5ì¼ í‰ê· : 500,000ì£¼ â†’ í‰ê·  ì´í•˜
ã€ê¸°ìˆ ì  ì‹ í˜¸ã€‘ì•ˆì •ì  ìƒìŠ¹ì„¸"""
            },
            {
                "role": "assistant",
                "content": """<think>
ê±°ë˜ëŸ‰ ì ì§€ë§Œ ê¾¸ì¤€í•œ ìƒìŠ¹ + MA ìƒíšŒ â†’ ì•ˆì •ì 
</think>
<answer>
ì˜ˆì¸¡: ìƒìŠ¹
ì‹ ë¢°ë„: 60%
ê·¼ê±°: ë‚®ì€ ë³€ë™ì„± ì† ê¾¸ì¤€í•œ ìƒìŠ¹ì„¸ë¡œ ì•ˆì •ì  ì¶”ì„¸ ìœ ì§€ ì „ë§
</answer>"""
            },

            # ì˜ˆì‹œ 8: í•˜ë½ (ì €ê±°ë˜ëŸ‰ í•˜ë½)
            {
                "role": "user",
                "content": """ì¢…ëª©: ticker_í•˜ë½4
ã€ê°€ê²© ë™í–¥ã€‘ì¼ì¤‘ ìˆ˜ìµë¥ : -0.5%, ì¢…ê°€ ë³€í™”: -0.7%, ì¼ì¤‘ ë³€ë™í­: 1.8% (ë‚®ìŒ)
ã€ì´ë™í‰ê·  ë¶„ì„ã€‘5ì¼MA: $55.00 (í˜„ì¬: $53.50) â†’ í•˜ë½ (0.973), 20ì¼MA: $56.50 â†’ í•˜ë½ (0.947)
ã€ê±°ë˜ëŸ‰ ë¶„ì„ã€‘í˜„ì¬: 350,000ì£¼, 5ì¼ í‰ê· : 450,000ì£¼ â†’ í‰ê·  ì´í•˜
ã€ê¸°ìˆ ì  ì‹ í˜¸ã€‘ì•½í•œ í•˜ë½ì„¸"""
            },
            {
                "role": "assistant",
                "content": """<think>
ê±°ë˜ëŸ‰ ê°ì†Œ + ì§€ì†ì  í•˜ë½ â†’ ë§¤ìˆ˜ì„¸ ë¶€ì¡±
</think>
<answer>
ì˜ˆì¸¡: í•˜ë½
ì‹ ë¢°ë„: 58%
ê·¼ê±°: ë§¤ìˆ˜ì„¸ ë¶€ì¡±ê³¼ ì´ë™í‰ê·  í•˜íšŒë¡œ ì•½ì„¸ ì§€ì† ì˜ˆìƒ
</answer>"""
            },

            # ì˜ˆì‹œ 9: ìƒìŠ¹ (íšŒë³µ ì‹ í˜¸)
            {
                "role": "user",
                "content": """ì¢…ëª©: ticker_ìƒìŠ¹5
ã€ê°€ê²© ë™í–¥ã€‘ì¼ì¤‘ ìˆ˜ìµë¥ : 1.8%, ì¢…ê°€ ë³€í™”: +2.1%, ì¼ì¤‘ ë³€ë™í­: 3.5% (ë³´í†µ)
ã€ì´ë™í‰ê·  ë¶„ì„ã€‘5ì¼MA: $88.00 (í˜„ì¬: $90.00) â†’ ìƒìŠ¹ (1.023), 20ì¼MA: $85.00 â†’ ìƒìŠ¹ (1.059)
ã€ê±°ë˜ëŸ‰ ë¶„ì„ã€‘í˜„ì¬: 1,800,000ì£¼, 5ì¼ í‰ê· : 1,300,000ì£¼ â†’ í‰ê·  ì´ìƒ
ã€ê¸°ìˆ ì  ì‹ í˜¸ã€‘5ì¼MAê°€ 20ì¼MA ìƒí–¥ ëŒíŒŒ ì§ì „"""
            },
            {
                "role": "assistant",
                "content": """<think>
ê³¨ë“ í¬ë¡œìŠ¤ ì„ë°• + ê±°ë˜ëŸ‰ ì¦ê°€ â†’ ì¶”ì„¸ ì „í™˜
</think>
<answer>
ì˜ˆì¸¡: ìƒìŠ¹
ì‹ ë¢°ë„: 72%
ê·¼ê±°: ê³¨ë“ í¬ë¡œìŠ¤ ì„ë°•ê³¼ ê±°ë˜ëŸ‰ ì¦ê°€ë¡œ ìƒìŠ¹ ì „í™˜ ê¸°ëŒ€
</answer>"""
            },

            # ì˜ˆì‹œ 10: í•˜ë½ (ì¶”ì„¸ ì „í™˜ ì‹ í˜¸)
            {
                "role": "user",
                "content": """ì¢…ëª©: ticker_í•˜ë½5
ã€ê°€ê²© ë™í–¥ã€‘ì¼ì¤‘ ìˆ˜ìµë¥ : -1.3%, ì¢…ê°€ ë³€í™”: -1.5%, ì¼ì¤‘ ë³€ë™í­: 3.2% (ë³´í†µ)
ã€ì´ë™í‰ê·  ë¶„ì„ã€‘5ì¼MA: $42.00 (í˜„ì¬: $41.00) â†’ í•˜ë½ (0.976), 20ì¼MA: $44.00 â†’ í•˜ë½ (0.932)
ã€ê±°ë˜ëŸ‰ ë¶„ì„ã€‘í˜„ì¬: 1,600,000ì£¼, 5ì¼ í‰ê· : 1,100,000ì£¼ â†’ í‰ê·  ì´ìƒ
ã€ê¸°ìˆ ì  ì‹ í˜¸ã€‘5ì¼MAê°€ 20ì¼MA í•˜í–¥ ëŒíŒŒ"""
            },
            {
                "role": "assistant",
                "content": """<think>
ë°ë“œí¬ë¡œìŠ¤ ë°œìƒ + ê±°ë˜ëŸ‰ ì¦ê°€ â†’ í•˜ë½ ì „í™˜
</think>
<answer>
ì˜ˆì¸¡: í•˜ë½
ì‹ ë¢°ë„: 68%
ê·¼ê±°: ë°ë“œí¬ë¡œìŠ¤ ë°œìƒê³¼ ê±°ë˜ëŸ‰ ì¦ê°€ë¡œ í•˜ë½ ì¶”ì„¸ ì „í™˜ ì˜ˆìƒ
</answer>"""
            }
        ]

    def predict(self, features: Dict[str, float], ticker: str) -> Tuple[int, float, str]:
        """
        ë‹¨ì¼ ì¢…ëª©ì— ëŒ€í•œ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        Args:
            features: 16ê°œ ê¸°ìˆ ì  ì§€í‘œ ë”•ì…”ë„ˆë¦¬
            ticker: ì¢…ëª© ì½”ë“œ

        Returns:
            (prediction, confidence, reasoning)
            - prediction: 0 (í•˜ë½) or 1 (ìƒìŠ¹)
            - confidence: 0.0 ~ 1.0
            - reasoning: DeepSeekì˜ ì¶”ë¡  ê³¼ì •
        """
        # 1. íŠ¹ì§•ì„ ìì—°ì–´ë¡œ ë³€í™˜
        ticker_summary = self.converter.convert(features, ticker)

        # 2. ë©”ì‹œì§€ êµ¬ì„± (Few-shot + User query)
        messages = [
            {"role": "system", "content": self._create_system_prompt()}
        ]

        # Few-shot ì˜ˆì œ ì¶”ê°€
        messages.extend(self._create_few_shot_examples())

        # ì‹¤ì œ ì§ˆë¬¸ ì¶”ê°€
        messages.append({
            "role": "user",
            "content": ticker_summary
        })

        # 3. vLLMì„ í†µí•œ DeepSeek-R1 ì¶”ë¡  í˜¸ì¶œ
        try:
            response = self.client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=DEEPSEEK_TEMPERATURE,
                max_tokens=DEEPSEEK_MAX_TOKENS,
            )

            response_text = response.choices[0].message.content

        except Exception as e:
            print(f"âŒ ì˜ˆì¸¡ ì‹¤íŒ¨ ({ticker}): {e}")
            # ì‹¤íŒ¨ ì‹œ ì¤‘ë¦½ ì˜ˆì¸¡ ë°˜í™˜
            return 1, 0.5, f"Error: {str(e)}"

        # 4. ì‘ë‹µ íŒŒì‹±
        prediction, confidence, reasoning = self._parse_response(response_text)

        return prediction, confidence, reasoning

    def _parse_response(self, response_text: str) -> Tuple[int, float, str]:
        """
        DeepSeek-R1ì˜ ì‘ë‹µì„ íŒŒì‹±í•˜ì—¬ êµ¬ì¡°í™”ëœ ì˜ˆì¸¡ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

        Args:
            response_text: DeepSeek-R1ì˜ ì›ë³¸ ì‘ë‹µ

        Returns:
            (prediction, confidence, reasoning)
        """
        # <think> íƒœê·¸ì—ì„œ ì¶”ë¡  ê³¼ì • ì¶”ì¶œ
        think_match = re.search(r'<think>(.*?)</think>', response_text, re.DOTALL | re.IGNORECASE)
        reasoning = think_match.group(1).strip() if think_match else ""

        # <answer> íƒœê·¸ì—ì„œ ìµœì¢… ë‹µë³€ ì¶”ì¶œ
        answer_match = re.search(r'<answer>(.*?)</answer>', response_text, re.DOTALL | re.IGNORECASE)
        answer = answer_match.group(1).strip() if answer_match else response_text

        # ì˜ˆì¸¡ ì¶”ì¶œ (ìƒìŠ¹/í•˜ë½ í‚¤ì›Œë“œ) - ê°•í™”ëœ íŒŒì‹±
        prediction = None

        # í•˜ë½ í‚¤ì›Œë“œ ì²´í¬ (ìš°ì„ ìˆœìœ„ ë†’ìŒ)
        if re.search(r'(ì˜ˆì¸¡|prediction)[\s:]*í•˜ë½|í•˜ë½\s*ì˜ˆì¸¡', answer, re.IGNORECASE):
            prediction = 0
        elif re.search(r'í•˜ë½|fall|down|bearish|decline|decrease', answer, re.IGNORECASE):
            prediction = 0

        # ìƒìŠ¹ í‚¤ì›Œë“œ ì²´í¬
        elif re.search(r'(ì˜ˆì¸¡|prediction)[\s:]*ìƒìŠ¹|ìƒìŠ¹\s*ì˜ˆì¸¡', answer, re.IGNORECASE):
            prediction = 1
        elif re.search(r'ìƒìŠ¹|rise|up|bullish|increase|rally', answer, re.IGNORECASE):
            prediction = 1

        # ì¤‘ë¦½/íš¡ë³´ í‚¤ì›Œë“œ ì²˜ë¦¬ (ê¸ˆì§€ë˜ì—ˆì§€ë§Œ í˜¹ì‹œ ë‚˜ì˜¬ ê²½ìš° ëŒ€ë¹„)
        if prediction is None or re.search(r'íš¡ë³´|ì¤‘ë¦½|æŒå¹³|íŒë‹¨ë¶ˆê°€|neutral|sideways|flat|hold', answer, re.IGNORECASE):
            # ìµœê·¼ ì¶”ë¡  ê³¼ì •ì—ì„œ íŒíŠ¸ ì°¾ê¸°
            if re.search(r'ìƒìŠ¹|rise|up|bullish|ë§¤ìˆ˜|ê³¨ë“ í¬ë¡œìŠ¤', response_text, re.IGNORECASE):
                prediction = 1
            elif re.search(r'í•˜ë½|fall|down|bearish|ë§¤ë„|ë°ë“œí¬ë¡œìŠ¤', response_text, re.IGNORECASE):
                prediction = 0
            else:
                # ì™„ì „íˆ ë¶ˆí™•ì‹¤í•œ ê²½ìš° ê¸°ë³¸ê°’
                prediction = 1  # ê¸°ë³¸ê°’: ìƒìŠ¹

        # ì‹ ë¢°ë„ ì¶”ì¶œ (0-100% â†’ 0.0-1.0)
        confidence = 0.5  # ê¸°ë³¸ê°’
        conf_match = re.search(r'ì‹ ë¢°ë„:?\s*(\d+)\s*%?', answer, re.IGNORECASE)
        if conf_match:
            confidence = float(conf_match.group(1)) / 100.0
        else:
            # confidence ì˜ì–´ íŒ¨í„´ë„ ê²€ìƒ‰
            conf_match = re.search(r'confidence:?\s*(\d+)\s*%?', answer, re.IGNORECASE)
            if conf_match:
                confidence = float(conf_match.group(1)) / 100.0

        # ì¶”ë¡  ê³¼ì • í¬í•¨í•œ ì „ì²´ reasoning
        full_reasoning = f"ã€ì¶”ë¡  ê³¼ì •ã€‘\n{reasoning}\n\nã€ìµœì¢… ë‹µë³€ã€‘\n{answer}"

        return prediction, confidence, full_reasoning

    async def predict_async(self, features: Dict[str, float], ticker: str) -> Tuple[int, float, str]:
        """
        ë¹„ë™ê¸° ë°©ì‹ìœ¼ë¡œ ë‹¨ì¼ ì¢…ëª© ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤.

        Args:
            features: 16ê°œ ê¸°ìˆ ì  ì§€í‘œ ë”•ì…”ë„ˆë¦¬
            ticker: ì¢…ëª© ì½”ë“œ

        Returns:
            (prediction, confidence, reasoning)
        """
        # 1. íŠ¹ì§•ì„ ìì—°ì–´ë¡œ ë³€í™˜
        ticker_summary = self.converter.convert(features, ticker)

        # 2. ë©”ì‹œì§€ êµ¬ì„±
        messages = [
            {"role": "system", "content": self._create_system_prompt()}
        ]
        messages.extend(self._create_few_shot_examples())
        messages.append({
            "role": "user",
            "content": ticker_summary
        })

        # 3. ë¹„ë™ê¸° vLLMì„ í†µí•œ DeepSeek-R1 ì¶”ë¡  í˜¸ì¶œ
        try:
            response = await self.async_client.chat.completions.create(
                model=self.model_name,
                messages=messages,
                temperature=DEEPSEEK_TEMPERATURE,
                max_tokens=DEEPSEEK_MAX_TOKENS,
            )

            response_text = response.choices[0].message.content

            # DEBUG: ì²« ë²ˆì§¸ ì‘ë‹µë§Œ ë¡œê¹… (ë””ë²„ê¹…ìš©)
            if not hasattr(self, '_debug_logged'):
                print(f"\nğŸ” DEBUG - Raw Response for {ticker}:")
                print(f"Response length: {len(response_text)} chars")
                print(f"Finish reason: {response.choices[0].finish_reason}")
                print(f"First 500 chars: {response_text[:500]}")
                self._debug_logged = True

        except Exception as e:
            print(f"âŒ Async prediction error for {ticker}: {e}")
            import traceback
            traceback.print_exc()
            return 1, 0.5, f"Error: {str(e)}"

        # 4. ì‘ë‹µ íŒŒì‹±
        prediction, confidence, reasoning = self._parse_response(response_text)
        return prediction, confidence, reasoning

    def batch_predict(self, features_list: List[Dict], tickers: List[str]) -> pd.DataFrame:
        """
        ì—¬ëŸ¬ ì¢…ëª©ì— ëŒ€í•œ ë°°ì¹˜ ì˜ˆì¸¡ì„ ìˆ˜í–‰í•©ë‹ˆë‹¤ (ë¹„ë™ê¸° ë³‘ë ¬ ì²˜ë¦¬).

        Args:
            features_list: íŠ¹ì§• ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
            tickers: ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸

        Returns:
            ì˜ˆì¸¡ ê²°ê³¼ë¥¼ ë‹´ì€ DataFrame (ticker, prediction, confidence, reasoning)
        """
        print(f"\nğŸ¤– DeepSeek-R1ìœ¼ë¡œ {len(tickers)}ê°œ ì¢…ëª© ì˜ˆì¸¡ ì¤‘...")
        print(f"   ë³‘ë ¬ ì²˜ë¦¬: {CONCURRENT_REQUESTS}ê°œ ë™ì‹œ ì‹¤í–‰")

        # asyncioë¥¼ ì‚¬ìš©í•˜ì—¬ ë°°ì¹˜ ì²˜ë¦¬
        results = asyncio.run(self._batch_predict_async(features_list, tickers))

        return pd.DataFrame(results)

    async def _batch_predict_async(self, features_list: List[Dict], tickers: List[str]) -> List[Dict]:
        """
        ë¹„ë™ê¸° ë°°ì¹˜ ì˜ˆì¸¡ì˜ ë‚´ë¶€ êµ¬í˜„.

        ë™ì‹œì— CONCURRENT_REQUESTSê°œì”© ì²˜ë¦¬í•˜ì—¬ ì†ë„ë¥¼ í¬ê²Œ í–¥ìƒì‹œí‚µë‹ˆë‹¤.
        """
        results = []
        semaphore = asyncio.Semaphore(CONCURRENT_REQUESTS)

        async def predict_with_semaphore(features, ticker):
            """ì„¸ë§ˆí¬ì–´ë¥¼ ì‚¬ìš©í•œ ë™ì‹œ ì‹¤í–‰ ì œí•œ"""
            try:
                async with semaphore:
                    prediction, confidence, reasoning = await self.predict_async(features, ticker)
                    return {
                        'ticker': ticker,
                        'prediction': prediction,
                        'confidence': confidence,
                        'reasoning': reasoning
                    }
            except Exception as e:
                print(f"\nâŒ {ticker} ì˜ˆì¸¡ ì‹¤íŒ¨: {e}")
                import traceback
                traceback.print_exc()
                # ì‹¤íŒ¨ ì‹œì—ë„ ê¸°ë³¸ê°’ ë°˜í™˜
                return {
                    'ticker': ticker,
                    'prediction': 1,
                    'confidence': 0.5,
                    'reasoning': f"Error: {str(e)}"
                }

        # ëª¨ë“  ì˜ˆì¸¡ ì‘ì—…ì„ íƒœìŠ¤í¬ë¡œ ìƒì„±
        tasks = [
            predict_with_semaphore(features, ticker)
            for features, ticker in zip(features_list, tickers)
        ]

        # tqdmì„ ì‚¬ìš©í•œ í”„ë¡œê·¸ë ˆìŠ¤ë°”ì™€ í•¨ê»˜ ì‹¤í–‰
        results = []
        with tqdm(total=len(tasks), desc="ì˜ˆì¸¡ ì§„í–‰") as pbar:
            for coro in asyncio.as_completed(tasks):
                result = await coro
                results.append(result)
                pbar.update(1)

        print(f"\nâœ… ì´ {len(results)}ê°œ ì˜ˆì¸¡ ì™„ë£Œ")
        return results


# ====================================================================
# ë°ì´í„° ì¤€ë¹„ í•¨ìˆ˜
# ====================================================================

def prepare_ticker_features(train_df: pd.DataFrame, ticker: str) -> Dict[str, float]:
    """
    íŠ¹ì • ì¢…ëª©ì˜ ìµœê·¼ ë°ì´í„°ë¡œë¶€í„° íŠ¹ì§•ì„ ì¶”ì¶œí•©ë‹ˆë‹¤.

    Args:
        train_df: ì „ì²´ í•™ìŠµ ë°ì´í„°
        ticker: ì¢…ëª© ì½”ë“œ

    Returns:
        16ê°œ íŠ¹ì§•ì„ ë‹´ì€ ë”•ì…”ë„ˆë¦¬
    """
    # í•´ë‹¹ ì¢…ëª© ë°ì´í„° í•„í„°ë§
    ticker_data = train_df[train_df['Ticker'] == ticker].sort_values('Date')

    if len(ticker_data) == 0:
        # ë°ì´í„° ì—†ëŠ” ê²½ìš° ë¹ˆ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
        return {}

    # ê¸°ë³¸ íŠ¹ì§• ìƒì„±
    features_df = create_features(ticker_data)

    # ì´ë™í‰ê·  ì¶”ê°€
    for window in [5, 10, 20]:
        features_df[f'ma_{window}'] = ticker_data['Close'].rolling(
            window=window, min_periods=1
        ).mean()
        features_df[f'volume_ma_{window}'] = ticker_data['Volume'].rolling(
            window=window, min_periods=1
        ).mean()

    # ê°€ê²©/ì´ë™í‰ê·  ë¹„ìœ¨
    features_df['price_to_ma5'] = ticker_data['Close'] / features_df['ma_5']
    features_df['price_to_ma20'] = ticker_data['Close'] / features_df['ma_20']

    # Close ê°€ê²© ì¶”ê°€ (í…ìŠ¤íŠ¸ ë³€í™˜ìš©)
    features_df['close'] = ticker_data['Close'].values

    # ê°€ì¥ ìµœê·¼ í–‰ ì¶”ì¶œ
    latest_features = features_df.iloc[-1].to_dict()

    return latest_features


def save_features_cache(features_list: List[Dict], tickers: List[str], cache_path: str):
    """
    íŠ¹ì§• ì¶”ì¶œ ê²°ê³¼ë¥¼ parquet íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.

    Args:
        features_list: íŠ¹ì§• ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        tickers: ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸
        cache_path: ì €ì¥í•  íŒŒì¼ ê²½ë¡œ
    """
    # DEBUG: ë°ì´í„° í™•ì¸
    print(f"   ì €ì¥í•  ë°ì´í„°: {len(features_list)}ê°œ ë”•ì…”ë„ˆë¦¬")
    if len(features_list) > 0:
        print(f"   ì²« ë²ˆì§¸ ë”•ì…”ë„ˆë¦¬ í‚¤ ê°œìˆ˜: {len(features_list[0])}ê°œ")
        print(f"   ìƒ˜í”Œ í‚¤: {list(features_list[0].keys())[:5]}")

    # ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜
    features_df = pd.DataFrame(features_list)
    print(f"   DataFrame shape: {features_df.shape}")
    print(f"   DataFrame ì»¬ëŸ¼: {features_df.columns.tolist()[:10]}")

    features_df['ticker'] = tickers

    # parquetìœ¼ë¡œ ì €ì¥
    features_df.to_parquet(cache_path, index=False, compression='snappy')
    print(f"âœ… íŠ¹ì§• ìºì‹œ ì €ì¥ ì™„ë£Œ: {cache_path}")
    print(f"   í¬ê¸°: {os.path.getsize(cache_path) / 1024 / 1024:.2f} MB")


def load_features_cache(cache_path: str) -> Tuple[List[Dict], List[str]]:
    """
    ì €ì¥ëœ íŠ¹ì§• ì¶”ì¶œ ê²°ê³¼ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤.

    Args:
        cache_path: ìºì‹œ íŒŒì¼ ê²½ë¡œ

    Returns:
        (features_list, tickers)
    """
    features_df = pd.read_parquet(cache_path)

    # ticker ì»¬ëŸ¼ ë¶„ë¦¬
    tickers = features_df['ticker'].tolist()
    features_df = features_df.drop(columns=['ticker'])

    # DataFrameì„ ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
    features_list = features_df.to_dict('records')

    print(f"âœ… íŠ¹ì§• ìºì‹œ ë¡œë“œ ì™„ë£Œ: {cache_path}")
    print(f"   ì¢…ëª© ìˆ˜: {len(tickers)}ê°œ")

    return features_list, tickers


def prepare_test_features(test_df: pd.DataFrame, train_df: pd.DataFrame, use_cache: bool = True) -> Tuple[List[Dict], List[str]]:
    """
    í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ì˜ ëª¨ë“  ì¢…ëª©ì— ëŒ€í•œ íŠ¹ì§•ì„ ì¤€ë¹„í•©ë‹ˆë‹¤.

    Args:
        test_df: í…ŒìŠ¤íŠ¸ ë°ì´í„° (ID, Date í¬í•¨)
        train_df: í•™ìŠµ ë°ì´í„° (ê³¼ê±° OHLCV ë°ì´í„°)
        use_cache: ìºì‹œ ì‚¬ìš© ì—¬ë¶€ (ê¸°ë³¸: True)

    Returns:
        (features_list, tickers)
        - features_list: íŠ¹ì§• ë”•ì…”ë„ˆë¦¬ ë¦¬ìŠ¤íŠ¸
        - tickers: ì¢…ëª© ì½”ë“œ ë¦¬ìŠ¤íŠ¸
    """
    # ìºì‹œ íŒŒì¼ ê²½ë¡œ
    cache_path = os.path.join(OUTPUT_DIR, 'test_features_cache.parquet')

    # ìºì‹œ ì‚¬ìš© ë° ìºì‹œ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°
    if use_cache and os.path.exists(cache_path):
        print("\nğŸ“¦ ìºì‹œëœ íŠ¹ì§• ë°ì´í„°ë¥¼ ë¡œë“œí•©ë‹ˆë‹¤...")
        try:
            return load_features_cache(cache_path)
        except Exception as e:
            print(f"âš ï¸  ìºì‹œ ë¡œë“œ ì‹¤íŒ¨: {e}")
            print("   íŠ¹ì§•ì„ ìƒˆë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤...")

    # ìºì‹œê°€ ì—†ê±°ë‚˜ ì‚¬ìš©í•˜ì§€ ì•ŠëŠ” ê²½ìš° ìƒˆë¡œ ì¶”ì¶œ
    print("\nğŸ“Š í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ íŠ¹ì§• ì¤€ë¹„ ì¤‘...")

    features_list = []
    tickers = []

    for _, row in tqdm(test_df.iterrows(), total=len(test_df), desc="íŠ¹ì§• ì¶”ì¶œ"):
        # IDê°€ ì´ë¯¸ tickerì„ (ì˜ˆ: ticker_1, ticker_10)
        ticker = row['ID']
        tickers.append(ticker)

        # íŠ¹ì§• ì¶”ì¶œ
        features = prepare_ticker_features(train_df, ticker)
        features_list.append(features)

    # ìºì‹œ ì €ì¥
    if use_cache:
        os.makedirs(OUTPUT_DIR, exist_ok=True)
        save_features_cache(features_list, tickers, cache_path)

    return features_list, tickers


# ====================================================================
# ë©”ì¸ ì‹¤í–‰ íŒŒì´í”„ë¼ì¸
# ====================================================================

def main():
    """
    DeepSeek-R1 ê¸°ë°˜ ì£¼ì‹ ì˜ˆì¸¡ íŒŒì´í”„ë¼ì¸ì˜ ë©”ì¸ í•¨ìˆ˜.

    ì‹¤í–‰ íë¦„:
        1. ë°ì´í„° ë¡œë“œ
        2. í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ íŠ¹ì§• ì¤€ë¹„
        3. DeepSeek-R1 ì˜ˆì¸¡ ìˆ˜í–‰
        4. ì œì¶œ íŒŒì¼ ìƒì„±
        5. ì¶”ë¡  ê³¼ì • ì €ì¥ (ì„ íƒ)
    """
    print("="*70)
    print("ğŸš€ DeepSeek-R1 ì£¼ì‹ íŠ¸ë Œë“œ ì˜ˆì¸¡ ì‹œì‘")
    print("="*70)

    start_time = datetime.now()

    # ====================================================================
    # 1. ë°ì´í„° ë¡œë“œ
    # ====================================================================
    train_df, test_df, sample_submission = load_data()

    # ====================================================================
    # 2. ì¶œë ¥ ë””ë ‰í† ë¦¬ ìƒì„±
    # ====================================================================
    os.makedirs(OUTPUT_DIR, exist_ok=True)

    # ====================================================================
    # 3. DeepSeek ì˜ˆì¸¡ê¸° ì´ˆê¸°í™”
    # ====================================================================
    predictor = DeepSeekStockPredictor(model_name=DEEPSEEK_MODEL)

    # ====================================================================
    # 4. í…ŒìŠ¤íŠ¸ ì„¸íŠ¸ íŠ¹ì§• ì¤€ë¹„
    # ====================================================================
    features_list, tickers = prepare_test_features(test_df, train_df)

    # ====================================================================
    # 5. ë°°ì¹˜ ì˜ˆì¸¡ ìˆ˜í–‰
    # ====================================================================
    predictions_df = predictor.batch_predict(features_list, tickers)

    # ì˜ˆì¸¡ ê²°ê³¼ í™•ì¸
    if predictions_df.empty or len(predictions_df) == 0:
        print("âŒ ì˜ˆì¸¡ ê²°ê³¼ê°€ ë¹„ì–´ìˆìŠµë‹ˆë‹¤!")
        return None, None

    print(f"\nğŸ“Š ì˜ˆì¸¡ ì™„ë£Œ: {len(predictions_df)}ê°œ")
    print(f"   ìƒìŠ¹ ì˜ˆì¸¡: {(predictions_df['prediction'] == 1).sum()}ê°œ")
    print(f"   í•˜ë½ ì˜ˆì¸¡: {(predictions_df['prediction'] == 0).sum()}ê°œ")
    print(f"   í‰ê·  ì‹ ë¢°ë„: {predictions_df['confidence'].mean():.3f}")

    # ====================================================================
    # 6. ì œì¶œ íŒŒì¼ ìƒì„±
    # ====================================================================
    submission = sample_submission.copy()
    submission['Pred'] = predictions_df['prediction'].values

    submission_path = os.path.join(OUTPUT_DIR, 'submission_deepseek.csv')
    submission.to_csv(submission_path, index=False)
    print(f"\nâœ… ì œì¶œ íŒŒì¼ ì €ì¥: {submission_path}")

    # ====================================================================
    # 7. ì¶”ë¡  ê³¼ì • ì €ì¥ (ì„ íƒ)
    # ====================================================================
    if SAVE_REASONING:
        reasoning_path = os.path.join(OUTPUT_DIR, 'deepseek_reasoning.json')
        reasoning_data = predictions_df[['ticker', 'prediction', 'confidence', 'reasoning']].to_dict('records')

        with open(reasoning_path, 'w', encoding='utf-8') as f:
            json.dump(reasoning_data, f, ensure_ascii=False, indent=2)

        print(f"âœ… ì¶”ë¡  ê³¼ì • ì €ì¥: {reasoning_path}")

    # ====================================================================
    # 8. í†µê³„ ì¶œë ¥
    # ====================================================================
    print("\n" + "="*70)
    print("ğŸ“Š ì˜ˆì¸¡ ê²°ê³¼ í†µê³„")
    print("="*70)

    total = len(submission)
    rises = (submission['Pred'] == 1).sum()
    falls = (submission['Pred'] == 0).sum()

    print(f"ì´ ì˜ˆì¸¡ ìˆ˜: {total}")
    print(f"ìƒìŠ¹ ì˜ˆì¸¡ (1): {rises}ê°œ ({rises/total:.1%})")
    print(f"í•˜ë½ ì˜ˆì¸¡ (0): {falls}ê°œ ({falls/total:.1%})")

    avg_confidence = predictions_df['confidence'].mean()
    print(f"í‰ê·  ì‹ ë¢°ë„: {avg_confidence:.1%}")

    # ì‹¤í–‰ ì‹œê°„
    elapsed = datetime.now() - start_time
    print(f"\nâ±ï¸  ì´ ì‹¤í–‰ ì‹œê°„: {elapsed}")
    print(f"   í‰ê·  ì˜ˆì¸¡ ì‹œê°„: {elapsed.total_seconds() / total:.2f}ì´ˆ/ì¢…ëª©")

    # ====================================================================
    # 9. ê²½ê³  ë° ë‹¤ìŒ ë‹¨ê³„ ì•ˆë‚´
    # ====================================================================
    print("\n" + "="*70)
    print("âœ… DeepSeek-R1 ì˜ˆì¸¡ ì™„ë£Œ!")
    print("="*70)

    if rises / total < 0.1 or rises / total > 0.9:
        print("\nâš ï¸  ê²½ê³ : ì˜ˆì¸¡ì´ ë§¤ìš° ë¶ˆê· í˜•í•©ë‹ˆë‹¤!")
        print("   - í”„ë¡¬í”„íŠ¸ íŠœë‹ì´ í•„ìš”í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤")
        print("   - Few-shot ì˜ˆì œë¥¼ ì¡°ì •í•˜ì„¸ìš”")

    print("\nğŸ“Œ ë‹¤ìŒ ë‹¨ê³„:")
    print(f"   1. ì œì¶œ: {submission_path}")
    print(f"   2. ì¶”ë¡  ê²€í† : {reasoning_path if SAVE_REASONING else 'N/A'}")
    print("   3. baseline.pyì™€ ì„±ëŠ¥ ë¹„êµ")
    print("   4. í”„ë¡¬í”„íŠ¸ ìµœì í™” (temperature, few-shot ì¡°ì •)")

    return predictions_df, submission


# ====================================================================
# ìŠ¤í¬ë¦½íŠ¸ ì§„ì…ì 
# ====================================================================

if __name__ == "__main__":
    """
    ìŠ¤í¬ë¦½íŠ¸ ì§ì ‘ ì‹¤í–‰ ì‹œ ë©”ì¸ íŒŒì´í”„ë¼ì¸ì„ ì‹¤í–‰í•©ë‹ˆë‹¤.

    ì‚¬ìš©ë²•:
        python deepseek_predictor.py

    ì‚¬ì „ ìš”êµ¬ì‚¬í•­:
        1. Ollama ì„¤ì¹˜ ë° ì‹¤í–‰ (ollama serve)
        2. DeepSeek-R1 ëª¨ë¸ ì„¤ì¹˜ (ollama pull deepseek-r1:14b)
        3. ë°ì´í„° íŒŒì¼ ì¡´ì¬ (data/train.csv, data/test.csv)

    ì˜ˆìƒ ì‹¤í–‰ ì‹œê°„:
        - íŠ¹ì§• ì¶”ì¶œ: ~5ë¶„ (5,000 ì¢…ëª©)
        - DeepSeek ì˜ˆì¸¡: ~40-60ë¶„ (0.5ì´ˆ/ì¢…ëª©)
        - ì´: ~45-65ë¶„
    """
    try:
        predictions_df, submission = main()
    except KeyboardInterrupt:
        print("\n\nâš ï¸  ì‚¬ìš©ìì— ì˜í•´ ì¤‘ë‹¨ë˜ì—ˆìŠµë‹ˆë‹¤.")
    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()
