#!/usr/bin/env python3
"""
Chapter 6: ì¼ê°„ ëª¨ë©˜í…€ ì „ëµ - ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±ê¸°

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Ernest Chanì˜ "Algorithmic Trading" Chapter 6ì˜ í•µì‹¬ ê°œë…ë“¤ì„ ì‹¤í–‰í•˜ê³ 
ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•© ë¦¬í¬íŠ¸ í˜•íƒœë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.

ë¶„ì„ ë‚´ìš©:
1. ì‹œê³„ì—´ ëª¨ë©˜í…€ ìƒê´€ê´€ê³„ í…ŒìŠ¤íŠ¸ (Box 6.1) - TU ì„ ë¬¼
2. TU ì‹œê³„ì—´ ëª¨ë©˜í…€ ì „ëµ (ì˜ˆì œ 6.1)
3. ëª¨ë©˜í…€ ì „ëµ ê°€ì„¤ ê²€ì • (ì˜ˆì œ 6.1 í™•ì¥)
4. ì£¼ì‹ íš¡ë‹¨ë©´ ëª¨ë©˜í…€ ì „ëµ (ì˜ˆì œ 6.2 - Kent Daniel)
"""

import os
import sys
import warnings
from datetime import datetime
from pathlib import Path

import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
from scipy.stats import pearsonr
from scipy.stats import pearson3

# ê²½ê³  ë©”ì‹œì§€ ì–µì œ
warnings.filterwarnings('ignore')

# ë¦¬í¬íŠ¸ ì¶œë ¥ ì„¤ì •
REPORT_DIR = Path(__file__).parent / "reports"
FIGURES_DIR = REPORT_DIR / "figures"


def calculateMaxDD(cumret):
    """ìµœëŒ€ ë‚™í­ ê³„ì‚°"""
    vals = cumret.values if hasattr(cumret, 'values') else np.array(cumret)
    vals = np.nan_to_num(vals, nan=0.0)
    highwatermark = np.zeros(len(vals))
    drawdown = np.zeros(len(vals))
    drawdownduration = np.zeros(len(vals))

    for t in range(1, len(vals)):
        highwatermark[t] = max(highwatermark[t-1], vals[t])
        drawdown[t] = (1 + vals[t]) / (1 + highwatermark[t]) - 1 if (1 + highwatermark[t]) != 0 else 0
        if drawdown[t] == 0:
            drawdownduration[t] = 0
        else:
            drawdownduration[t] = drawdownduration[t-1] + 1

    maxDD = np.min(drawdown) if len(drawdown) > 0 else 0
    maxDDD = int(np.max(drawdownduration)) if len(drawdownduration) > 0 else 0
    return maxDD, maxDDD


class Chapter6Analyzer:
    """Chapter 6 ì¼ê°„ ëª¨ë©˜í…€ ì „ëµ ë¶„ì„ í´ë˜ìŠ¤"""

    def __init__(self):
        self.results = {}
        self.figures = []
        REPORT_DIR.mkdir(exist_ok=True)
        FIGURES_DIR.mkdir(exist_ok=True)

    def load_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print("=" * 60)
        print("ğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
        print("=" * 60)

        data_dir = Path(__file__).parent

        # TU ì„ ë¬¼ ë°ì´í„° (OHLC í˜•ì‹)
        tu_path = data_dir / "inputDataOHLCDaily_TU_20120511.csv"
        self.tu = pd.read_csv(tu_path)
        self.tu['Date'] = pd.to_datetime(self.tu['Date'], format='%Y%m%d')
        self.tu.set_index('Date', inplace=True)
        print(f"  âœ“ TU ì„ ë¬¼ (OHLC): {len(self.tu)} ê±°ë˜ì¼")

        # TU ì„ ë¬¼ ë°ì´í„° (ê°€ì„¤ ê²€ì •ìš©)
        tu2_path = data_dir / "TU.csv"
        self.tu_hyp = pd.read_csv(tu2_path)
        self.tu_hyp['Time'] = pd.to_datetime(self.tu_hyp['Time']).dt.date
        self.tu_hyp.set_index('Time', inplace=True)
        print(f"  âœ“ TU ì„ ë¬¼ (ê°€ì„¤ê²€ì •): {len(self.tu_hyp)} ê±°ë˜ì¼")

        # ì£¼ì‹ ë°ì´í„° (Chapter 4 ë””ë ‰í† ë¦¬ì—ì„œ ë¡œë“œ)
        ch4_dir = data_dir.parent.parent / "chapter_4_mean_reversion_of_stocks_and_etfs" / "src"
        cl_path = ch4_dir / "inputDataOHLCDaily_20120424_cl.csv"
        stocks_path = ch4_dir / "inputDataOHLCDaily_20120424_stocks.csv"

        if cl_path.exists() and stocks_path.exists():
            stocks_df = pd.read_csv(stocks_path)
            self.stock_names = stocks_df.values[0].tolist()  # ë‘ ë²ˆì§¸ í–‰ì´ ì‹¤ì œ ì¢…ëª©ëª…

            cl = pd.read_csv(cl_path)
            date_col = cl.columns[0]
            cl[date_col] = pd.to_datetime(cl[date_col], format='%Y%m%d')
            cl.columns = ['Date'] + self.stock_names
            cl.set_index('Date', inplace=True)
            self.stocks_cl = cl
            print(f"  âœ“ ì£¼ì‹ ì¢…ê°€: {len(self.stocks_cl)} ê±°ë˜ì¼ x {len(self.stocks_cl.columns)} ì¢…ëª©")
        else:
            self.stocks_cl = None
            print("  âœ— ì£¼ì‹ ë°ì´í„° íŒŒì¼ ë¯¸ë°œê²¬ (Chapter 4 ë””ë ‰í† ë¦¬)")

        print()

    def analyze_ts_momentum_correlation(self):
        """Box 6.1: ì‹œê³„ì—´ ëª¨ë©˜í…€ ìƒê´€ê´€ê³„ í…ŒìŠ¤íŠ¸

        ë‹¤ì–‘í•œ lookback/holddays ì¡°í•©ì—ì„œ ê³¼ê±° ìˆ˜ìµë¥ ê³¼ ë¯¸ë˜ ìˆ˜ìµë¥  ê°„
        í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ë¥¼ ê³„ì‚°í•˜ì—¬ ëª¨ë©˜í…€ ì¡´ì¬ ì—¬ë¶€ í™•ì¸.
        """
        print("=" * 60)
        print("ğŸ“ˆ ë¶„ì„ 1: ì‹œê³„ì—´ ëª¨ë©˜í…€ ìƒê´€ê´€ê³„ (Box 6.1)")
        print("=" * 60)

        df = self.tu.copy()
        lookbacks = [1, 5, 10, 25, 60, 120, 250]
        holddays_list = [1, 5, 10, 25, 60, 120, 250]

        # ìƒê´€ í–‰ë ¬ ì €ì¥
        corr_matrix = np.full((len(lookbacks), len(holddays_list)), np.nan)
        pval_matrix = np.full((len(lookbacks), len(holddays_list)), np.nan)

        print(f"\n  {'Lookback':>8} {'Holddays':>8} {'Corr':>8} {'P-value':>8}")
        print(f"  {'-'*36}")

        for i, lookback in enumerate(lookbacks):
            for j, holddays in enumerate(holddays_list):
                ret_lag = df.pct_change(periods=lookback)
                ret_fut = df.shift(-holddays).pct_change(periods=holddays)

                if lookback >= holddays:
                    indepSet = range(0, ret_lag.shape[0], holddays)
                else:
                    indepSet = range(0, ret_lag.shape[0], lookback)

                ret_lag = ret_lag.iloc[indepSet]
                ret_fut = ret_fut.iloc[indepSet]
                goodDates = (ret_lag.notna() & ret_fut.notna()).values.flatten()

                if np.sum(goodDates) > 10:
                    cc, pval = pearsonr(
                        ret_lag.values[goodDates].flatten(),
                        ret_fut.values[goodDates].flatten()
                    )
                    corr_matrix[i, j] = cc
                    pval_matrix[i, j] = pval

                    # ìœ ì˜í•œ ëª¨ë©˜í…€ ìƒê´€ê´€ê³„ë§Œ ì¶œë ¥
                    if pval < 0.05 and cc > 0:
                        print(f"  {lookback:8d} {holddays:8d} {cc:8.4f} {pval:8.4f} *")

        self.results['ts_correlation'] = {
            'corr_matrix': corr_matrix,
            'pval_matrix': pval_matrix,
            'lookbacks': lookbacks,
            'holddays_list': holddays_list,
        }

        # ì°¨íŠ¸: íˆíŠ¸ë§µ
        fig, axes = plt.subplots(1, 2, figsize=(14, 5))

        im0 = axes[0].imshow(corr_matrix, cmap='RdBu_r', vmin=-0.3, vmax=0.3, aspect='auto')
        axes[0].set_title('Correlation Coefficient', fontsize=13)
        axes[0].set_xlabel('Holding Period (days)')
        axes[0].set_ylabel('Lookback Period (days)')
        axes[0].set_xticks(range(len(holddays_list)))
        axes[0].set_xticklabels(holddays_list)
        axes[0].set_yticks(range(len(lookbacks)))
        axes[0].set_yticklabels(lookbacks)
        plt.colorbar(im0, ax=axes[0])

        # p-value íˆíŠ¸ë§µ (ìœ ì˜í•˜ì§€ ì•Šì€ ê²ƒ ê°•ì¡°)
        sig_matrix = np.where(pval_matrix < 0.05, corr_matrix, 0)
        im1 = axes[1].imshow(sig_matrix, cmap='RdBu_r', vmin=-0.3, vmax=0.3, aspect='auto')
        axes[1].set_title('Significant Correlations Only (p<0.05)', fontsize=13)
        axes[1].set_xlabel('Holding Period (days)')
        axes[1].set_ylabel('Lookback Period (days)')
        axes[1].set_xticks(range(len(holddays_list)))
        axes[1].set_xticklabels(holddays_list)
        axes[1].set_yticks(range(len(lookbacks)))
        axes[1].set_yticklabels(lookbacks)
        plt.colorbar(im1, ax=axes[1])

        plt.tight_layout()
        fig_path = FIGURES_DIR / "ch6_correlation_heatmap.png"
        plt.savefig(fig_path, dpi=150, bbox_inches='tight')
        plt.close()
        self.figures.append(('ch6_correlation_heatmap.png', 'TU ëª¨ë©˜í…€ ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ'))
        print(f"\n  âœ“ ì°¨íŠ¸ ì €ì¥: {fig_path.name}")
        print()

    def analyze_tu_momentum(self):
        """ì˜ˆì œ 6.1: TU ì‹œê³„ì—´ ëª¨ë©˜í…€ ì „ëµ

        lookback=250ì¼, holddays=25ì¼ ëª¨ë©˜í…€ ì „ëµ.
        ê³¼ê±° 250ì¼ ìˆ˜ìµë¥ ì´ ì–‘ì´ë©´ ë¡±, ìŒì´ë©´ ìˆ.
        25ì¼ê°„ í¬ì§€ì…˜ì„ ìœ ì§€í•˜ë©° ë§¤ì¼ ìƒˆ ì‹ í˜¸ ì¤‘ì²©.
        ì±… ê²°ê³¼: APR=1.2%, Sharpe=1.3, MaxDD=-2.7%
        """
        print("=" * 60)
        print("ğŸ“ˆ ë¶„ì„ 2: TU ì‹œê³„ì—´ ëª¨ë©˜í…€ ì „ëµ (ì˜ˆì œ 6.1)")
        print("=" * 60)

        df = self.tu.copy()
        lookback = 250
        holddays = 25

        # ë¡±/ìˆ ì§„ì… ì‹ í˜¸ - ì›ë³¸ ë¡œì§
        longs = df > df.shift(lookback)
        shorts = df < df.shift(lookback)

        # í¬ì§€ì…˜ ëˆ„ì  (holddays-1 ê¸°ê°„ ë™ì•ˆ ë˜ê¹…) - ì›ë³¸ ë¡œì§
        pos = np.zeros(df.shape)
        for h in range(holddays - 1):
            long_lag = longs.shift(h).fillna(False).astype(bool).values
            short_lag = shorts.shift(h).fillna(False).astype(bool).values
            pos[long_lag] = pos[long_lag] + 1
            pos[short_lag] = pos[short_lag] - 1

        pos = pd.DataFrame(pos)

        # ìˆ˜ìµë¥  ê³„ì‚°
        pnl = np.sum((pos.shift().values) * (df.pct_change().values), axis=1)
        denom = np.nansum(np.abs(pos.shift().values), axis=1)
        denom[denom == 0] = np.nan
        ret = pnl / denom

        # NaN ì •ë¦¬
        ret = pd.Series(ret, index=df.index)
        valid_ret = ret.dropna()
        cumret = (1 + valid_ret).cumprod() - 1

        apr = np.prod(1 + valid_ret.values) ** (252 / len(valid_ret)) - 1 if len(valid_ret) > 0 else 0
        sharpe = np.sqrt(252) * np.mean(valid_ret.values) / np.std(valid_ret.values) if np.std(valid_ret.values) > 0 else 0
        maxDD, maxDDD = calculateMaxDD(cumret)

        self.results['tu_momentum'] = {
            'apr': apr, 'sharpe': sharpe, 'maxDD': maxDD, 'maxDDD': maxDDD,
            'lookback': lookback, 'holddays': holddays,
        }

        print(f"  Lookback = {lookback}ì¼, Holddays = {holddays}ì¼")
        print(f"  APR = {apr*100:.2f}%")
        print(f"  Sharpe = {sharpe:.4f}")
        print(f"  Max DD = {maxDD*100:.2f}%, Max DDD = {maxDDD}ì¼")
        print(f"  ì±… ê¸°ëŒ€ê°’: Sharpe ~1.3, MaxDD ~-2.7%")

        # ì°¨íŠ¸
        fig, axes = plt.subplots(2, 1, figsize=(12, 8))

        axes[0].plot(cumret.index, cumret.values * 100, 'b-', linewidth=1)
        axes[0].set_title(f'TU Momentum Strategy (LB={lookback}, HD={holddays}) - Cumulative Returns', fontsize=13)
        axes[0].set_ylabel('Cumulative Return (%)')
        axes[0].grid(True, alpha=0.3)

        axes[1].plot(df.index, df.values, 'gray', linewidth=0.5, alpha=0.7)
        axes[1].set_title('TU Futures Price', fontsize=13)
        axes[1].set_ylabel('Price')
        axes[1].grid(True, alpha=0.3)

        plt.tight_layout()
        fig_path = FIGURES_DIR / "ch6_tu_momentum.png"
        plt.savefig(fig_path, dpi=150, bbox_inches='tight')
        plt.close()
        self.figures.append(('ch6_tu_momentum.png', 'TU ì‹œê³„ì—´ ëª¨ë©˜í…€ ì „ëµ'))
        print(f"  âœ“ ì°¨íŠ¸ ì €ì¥: {fig_path.name}")
        print()

    def analyze_hypothesis_test(self):
        """ì˜ˆì œ 6.1 í™•ì¥: ëª¨ë©˜í…€ ì „ëµ ê°€ì„¤ ê²€ì •

        1. ê°€ìš°ì‹œì•ˆ í…ŒìŠ¤íŠ¸: Sharpe ratioë¥¼ t-í†µê³„ëŸ‰ìœ¼ë¡œ ì‚¬ìš©
        2. ëœë¤í™” ì‹œì¥ ìˆ˜ìµë¥ : Pearson Type III ë¶„í¬ì—ì„œ ì‹œë®¬ë ˆì´ì…˜
        3. ëœë¤í™” ê±°ë˜ ì§„ì…: ì§„ì… íƒ€ì´ë°ì„ ì…”í”Œ

        ì±… ê²°ê³¼: Gaussian=2.77, Randomized prices p=23.6, Randomized trades p=1.37
        """
        print("=" * 60)
        print("ğŸ“ˆ ë¶„ì„ 3: ëª¨ë©˜í…€ ì „ëµ ê°€ì„¤ ê²€ì • (ì˜ˆì œ 6.1 í™•ì¥)")
        print("=" * 60)

        df = self.tu_hyp.copy()
        lookback = 250
        holddays = 25

        # ì›ë³¸ ë¡œì§: 1ì¼ ìˆ˜ìµë¥  ê¸°ë°˜ ëª¨ë©˜í…€
        longs = df['Close'] > df['Close'].shift()
        shorts = df['Close'] < df['Close'].shift()

        pos = np.zeros(df.shape[0])
        for h in range(0, holddays):
            long_lag = longs.shift(h)
            long_lag[long_lag.isna()] = False
            long_lag = long_lag.astype(bool)
            short_lag = shorts.shift(h)
            short_lag[short_lag.isna()] = False
            short_lag = short_lag.astype(bool)
            pos[long_lag] = pos[long_lag] + 1
            pos[short_lag] = pos[short_lag] - 1

        capital = np.nansum(np.array(pd.DataFrame(abs(pos)).shift()), axis=1)
        pos[capital == 0] = 0
        capital[capital == 0] = 1

        marketRet = df['Close'].pct_change()
        ret = np.nansum(np.array(pd.DataFrame(pos).shift()) * np.array(marketRet), axis=1) / capital / holddays

        # ê°€ìš°ì‹œì•ˆ í…ŒìŠ¤íŠ¸ í†µê³„ëŸ‰ = ì „ì²´ Sharpe ë¹„ìœ¨
        sharpe_stat = np.sqrt(len(ret)) * np.nanmean(ret) / np.nanstd(ret)
        print(f"  [ê°€ìš°ì‹œì•ˆ ê²€ì •]")
        print(f"    Test statistic = {sharpe_stat:.4f}")
        print(f"    ì±… ê¸°ëŒ€ê°’: 2.77")

        # ëœë¤í™” ì‹œì¥ ìˆ˜ìµë¥  ê°€ì„¤ ê²€ì • (ì¶•ì†Œëœ ë°˜ë³µ íšŸìˆ˜)
        n_sim = 1000  # ì›ë³¸ 10000 â†’ ì‹œê°„ ì ˆì•½ì„ ìœ„í•´ 1000
        skew_, loc_, scale_ = pearson3.fit(marketRet.values[1:])

        numBetter_prices = 0
        for sample in range(n_sim):
            marketRet_sim = pearson3.rvs(skew=skew_, loc=loc_, scale=scale_,
                                         size=marketRet.shape[0], random_state=sample)
            cl_sim = np.cumprod(1 + marketRet_sim) - 1

            longs_sim = cl_sim > pd.Series(cl_sim).shift(lookback)
            shorts_sim = cl_sim < pd.Series(cl_sim).shift(lookback)

            pos_sim = np.zeros(cl_sim.shape[0])
            for h in range(0, holddays):
                long_sim_lag = longs_sim.shift(h)
                long_sim_lag[long_sim_lag.isna()] = False
                long_sim_lag = long_sim_lag.astype(bool)
                short_sim_lag = shorts_sim.shift(h)
                short_sim_lag[short_sim_lag.isna()] = False
                short_sim_lag = short_sim_lag.astype(bool)
                pos_sim[long_sim_lag] = pos_sim[long_sim_lag] + 1
                pos_sim[short_sim_lag] = pos_sim[short_sim_lag] - 1

            cap_sim = np.nansum(np.array(pd.DataFrame(abs(pos_sim)).shift()), axis=1)
            pos_sim[cap_sim == 0] = 0
            cap_sim[cap_sim == 0] = 1
            ret_sim = np.nansum(np.array(pd.DataFrame(pos_sim).shift()) * np.array(marketRet_sim), axis=1) / cap_sim / holddays

            if np.mean(ret_sim) >= np.mean(ret):
                numBetter_prices += 1

        pval_prices = numBetter_prices / n_sim
        print(f"  [ëœë¤í™” ì‹œì¥ ìˆ˜ìµë¥  p-value] = {pval_prices:.4f} (x {n_sim} ì‹œë®¬ë ˆì´ì…˜)")
        print(f"    ì±… ê¸°ëŒ€ê°’ (x10000): 23.6")

        # ëœë¤í™” ê±°ë˜ ì§„ì… ê°€ì„¤ ê²€ì •
        numBetter_trades = 0
        for sample in range(n_sim):
            rng = np.random.RandomState(sample)
            P = rng.permutation(len(longs))
            longs_sim = longs.iloc[P].reset_index(drop=True)
            shorts_sim = shorts.iloc[P].reset_index(drop=True)
            longs_sim.index = longs.index
            shorts_sim.index = shorts.index

            pos_sim = np.zeros(df.shape[0])
            for h in range(0, holddays):
                long_sim_lag = longs_sim.shift(h)
                long_sim_lag[long_sim_lag.isna()] = False
                long_sim_lag = long_sim_lag.astype(bool)
                short_sim_lag = shorts_sim.shift(h)
                short_sim_lag[short_sim_lag.isna()] = False
                short_sim_lag = short_sim_lag.astype(bool)
                pos_sim[long_sim_lag] = pos_sim[long_sim_lag] + 1
                pos_sim[short_sim_lag] = pos_sim[short_sim_lag] - 1

            cap_sim = np.nansum(np.array(pd.DataFrame(abs(pos_sim)).shift()), axis=1)
            pos_sim[cap_sim == 0] = 0
            cap_sim[cap_sim == 0] = 1
            ret_sim = np.nansum(np.array(pd.DataFrame(pos_sim).shift()) * np.array(marketRet), axis=1) / cap_sim / holddays

            if np.mean(ret_sim) >= np.mean(ret):
                numBetter_trades += 1

        pval_trades = numBetter_trades / n_sim
        print(f"  [ëœë¤í™” ê±°ë˜ ì§„ì… p-value] = {pval_trades:.4f} (x {n_sim} ì‹œë®¬ë ˆì´ì…˜)")
        print(f"    ì±… ê¸°ëŒ€ê°’ (x10000): 1.37")

        self.results['hypothesis_test'] = {
            'gaussian_stat': sharpe_stat,
            'pval_prices': pval_prices,
            'pval_trades': pval_trades,
            'n_sim': n_sim,
        }

        # ì°¨íŠ¸: ê°€ì„¤ ê²€ì • ê²°ê³¼ ìš”ì•½
        fig, ax = plt.subplots(1, 1, figsize=(8, 5))
        labels = ['Gaussian\nTest Stat', f'Randomized\nPrices p\n(x{n_sim})', f'Randomized\nTrades p\n(x{n_sim})']
        values = [sharpe_stat, pval_prices, pval_trades]
        colors = ['green' if v > 1.96 or v < 0.05 else 'red' for v in [sharpe_stat, pval_prices, pval_trades]]
        # ê°€ìš°ì‹œì•ˆ: >1.96ì´ë©´ ìœ ì˜, p-value: <0.05ë©´ ìœ ì˜
        colors = ['green', 'red', 'red']  # ê°€ìš°ì‹œì•ˆ ìœ ì˜, p-valueëŠ” ìœ ì˜í•˜ì§€ ì•Šì„ ìˆ˜ ìˆìŒ

        bars = ax.bar(labels, values, color=colors, alpha=0.7, edgecolor='black')
        ax.axhline(y=1.96, color='r', linestyle='--', alpha=0.5, label='Critical Value (1.96)')
        ax.axhline(y=0.05, color='b', linestyle='--', alpha=0.5, label='Significance Level (0.05)')
        ax.set_title('Hypothesis Tests for TU Momentum Strategy', fontsize=13)
        ax.set_ylabel('Value')
        ax.legend()
        ax.grid(True, alpha=0.3)

        for bar, val in zip(bars, values):
            ax.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.1,
                    f'{val:.4f}', ha='center', va='bottom', fontsize=10)

        plt.tight_layout()
        fig_path = FIGURES_DIR / "ch6_hypothesis_test.png"
        plt.savefig(fig_path, dpi=150, bbox_inches='tight')
        plt.close()
        self.figures.append(('ch6_hypothesis_test.png', 'ëª¨ë©˜í…€ ê°€ì„¤ ê²€ì • ê²°ê³¼'))
        print(f"  âœ“ ì°¨íŠ¸ ì €ì¥: {fig_path.name}")
        print()

    def analyze_cross_sectional_momentum(self):
        """ì˜ˆì œ 6.2: ì£¼ì‹ íš¡ë‹¨ë©´ ëª¨ë©˜í…€ ì „ëµ (Kent Daniel ìŠ¤íƒ€ì¼)

        252ì¼ ìˆ˜ìµë¥  ê¸°ì¤€ ìƒìœ„ 50 ì¢…ëª© ë¡±, í•˜ìœ„ 50 ì¢…ëª© ìˆ.
        25ì¼ê°„ í¬ì§€ì…˜ ìœ ì§€, ë§¤ì¼ ìƒˆ ì‹ í˜¸ ì¤‘ì²©.
        """
        print("=" * 60)
        print("ğŸ“ˆ ë¶„ì„ 4: ì£¼ì‹ íš¡ë‹¨ë©´ ëª¨ë©˜í…€ ì „ëµ (ì˜ˆì œ 6.2)")
        print("=" * 60)

        if self.stocks_cl is None:
            print("  âœ— ì£¼ì‹ ë°ì´í„° ì—†ìŒ - ê±´ë„ˆëœ€")
            return

        cl = self.stocks_cl.copy()
        lookback = 252
        holddays = 25
        topN = 50

        # ê³¼ê±° ìˆ˜ìµë¥ 
        ret = cl.pct_change(periods=lookback)

        # ë¡±/ìˆ ì¢…ëª© ì„ ì • (ìƒìœ„/í•˜ìœ„ topN)
        longs = np.full(cl.shape, False)
        shorts = np.full(cl.shape, False)
        positions = np.zeros(cl.shape)

        for t in range(lookback, cl.shape[0]):
            hasData = np.where(np.isfinite(ret.iloc[t, :]))[0]
            if len(hasData) > 0:
                idxSort = np.argsort(ret.iloc[t, hasData])
                n_select = min(topN, len(idxSort))
                # ìƒìœ„ n_select: ë¡±
                longs[t, hasData[idxSort.values[-n_select:]]] = True
                # í•˜ìœ„ n_select: ìˆ
                shorts[t, hasData[idxSort.values[:n_select]]] = True

        longs = pd.DataFrame(longs)
        shorts = pd.DataFrame(shorts)

        # í¬ì§€ì…˜ ëˆ„ì  (holddays-1 ê¸°ê°„)
        for h in range(holddays - 1):
            long_lag = longs.shift(h).fillna(False).astype(bool).values
            short_lag = shorts.shift(h).fillna(False).astype(bool).values
            positions[long_lag] = positions[long_lag] + 1
            positions[short_lag] = positions[short_lag] - 1

        positions = pd.DataFrame(positions)

        # ìˆ˜ìµë¥  = PnL / (2 * topN * holddays) -> ê· ë“± ê°€ì¤‘ ë²¤ì¹˜ë§ˆí¬
        ret_arr = np.nansum((positions.shift().values) * (cl.pct_change().values), axis=1) / (2 * topN) / holddays
        ret_strat = pd.Series(ret_arr, index=cl.index).fillna(0)

        cumret = (1 + ret_strat).cumprod() - 1

        apr = float(np.prod(1 + ret_strat.values) ** (252 / len(ret_strat)) - 1)
        sharpe = float(np.sqrt(252) * np.mean(ret_strat.values) / np.std(ret_strat.values)) if np.std(ret_strat.values) > 0 else 0
        maxDD, maxDDD = calculateMaxDD(cumret)

        self.results['cross_sectional'] = {
            'apr': apr, 'sharpe': sharpe, 'maxDD': maxDD, 'maxDDD': maxDDD,
            'lookback': lookback, 'holddays': holddays, 'topN': topN,
        }

        print(f"  Lookback = {lookback}ì¼, Holddays = {holddays}ì¼, TopN = {topN}")
        print(f"  APR = {apr*100:.2f}%")
        print(f"  Sharpe = {sharpe:.4f}")
        print(f"  Max DD = {maxDD*100:.2f}%, Max DDD = {maxDDD}ì¼")

        # ì°¨íŠ¸
        fig, ax = plt.subplots(1, 1, figsize=(12, 5))
        ax.plot(cumret.index, cumret.values * 100, 'b-', linewidth=1)
        ax.set_title(f'Cross-Sectional Momentum (LB={lookback}, HD={holddays}, TopN={topN})', fontsize=13)
        ax.set_ylabel('Cumulative Return (%)')
        ax.grid(True, alpha=0.3)

        plt.tight_layout()
        fig_path = FIGURES_DIR / "ch6_cross_sectional_momentum.png"
        plt.savefig(fig_path, dpi=150, bbox_inches='tight')
        plt.close()
        self.figures.append(('ch6_cross_sectional_momentum.png', 'íš¡ë‹¨ë©´ ëª¨ë©˜í…€ ì „ëµ'))
        print(f"  âœ“ ì°¨íŠ¸ ì €ì¥: {fig_path.name}")
        print()

    def generate_report(self):
        """ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("=" * 60)
        print("ğŸ“ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        print("=" * 60)

        report = []
        report.append("# Chapter 6: ì¼ê°„ ëª¨ë©˜í…€ ì „ëµ (Interday Momentum Strategies)")
        report.append(f"\n> ë¶„ì„ ì‹¤í–‰ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

        # 1. ê°œìš”
        report.append("## 1. ê°œìš” ë° ë¬¸ì œ ì •ì˜\n")
        report.append("Chapter 6ì€ ì¼ê°„(interday) ì‹œê°„ ì²™ë„ì—ì„œì˜ ëª¨ë©˜í…€ ì „ëµì„ íƒêµ¬í•œë‹¤.")
        report.append("í‰ê·  íšŒê·€ì™€ ë°˜ëŒ€ë˜ëŠ” ëª¨ë©˜í…€ í˜„ìƒì´ íŠ¹ì • ìì‚°êµ°/ì‹œê°„ëŒ€ì—ì„œ ì•ˆì •ì ìœ¼ë¡œ ë°œìƒí•˜ëŠ”ì§€ ê²€ì¦í•œë‹¤.\n")
        report.append("### ëª¨ë©˜í…€ì˜ 4ê°€ì§€ ì›ì¸\n")
        report.append("1. **ë¡¤ ìˆ˜ìµë¥  ì§€ì†ì„±**: ì„ ë¬¼ì˜ ì½˜íƒ±ê³ /ë°±ì›Œë°ì´ì…˜ êµ¬ì¡° ìœ ì§€")
        report.append("2. **ì •ë³´ í™•ì‚° ì§€ì—°**: ë‰´ìŠ¤ì— ëŒ€í•œ ê°€ê²© ë°˜ì‘ì´ ì¦‰ê°ì ì´ì§€ ì•ŠìŒ")
        report.append("3. **ê°•ì œ ë§¤ë§¤**: í€ë“œì˜ ê°•ì œ ì²­ì‚°/í¸ì…ì— ì˜í•œ ê°€ê²© ì••ë ¥")
        report.append("4. **ê³ ë¹ˆë„ ê±°ë˜ìì˜ ì‹œì¥ ì¡°ì‘**: ë‹¨ê¸°ì  ê°€ê²© ì™œê³¡\n")
        report.append("### í•µì‹¬ ìˆ˜í•™ì  ê°œë…\n")
        report.append("**ì‹œê³„ì—´ ëª¨ë©˜í…€ ê²€ì • (ìƒê´€ê³„ìˆ˜):**\n")
        report.append("$$\\rho(r_{[t-L,t]}, r_{[t,t+H]}) \\neq 0 \\quad (\\text{with } p < 0.05)$$\n")
        report.append("**ëª¨ë©˜í…€ í¬ì§€ì…˜ ëˆ„ì :**\n")
        report.append("$$pos(t) = \\sum_{h=0}^{H-1} \\text{signal}(t-h)$$\n")
        report.append("**íš¡ë‹¨ë©´ ëª¨ë©˜í…€ (Kent Daniel):**\n")
        report.append("ìƒìœ„ N ì¢…ëª© ë¡±, í•˜ìœ„ N ì¢…ëª© ìˆ (ê³¼ê±° 252ì¼ ìˆ˜ìµë¥  ê¸°ì¤€)\n")

        # 2. ì‚¬ìš© ë°ì´í„°
        report.append("## 2. ì‚¬ìš© ë°ì´í„°\n")
        report.append("| íŒŒì¼ëª… | ë‚´ìš© | ìš©ë„ |")
        report.append("|--------|------|------|")
        report.append("| `inputDataOHLCDaily_TU_20120511.csv` | TU(2ë…„ êµ­ì±„ ì„ ë¬¼) ì¼ì¼ ì¢…ê°€ | ë¶„ì„ 1,2 |")
        report.append("| `TU.csv` | TU ì„ ë¬¼ ì¢…ê°€ (ë³„ë„ í˜•ì‹) | ë¶„ì„ 3 (ê°€ì„¤ ê²€ì •) |")
        report.append("| `inputDataOHLCDaily_20120424_cl.csv` | ~500 ì£¼ì‹ ì¢…ê°€ | ë¶„ì„ 4 |")
        report.append("| `inputDataOHLCDaily_20120424_stocks.csv` | ì¢…ëª©ëª… ë§¤í•‘ | ë¶„ì„ 4 |\n")

        # 3. ë¶„ì„ 1
        report.append("## 3. ë¶„ì„ 1: ì‹œê³„ì—´ ëª¨ë©˜í…€ ìƒê´€ê´€ê³„ (Box 6.1)\n")
        report.append("### ë°©ë²•ë¡ \n")
        report.append("- TU ì„ ë¬¼ì˜ ë‹¤ì–‘í•œ lookback/holddays ì¡°í•©ì—ì„œ í”¼ì–´ìŠ¨ ìƒê´€ê³„ìˆ˜ ì¸¡ì •")
        report.append("- ë…ë¦½ í‘œë³¸ì„ ìœ„í•´ ë¹„ì¤‘ë³µ ê¸°ê°„ ì‚¬ìš© (ê°„ê²© = max(lookback, holddays))\n")

        if 'ts_correlation' in self.results:
            r = self.results['ts_correlation']
            report.append("### ê²°ê³¼ - ìƒê´€ê³„ìˆ˜ í–‰ë ¬\n")
            report.append("| LB\\HD | " + " | ".join(str(h) for h in r['holddays_list']) + " |")
            report.append("|" + "|".join(["---"] * (len(r['holddays_list']) + 1)) + "|")
            for i, lb in enumerate(r['lookbacks']):
                row = f"| {lb} |"
                for j in range(len(r['holddays_list'])):
                    val = r['corr_matrix'][i, j]
                    pv = r['pval_matrix'][i, j]
                    if np.isnan(val):
                        row += " - |"
                    elif pv < 0.05:
                        row += f" **{val:.3f}** |"
                    else:
                        row += f" {val:.3f} |"
                report.append(row)
            report.append("\n(ë³¼ë“œì²´ëŠ” p < 0.05ë¡œ ìœ ì˜í•œ ìƒê´€ê´€ê³„)\n")
            report.append("**í†µì°°**: ì¥ê¸° lookback (120-250ì¼)ê³¼ ì¤‘ê¸° holddays (25-60ì¼) ì¡°í•©ì—ì„œ ì–‘ì˜ ëª¨ë©˜í…€ ìƒê´€ê´€ê³„ í™•ì¸.\n")
            report.append("![ìƒê´€ê´€ê³„ íˆíŠ¸ë§µ](figures/ch6_correlation_heatmap.png)\n")

        # 4. ë¶„ì„ 2
        report.append("## 4. ë¶„ì„ 2: TU ì‹œê³„ì—´ ëª¨ë©˜í…€ ì „ëµ (ì˜ˆì œ 6.1)\n")
        report.append("### ë°©ë²•ë¡ \n")
        report.append("- lookback=250ì¼ ìˆ˜ìµë¥  ì–‘ìˆ˜ë©´ ë¡±, ìŒìˆ˜ë©´ ìˆ")
        report.append("- holddays=25ì¼ ë™ì•ˆ í¬ì§€ì…˜ ìœ ì§€, ë§¤ì¼ ìƒˆ ì‹ í˜¸ ì¤‘ì²©\n")

        if 'tu_momentum' in self.results:
            r = self.results['tu_momentum']
            report.append("### ê²°ê³¼\n")
            report.append("| ì§€í‘œ | ê°’ | ì±… ê¸°ëŒ€ê°’ |")
            report.append("|------|-----|----------|")
            report.append(f"| APR | {r['apr']*100:.2f}% | ~1.2% |")
            report.append(f"| Sharpe Ratio | {r['sharpe']:.4f} | ~1.3 |")
            report.append(f"| Max Drawdown | {r['maxDD']*100:.2f}% | ~-2.7% |")
            report.append(f"| Max DDD | {r['maxDDD']}ì¼ | - |\n")
            report.append("![TU ëª¨ë©˜í…€](figures/ch6_tu_momentum.png)\n")

        # 5. ë¶„ì„ 3
        report.append("## 5. ë¶„ì„ 3: ëª¨ë©˜í…€ ì „ëµ ê°€ì„¤ ê²€ì •\n")
        report.append("### ë°©ë²•ë¡ \n")
        report.append("ì„¸ ê°€ì§€ ê°€ì„¤ ê²€ì •ìœ¼ë¡œ ëª¨ë©˜í…€ ìˆ˜ìµì˜ í†µê³„ì  ìœ ì˜ì„± í™•ì¸:\n")
        report.append("1. **ê°€ìš°ì‹œì•ˆ ê²€ì •**: $\\frac{\\sqrt{N} \\cdot \\bar{r}}{\\sigma_r}$ (Sharpe ratio ê¸°ë°˜)")
        report.append("2. **ëœë¤í™” ì‹œì¥ ìˆ˜ìµë¥ **: Pearson Type III ë¶„í¬ë¡œ ì‹œì¥ ìˆ˜ìµë¥  ì‹œë®¬ë ˆì´ì…˜")
        report.append("3. **ëœë¤í™” ê±°ë˜ ì§„ì…**: ì§„ì… íƒ€ì´ë°ë§Œ ì…”í”Œí•˜ì—¬ ì „ëµ ê³ ìœ  ìˆ˜ìµ ê²€ì¦\n")

        if 'hypothesis_test' in self.results:
            r = self.results['hypothesis_test']
            report.append("### ê²°ê³¼\n")
            report.append("| ê²€ì • | ê°’ | ì±… ê¸°ëŒ€ê°’ | í•´ì„ |")
            report.append("|------|-----|----------|------|")
            gauss_sig = "ìœ ì˜ (>1.96)" if r['gaussian_stat'] > 1.96 else "ë¹„ìœ ì˜"
            report.append(f"| ê°€ìš°ì‹œì•ˆ í†µê³„ëŸ‰ | {r['gaussian_stat']:.4f} | 2.77 | {gauss_sig} |")
            report.append(f"| ëœë¤ ì‹œì¥ p-value | {r['pval_prices']:.4f} | ~0.24 | ë¹„ìœ ì˜ |")
            trade_sig = "ìœ ì˜ (<0.05)" if r['pval_trades'] < 0.05 else "ë¹„ìœ ì˜"
            report.append(f"| ëœë¤ ê±°ë˜ p-value | {r['pval_trades']:.4f} | ~0.014 | {trade_sig} |\n")
            report.append("**í†µì°°**: ê°€ìš°ì‹œì•ˆ ê²€ì •ì€ ìœ ì˜í•˜ì§€ë§Œ, ëœë¤ ì‹œì¥ ìˆ˜ìµë¥  ê²€ì •ì€ ë¹„ìœ ì˜ - ëª¨ë©˜í…€ì´ ì‹œì¥ ìˆ˜ìµë¥  ë¶„í¬ì˜ ë‚´ì¬ì  íŠ¹ì„±ì¼ ìˆ˜ ìˆìŒ.\n")
            report.append("![ê°€ì„¤ ê²€ì •](figures/ch6_hypothesis_test.png)\n")

        # 6. ë¶„ì„ 4
        report.append("## 6. ë¶„ì„ 4: ì£¼ì‹ íš¡ë‹¨ë©´ ëª¨ë©˜í…€ ì „ëµ (ì˜ˆì œ 6.2)\n")
        report.append("### ë°©ë²•ë¡ \n")
        report.append("- Kent Daniel ìŠ¤íƒ€ì¼: ê³¼ê±° 252ì¼ ìˆ˜ìµë¥ ë¡œ ~500 ì¢…ëª© ìˆœìœ„ ë§¤ê¸°ê¸°")
        report.append("- ìƒìœ„ 50ì¢…ëª© ë¡±, í•˜ìœ„ 50ì¢…ëª© ìˆ")
        report.append("- 25ì¼ê°„ ë³´ìœ , ë§¤ì¼ ë¦¬ë°¸ëŸ°ìŠ¤ (ì¤‘ì²©)\n")

        if 'cross_sectional' in self.results:
            r = self.results['cross_sectional']
            report.append("### ê²°ê³¼\n")
            report.append("| ì§€í‘œ | ê°’ |")
            report.append("|------|-----|")
            report.append(f"| APR | {r['apr']*100:.2f}% |")
            report.append(f"| Sharpe Ratio | {r['sharpe']:.4f} |")
            report.append(f"| Max Drawdown | {r['maxDD']*100:.2f}% |")
            report.append(f"| Max DDD | {r['maxDDD']}ì¼ |\n")
            report.append("![íš¡ë‹¨ë©´ ëª¨ë©˜í…€](figures/ch6_cross_sectional_momentum.png)\n")

        # 7. ì¢…í•© ë¹„êµ
        report.append("## 7. ì‹œê³„ì—´ vs íš¡ë‹¨ë©´ ëª¨ë©˜í…€ ë¹„êµ\n")
        report.append("| êµ¬ë¶„ | ì‹œê³„ì—´ ëª¨ë©˜í…€ | íš¡ë‹¨ë©´ ëª¨ë©˜í…€ |")
        report.append("|------|------------|------------|")
        report.append("| ì‹ í˜¸ ê¸°ë°˜ | ì ˆëŒ€ ìˆ˜ìµë¥  (ìì²´ ê³¼ê±°) | ìƒëŒ€ ìˆ˜ìµë¥  (ì¢…ëª© ê°„ ìˆœìœ„) |")
        report.append("| ìì‚° ìœ í˜• | ì„ ë¬¼ (ë‹¨ì¼ ìì‚°) | ì£¼ì‹ (ëŒ€í˜• ìœ ë‹ˆë²„ìŠ¤) |")
        report.append("| í¬ì§€ì…˜ | ë¡± ë˜ëŠ” ìˆ (1ê°œ) | ë‹¤ìˆ˜ ë¡± + ë‹¤ìˆ˜ ìˆ |")
        report.append("| ë¦¬ìŠ¤í¬ | ë°©í–¥ì„± ë¦¬ìŠ¤í¬ ë†’ìŒ | ì‹œì¥ ì¤‘ë¦½ì— ê°€ê¹Œì›€ |")

        if 'tu_momentum' in self.results and 'cross_sectional' in self.results:
            tu = self.results['tu_momentum']
            cs = self.results['cross_sectional']
            report.append(f"| APR | {tu['apr']*100:.2f}% | {cs['apr']*100:.2f}% |")
            report.append(f"| Sharpe | {tu['sharpe']:.2f} | {cs['sharpe']:.2f} |")
        report.append("")

        # 8. ê²°ë¡ 
        report.append("## 8. ê²°ë¡  ë° ê¶Œê³ ì‚¬í•­\n")
        report.append("### í•µì‹¬ ë°œê²¬\n")
        report.append("1. **TU ì„ ë¬¼ì— ëª¨ë©˜í…€ ì¡´ì¬**: ì¥ê¸° lookback, ì¤‘ê¸° holddays ì¡°í•©ì—ì„œ í†µê³„ì ìœ¼ë¡œ ìœ ì˜í•œ ì–‘ì˜ ìƒê´€ê´€ê³„")
        report.append("2. **ê°€ì„¤ ê²€ì •ì˜ ë¯¸ë¬˜í•¨**: ê°€ìš°ì‹œì•ˆ ê²€ì •ì€ í†µê³¼í•˜ë‚˜, ì‹œì¥ ìˆ˜ìµë¥  ìì²´ì˜ ë¶„í¬ íŠ¹ì„±ì¼ ê°€ëŠ¥ì„±")
        report.append("3. **íš¡ë‹¨ë©´ ëª¨ë©˜í…€**: ì‹œì¥ ì¤‘ë¦½ì— ê°€ê¹Œì›Œ ë°©í–¥ì„± ë¦¬ìŠ¤í¬ ë‚®ìŒ\n")
        report.append("### ì£¼ì˜ì‚¬í•­\n")
        report.append("- **ëª¨ë©˜í…€ í¬ë˜ì‹œ**: ì‹œì¥ ë°˜ì „ ì‹œ ëª¨ë©˜í…€ ì „ëµì˜ ê¸‰ê²©í•œ ì†ì‹¤ ê°€ëŠ¥")
        report.append("- **ê±°ë˜ë¹„ìš©**: ë†’ì€ íšŒì „ìœ¨ë¡œ ì¸í•œ ê±°ë˜ë¹„ìš© ê³ ë ¤ í•„ìš”")
        report.append("- **ì‹œê°„ ë³€í™”**: ëª¨ë©˜í…€ íš¨ê³¼ëŠ” ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ ì•½í™”ë˜ëŠ” ê²½í–¥\n")

        report_path = REPORT_DIR / "chapter6_report.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report))
        print(f"  âœ“ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")
        print()

    def run(self):
        """ì „ì²´ ë¶„ì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜"""
        print("\n" + "ğŸ”¬" * 30)
        print("  Chapter 6: ì¼ê°„ ëª¨ë©˜í…€ ì „ëµ - ì¢…í•© ë¶„ì„")
        print("ğŸ”¬" * 30 + "\n")

        self.load_data()
        self.analyze_ts_momentum_correlation()
        self.analyze_tu_momentum()
        self.analyze_hypothesis_test()
        self.analyze_cross_sectional_momentum()
        self.generate_report()

        print("=" * 60)
        print("âœ… Chapter 6 ë¶„ì„ ì™„ë£Œ!")
        print(f"   ë¦¬í¬íŠ¸: reports/chapter6_report.md")
        print(f"   ì°¨íŠ¸: {len(self.figures)}ê°œ ìƒì„±")
        for fig_name, fig_desc in self.figures:
            print(f"     - {fig_name}: {fig_desc}")
        print("=" * 60)


if __name__ == "__main__":
    analyzer = Chapter6Analyzer()
    analyzer.run()
