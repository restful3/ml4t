#!/usr/bin/env python3
"""
Chapter 4: ì£¼ì‹ê³¼ ETFì˜ í‰ê·  íšŒê·€ - ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±ê¸°

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Ernest Chanì˜ "Algorithmic Trading" Chapter 4ì˜ í•µì‹¬ ê°œë…ë“¤ì„ ì‹¤í–‰í•˜ê³ 
ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•© ë¦¬í¬íŠ¸ í˜•íƒœë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.

ë¶„ì„ ë‚´ìš©:
1. Buy-on-Gap ëª¨ë¸ (ì˜ˆì œ 4.1)
2. SPYì™€ êµ¬ì„± ì£¼ì‹ ê°„ ì¸ë±ìŠ¤ ì°¨ìµê±°ë˜ (ì˜ˆì œ 4.2)
3. íš¡ë‹¨ë©´ ì„ í˜• ë¡±-ìˆ ëª¨ë¸ (ì˜ˆì œ 4.3)
4. ì¼ì¤‘ ì„ í˜• ë¡±-ìˆ ëª¨ë¸ (ì˜ˆì œ 4.4)
"""

import os
import sys
import warnings
from datetime import datetime
from pathlib import Path

import numpy as np
import pandas as pd
import matplotlib
matplotlib.use('Agg')
import matplotlib.pyplot as plt
import statsmodels.tsa.stattools as ts
import statsmodels.tsa.vector_ar.vecm as vm

# ê²½ê³  ë©”ì‹œì§€ ì–µì œ
warnings.filterwarnings('ignore')

# ë¦¬í¬íŠ¸ ì¶œë ¥ ì„¤ì •
REPORT_DIR = Path(__file__).parent / "reports"
FIGURES_DIR = REPORT_DIR / "figures"


def calculateMaxDD(cumret):
    """ìµœëŒ€ ë‚™í­(Maximum Drawdown) ê³„ì‚°

    Args:
        cumret: ëˆ„ì  ë³µë¦¬ ìˆ˜ìµë¥  ë°°ì—´

    Returns:
        maxDD: ìµœëŒ€ ë‚™í­
        maxDDD: ìµœëŒ€ ë‚™í­ ê¸°ê°„ (ì¼ìˆ˜)
        i: ìµœëŒ€ ë‚™í­ ë°œìƒ ì¸ë±ìŠ¤
    """
    highwatermark = np.zeros(cumret.shape)
    drawdown = np.zeros(cumret.shape)
    drawdownduration = np.zeros(cumret.shape)

    for t in np.arange(1, cumret.shape[0]):
        highwatermark[t] = np.maximum(highwatermark[t-1], cumret.iloc[t] if hasattr(cumret, 'iloc') else cumret[t])
        val = cumret.iloc[t] if hasattr(cumret, 'iloc') else cumret[t]
        drawdown[t] = (1 + val) / (1 + highwatermark[t]) - 1
        if drawdown[t] == 0:
            drawdownduration[t] = 0
        else:
            drawdownduration[t] = drawdownduration[t-1] + 1

    maxDD = np.min(drawdown)
    i = np.argmin(drawdown)
    maxDDD = np.max(drawdownduration)
    return maxDD, maxDDD, i


class Chapter4Analyzer:
    """Chapter 4 ì£¼ì‹ê³¼ ETFì˜ í‰ê·  íšŒê·€ ë¶„ì„ í´ë˜ìŠ¤"""

    def __init__(self):
        self.results = {}
        self.figures = []

        # ë””ë ‰í† ë¦¬ ìƒì„±
        REPORT_DIR.mkdir(exist_ok=True)
        FIGURES_DIR.mkdir(exist_ok=True)

    def load_data(self):
        """ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬"""
        print("=" * 60)
        print("ğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
        print("=" * 60)

        data_dir = Path(__file__).parent

        # ì£¼ì‹ í‹°ì»¤ ì´ë¦„ ë¡œë“œ
        stocks_path = data_dir / "inputDataOHLCDaily_20120424_stocks.csv"
        stocks_df = pd.read_csv(stocks_path)
        self.stock_names = stocks_df.iloc[0].values.tolist()
        print(f"  âœ“ ì£¼ì‹ í‹°ì»¤: {len(self.stock_names)}ê°œ ë¡œë“œ")

        # OHLC ë°ì´í„° ë¡œë“œ í•¨ìˆ˜
        def load_price_file(filename):
            path = data_dir / filename
            df = pd.read_csv(path)
            # ì²« ë²ˆì§¸ ì»¬ëŸ¼ì€ Date
            date_col = df.columns[0]
            df[date_col] = pd.to_datetime(df[date_col], format='%Y%m%d')
            df.set_index(date_col, inplace=True)
            df.index.name = 'Date'
            # ì»¬ëŸ¼ ì´ë¦„ì„ ì‹¤ì œ í‹°ì»¤ë¡œ ë³€í™˜
            df.columns = self.stock_names
            return df

        # ì¢…ê°€, ì‹œê°€, ê³ ê°€, ì €ê°€ ë¡œë“œ
        self.cl = load_price_file("inputDataOHLCDaily_20120424_cl.csv")
        self.op = load_price_file("inputDataOHLCDaily_20120424_op.csv")
        self.hi = load_price_file("inputDataOHLCDaily_20120424_hi.csv")
        self.lo = load_price_file("inputDataOHLCDaily_20120424_lo.csv")
        print(f"  âœ“ OHLC ë°ì´í„°: {len(self.cl)} ê±°ë˜ì¼ x {len(self.cl.columns)} ì£¼ì‹")
        print(f"    ê¸°ê°„: {self.cl.index[0].strftime('%Y-%m-%d')} ~ {self.cl.index[-1].strftime('%Y-%m-%d')}")

        # ETF ë°ì´í„° ë¡œë“œ
        etf_stocks_path = data_dir / "inputData_ETF_stocks.csv"
        etf_stocks_df = pd.read_csv(etf_stocks_path)
        self.etf_names = etf_stocks_df.iloc[0].values.tolist()

        etf_cl_path = data_dir / "inputData_ETF_cl.csv"
        etf_df = pd.read_csv(etf_cl_path)
        date_col = etf_df.columns[0]
        etf_df[date_col] = pd.to_datetime(etf_df[date_col], format='%Y%m%d')
        etf_df.set_index(date_col, inplace=True)
        etf_df.index.name = 'Date'
        etf_df.columns = self.etf_names
        self.etf_cl = etf_df
        print(f"  âœ“ ETF ë°ì´í„°: {len(self.etf_cl)} ê±°ë˜ì¼ x {len(self.etf_cl.columns)} ETF")

        # ì–´ë‹ ë°œí‘œ ë°ì´í„° ë¡œë“œ
        earnann_path = data_dir / "earnannFile.csv"
        if earnann_path.exists():
            self.earnann = pd.read_csv(earnann_path)
            date_col = self.earnann.columns[0]
            self.earnann[date_col] = pd.to_datetime(self.earnann[date_col], format='%Y%m%d')
            self.earnann.set_index(date_col, inplace=True)
            self.earnann.index.name = 'Date'
            print(f"  âœ“ ì–´ë‹ ë°œí‘œ ë°ì´í„°: {len(self.earnann)} ê±°ë˜ì¼")
        else:
            self.earnann = None
            print(f"  âœ— ì–´ë‹ ë°œí‘œ ë°ì´í„° ì—†ìŒ")

        print()

    def analyze_buy_on_gap(self):
        """ì˜ˆì œ 4.1: Buy-on-Gap ëª¨ë¸ ë¶„ì„

        ì „ì¼ ì €ê°€ ëŒ€ë¹„ ê°­ ë‹¤ìš´í•œ ì£¼ì‹ì„ ë§¤ìˆ˜í•˜ê³  ë‹¹ì¼ ì¢…ê°€ì— ì²­ì‚°í•˜ëŠ” ì¼ì¤‘ ì „ëµ.
        ëª¨ë©˜í…€ í•„í„°(20ì¼ MA)ë¥¼ ì ìš©í•˜ì—¬ ì¶”ì„¸ í•˜ë½ ì£¼ì‹ì„ ì œì™¸.
        """
        print("=" * 60)
        print("ğŸ“ˆ ë¶„ì„ 1: Buy-on-Gap ëª¨ë¸ (ì˜ˆì œ 4.1)")
        print("=" * 60)

        topN = 10
        entryZscore = 1
        lookback = 20  # MAìš©

        # ì¢…ê°€ ëŒ€ ì¢…ê°€ ìˆ˜ìµë¥ ì˜ 90ì¼ ë¡¤ë§ í‘œì¤€í¸ì°¨ (ì „ì¼ ê¸°ì¤€)
        retC2C = self.cl.pct_change()
        stdretC2C90d = retC2C.rolling(90).std().shift(1)

        # ë§¤ìˆ˜ ê°€ê²©: ì „ì¼ ì €ê°€ * (1 - entryZscore * std)
        buyPrice = self.lo.shift(1) * (1 - entryZscore * stdretC2C90d)

        # ê°­ ìˆ˜ìµë¥ : (ì‹œê°€ - ì „ì¼ ì €ê°€) / ì „ì¼ ì €ê°€
        retGap = (self.op - self.lo.shift(1)) / self.lo.shift(1)

        # 20ì¼ ì´ë™í‰ê·  (ì „ì¼ ê¸°ì¤€)
        ma = self.cl.rolling(lookback).mean().shift(1)

        pnl_list = []
        trade_counts = []

        for t in range(1, len(self.cl)):
            # ì¡°ê±´: ë°ì´í„° ì¡´ì¬ + ì‹œê°€ < ë§¤ìˆ˜ê°€ê²© + ì‹œê°€ > 20ì¼ MA
            hasData = (retGap.iloc[t].notna() &
                      (self.op.iloc[t] < buyPrice.iloc[t]) &
                      (self.op.iloc[t] > ma.iloc[t]))

            valid_stocks = retGap.iloc[t][hasData].dropna()

            if len(valid_stocks) > 0:
                # ê°­ì´ ê°€ì¥ í° (ê°€ì¥ ìŒì˜) ì£¼ì‹ topNê°œ ì„ íƒ
                sorted_stocks = valid_stocks.sort_values(ascending=True)
                selected = sorted_stocks.head(min(topN, len(sorted_stocks)))

                # ì‹œê°€-ì¢…ê°€ ìˆ˜ìµë¥ 
                retO2C = (self.cl.iloc[t] - self.op.iloc[t]) / self.op.iloc[t]
                daily_pnl = retO2C[selected.index].sum()
                pnl_list.append(daily_pnl / topN)
                trade_counts.append(len(selected))
            else:
                pnl_list.append(0.0)
                trade_counts.append(0)

        ret = pd.Series(pnl_list, index=self.cl.index[1:])
        ret = ret.fillna(0)

        cumret = (1 + ret).cumprod() - 1

        # ì„±ê³¼ ì§€í‘œ ê³„ì‚°
        apr = (1 + ret).prod() ** (252 / len(ret)) - 1
        sharpe = np.sqrt(252) * ret.mean() / ret.std() if ret.std() > 0 else 0
        maxDD, maxDDD, _ = calculateMaxDD(cumret)

        avg_trades = np.mean([c for c in trade_counts if c > 0]) if any(c > 0 for c in trade_counts) else 0
        active_days = sum(1 for c in trade_counts if c > 0)

        self.results['bog'] = {
            'apr': apr,
            'sharpe': sharpe,
            'maxDD': maxDD,
            'maxDDD': maxDDD,
            'avg_trades_per_day': avg_trades,
            'active_trading_days': active_days,
            'total_days': len(ret),
        }

        print(f"  APR = {apr:.4f} ({apr*100:.2f}%)")
        print(f"  Sharpe = {sharpe:.4f}")
        print(f"  Max DD = {maxDD:.4f} ({maxDD*100:.2f}%)")
        print(f"  Max DD Duration = {maxDDD:.0f} ì¼")
        print(f"  í™œì„± ê±°ë˜ì¼ = {active_days}/{len(ret)}, í‰ê·  ì¢…ëª©ìˆ˜ = {avg_trades:.1f}")

        # ì°¨íŠ¸ ìƒì„±
        fig, axes = plt.subplots(2, 1, figsize=(12, 8))

        axes[0].plot(cumret.index, cumret.values * 100, 'b-', linewidth=1)
        axes[0].set_title('Buy-on-Gap Model - Cumulative Returns', fontsize=14)
        axes[0].set_ylabel('Cumulative Return (%)')
        axes[0].grid(True, alpha=0.3)
        axes[0].axhline(y=0, color='k', linewidth=0.5)

        # ì¼ë³„ ê±°ë˜ ìˆ˜
        trade_series = pd.Series(trade_counts, index=self.cl.index[1:])
        axes[1].bar(trade_series.index, trade_series.values, color='steelblue', alpha=0.5, width=3)
        axes[1].set_title('Daily Number of Trades', fontsize=14)
        axes[1].set_ylabel('Number of Stocks')
        axes[1].grid(True, alpha=0.3)

        plt.tight_layout()
        fig_path = FIGURES_DIR / "ch4_buy_on_gap.png"
        plt.savefig(fig_path, dpi=150, bbox_inches='tight')
        plt.close()
        self.figures.append(('ch4_buy_on_gap.png', 'Buy-on-Gap ëª¨ë¸ ëˆ„ì  ìˆ˜ìµë¥ '))
        print(f"  âœ“ ì°¨íŠ¸ ì €ì¥: {fig_path.name}")
        print()

    def analyze_index_arbitrage(self):
        """ì˜ˆì œ 4.2: SPYì™€ êµ¬ì„± ì£¼ì‹ ê°„ ì¸ë±ìŠ¤ ì°¨ìµê±°ë˜

        ìš”í•œì„¼ ê³µì ë¶„ ê²€ì •ìœ¼ë¡œ SPYì™€ ê°œë³„ì ìœ¼ë¡œ ê³µì ë¶„í•˜ëŠ” ì£¼ì‹ì„ ì°¾ê³ ,
        ì´ë“¤ì˜ ë¡±ì˜¨ë¦¬ í¬íŠ¸í´ë¦¬ì˜¤ì™€ SPY ì‚¬ì´ì— ì„ í˜• í‰ê·  íšŒê·€ ì „ëµì„ ì ìš©.
        """
        print("=" * 60)
        print("ğŸ“ˆ ë¶„ì„ 2: SPY ì¸ë±ìŠ¤ ì°¨ìµê±°ë˜ (ì˜ˆì œ 4.2)")
        print("=" * 60)

        # SPY ë°ì´í„° ì¶”ì¶œ
        if 'SPY' not in self.etf_cl.columns:
            print("  âœ— SPY ë°ì´í„°ê°€ ETF íŒŒì¼ì— ì—†ìŠµë‹ˆë‹¤")
            return

        spy = self.etf_cl[['SPY']].copy()

        # ê³µí†µ ë‚ ì§œë¡œ ë³‘í•©
        common_dates = self.cl.index.intersection(spy.index)
        cl_common = self.cl.loc[common_dates].copy()
        spy_common = spy.loc[common_dates].copy()

        # í›ˆë ¨/í…ŒìŠ¤íŠ¸ ê¸°ê°„ ì„¤ì •
        train_mask = (common_dates >= '2007-01-01') & (common_dates <= '2007-12-31')
        test_mask = common_dates > '2007-12-31'

        train_dates = common_dates[train_mask]
        test_dates = common_dates[test_mask]

        print(f"  í›ˆë ¨ ê¸°ê°„: {train_dates[0].strftime('%Y-%m-%d')} ~ {train_dates[-1].strftime('%Y-%m-%d')} ({len(train_dates)}ì¼)")
        print(f"  í…ŒìŠ¤íŠ¸ ê¸°ê°„: {test_dates[0].strftime('%Y-%m-%d')} ~ {test_dates[-1].strftime('%Y-%m-%d')} ({len(test_dates)}ì¼)")

        # ê° ì£¼ì‹ê³¼ SPYì˜ ê³µì ë¶„ ê²€ì • (í›ˆë ¨ ì„¸íŠ¸)
        isCoint = {}
        spy_train = spy_common.loc[train_dates, 'SPY'].values

        tested = 0
        coint_count = 0
        for stock in cl_common.columns:
            stock_train = cl_common.loc[train_dates, stock].values
            y2 = np.column_stack([stock_train, spy_train])

            # NaN ì œê±°
            bad = np.any(np.isnan(y2), axis=1)
            y2_clean = y2[~bad]

            if y2_clean.shape[0] > 250:
                tested += 1
                try:
                    result = vm.coint_johansen(y2_clean, det_order=0, k_ar_diff=1)
                    # 90% ì‹ ë¢°ë„ì—ì„œ ê³µì ë¶„ í™•ì¸ (lr1 ì²« ë²ˆì§¸ > cvt ì²« ë²ˆì§¸ í–‰ ì²« ë²ˆì§¸ ì—´)
                    if result.lr1[0] > result.cvt[0, 0]:
                        isCoint[stock] = True
                        coint_count += 1
                except Exception:
                    pass

        coint_stocks = [s for s in isCoint.keys()]
        print(f"  ê²€ì • ì™„ë£Œ: {tested}ê°œ ì£¼ì‹ ì¤‘ {coint_count}ê°œê°€ SPYì™€ ê³µì ë¶„")

        if coint_count < 5:
            print("  âœ— ê³µì ë¶„ ì£¼ì‹ì´ ë„ˆë¬´ ì ì–´ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤")
            self.results['indexArb'] = {'apr': 0, 'sharpe': 0, 'maxDD': 0, 'maxDDD': 0, 'coint_count': coint_count}
            return

        # ë™ì¼ ìë³¸ ë°°ë¶„ ë¡±ì˜¨ë¦¬ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„± (ë¡œê·¸ ê°€ê²©)
        coint_prices_train = cl_common.loc[train_dates, coint_stocks]
        logMktVal_train = np.log(coint_prices_train).sum(axis=1)

        # í¬íŠ¸í´ë¦¬ì˜¤ì™€ SPYì˜ ê³µì ë¶„ í™•ì¸
        ytest = np.column_stack([logMktVal_train.values, np.log(spy_common.loc[train_dates, 'SPY'].values)])
        bad = np.any(np.isnan(ytest), axis=1)
        ytest_clean = ytest[~bad]

        try:
            result_port = vm.coint_johansen(ytest_clean, det_order=0, k_ar_diff=1)
            port_coint = result_port.lr1[0] > result_port.cvt[0, 1]  # 95% ì‹ ë¢°ë„
            evec = result_port.evec[:, 0]  # ì²« ë²ˆì§¸ ê³ ìœ ë²¡í„°
            print(f"  í¬íŠ¸í´ë¦¬ì˜¤-SPY ê³µì ë¶„: {'Yes (95%)' if port_coint else 'No'}")
            print(f"  ê³ ìœ ë²¡í„°: [{evec[0]:.4f}, {evec[1]:.4f}]")
        except Exception as e:
            print(f"  âœ— í¬íŠ¸í´ë¦¬ì˜¤ ê³µì ë¶„ ê²€ì • ì‹¤íŒ¨: {e}")
            self.results['indexArb'] = {'apr': 0, 'sharpe': 0, 'maxDD': 0, 'maxDDD': 0, 'coint_count': coint_count}
            return

        # í…ŒìŠ¤íŠ¸ ê¸°ê°„ì— ì„ í˜• í‰ê·  íšŒê·€ ì „ëµ ì ìš©
        coint_prices_test = cl_common.loc[test_dates, coint_stocks]
        spy_test = spy_common.loc[test_dates, 'SPY']

        # ê²°í•© ë°ì´í„°
        yNplus = pd.concat([coint_prices_test, spy_test], axis=1)

        # ê°€ì¤‘ì¹˜: ê³ ìœ ë²¡í„° ì ìš©
        weights = pd.DataFrame(index=test_dates, columns=yNplus.columns)
        for col in coint_stocks:
            weights[col] = evec[0]
        weights['SPY'] = evec[1]
        weights = weights.astype(float)

        # ë¡œê·¸ ì‹œì¥ ê°€ì¹˜
        logMktVal = (weights * np.log(yNplus)).sum(axis=1)

        lookback = 5
        ma = logMktVal.rolling(lookback).mean()
        mstd = logMktVal.rolling(lookback).std()
        numUnits = -(logMktVal - ma) / mstd
        numUnits = numUnits.fillna(0)

        # í¬ì§€ì…˜ = numUnits * weights
        positions = weights.multiply(numUnits, axis=0)

        # PnL ê³„ì‚° (ë¡œê·¸ ìˆ˜ìµë¥  ê¸°ë°˜)
        log_prices = np.log(yNplus)
        log_ret = log_prices - log_prices.shift(1)

        pnl = (positions.shift(1) * log_ret).sum(axis=1)
        capital = positions.shift(1).abs().sum(axis=1)
        capital = capital.replace(0, np.nan)
        ret = pnl / capital
        ret = ret.fillna(0)

        # ì´ˆê¸° NaN ê¸°ê°„ ì œê±°
        ret = ret.iloc[lookback:]
        cumret = (1 + ret).cumprod() - 1

        apr = (1 + ret).prod() ** (252 / len(ret)) - 1
        sharpe = np.sqrt(252) * ret.mean() / ret.std() if ret.std() > 0 else 0
        maxDD, maxDDD, _ = calculateMaxDD(cumret)

        self.results['indexArb'] = {
            'apr': apr,
            'sharpe': sharpe,
            'maxDD': maxDD,
            'maxDDD': maxDDD,
            'coint_count': coint_count,
            'port_coint': port_coint if 'port_coint' in dir() else False,
            'evec': evec.tolist(),
        }

        print(f"  APR = {apr:.4f} ({apr*100:.2f}%)")
        print(f"  Sharpe = {sharpe:.4f}")
        print(f"  Max DD = {maxDD:.4f} ({maxDD*100:.2f}%)")
        print(f"  Max DD Duration = {maxDDD:.0f} ì¼")

        # ì°¨íŠ¸ ìƒì„±
        fig, axes = plt.subplots(2, 1, figsize=(12, 8))

        axes[0].plot(cumret.index, cumret.values * 100, 'b-', linewidth=1)
        axes[0].set_title('SPY Index Arbitrage - Cumulative Returns', fontsize=14)
        axes[0].set_ylabel('Cumulative Return (%)')
        axes[0].grid(True, alpha=0.3)
        axes[0].axhline(y=0, color='k', linewidth=0.5)

        # z-score ì¶”ì 
        zScore = numUnits.iloc[lookback:]
        axes[1].plot(zScore.index, zScore.values, 'r-', linewidth=0.5, alpha=0.7)
        axes[1].set_title('Portfolio Z-Score', fontsize=14)
        axes[1].set_ylabel('Z-Score')
        axes[1].axhline(y=0, color='k', linewidth=0.5)
        axes[1].axhline(y=1, color='gray', linewidth=0.5, linestyle='--')
        axes[1].axhline(y=-1, color='gray', linewidth=0.5, linestyle='--')
        axes[1].grid(True, alpha=0.3)

        plt.tight_layout()
        fig_path = FIGURES_DIR / "ch4_index_arbitrage.png"
        plt.savefig(fig_path, dpi=150, bbox_inches='tight')
        plt.close()
        self.figures.append(('ch4_index_arbitrage.png', 'SPY ì¸ë±ìŠ¤ ì°¨ìµê±°ë˜ ëˆ„ì  ìˆ˜ìµë¥ '))
        print(f"  âœ“ ì°¨íŠ¸ ì €ì¥: {fig_path.name}")
        print()

    def analyze_cross_sectional_mean_reversion(self):
        """ì˜ˆì œ 4.3: íš¡ë‹¨ë©´ ì„ í˜• ë¡±-ìˆ ëª¨ë¸

        Khandani & Loì˜ ì„ í˜• ë¡±-ìˆ ëª¨ë¸. ê° ì£¼ì‹ì˜ ì¼ì¼ ìˆ˜ìµë¥ ì—ì„œ
        ì‹œì¥ í‰ê·  ìˆ˜ìµë¥ ì„ ë¹¼ê³ , ì´ë¥¼ ì—­ë°©í–¥ìœ¼ë¡œ íˆ¬ì.
        """
        print("=" * 60)
        print("ğŸ“ˆ ë¶„ì„ 3: íš¡ë‹¨ë©´ ì„ í˜• ë¡±-ìˆ ëª¨ë¸ (ì˜ˆì œ 4.3)")
        print("=" * 60)

        # 2007-01-02 ~ 2011-12-30 í•„í„°ë§
        mask = (self.cl.index >= '2007-01-03') & (self.cl.index <= '2011-12-30')
        cl = self.cl.loc[mask].copy()
        op = self.op.loc[mask].copy()

        # === Close-to-Close ì „ëµ (ì˜ˆì œ 4.3) ===
        print("\n  [Close-to-Close ì „ëµ]")
        ret = cl.pct_change()

        # ì‹œì¥ ìˆ˜ìµë¥  (ë™ì¼ ê°€ì¤‘ í‰ê· )
        marketRet = ret.mean(axis=1)

        # ê°€ì¤‘ì¹˜: -(ê°œë³„ìˆ˜ìµë¥  - ì‹œì¥ìˆ˜ìµë¥ ), ì •ê·œí™”
        weights = -(ret.subtract(marketRet, axis=0))
        abs_sum = weights.abs().sum(axis=1)
        abs_sum = abs_sum.replace(0, np.nan)
        weights = weights.div(abs_sum, axis=0)
        weights = weights.fillna(0)

        # ì¼ì¼ ìˆ˜ìµë¥ 
        dailyret = (weights.shift(1) * ret).sum(axis=1)
        dailyret = dailyret.iloc[1:]  # ì²« ë‚  ì œê±°
        dailyret = dailyret.fillna(0)

        cumret_c2c = (1 + dailyret).cumprod() - 1
        apr_c2c = (1 + dailyret).prod() ** (252 / len(dailyret)) - 1
        sharpe_c2c = np.sqrt(252) * dailyret.mean() / dailyret.std() if dailyret.std() > 0 else 0
        maxDD_c2c, maxDDD_c2c, _ = calculateMaxDD(cumret_c2c)

        print(f"    APR = {apr_c2c:.4f} ({apr_c2c*100:.2f}%)")
        print(f"    Sharpe = {sharpe_c2c:.4f}")
        print(f"    Max DD = {maxDD_c2c:.4f} ({maxDD_c2c*100:.2f}%)")

        # === Intraday ì „ëµ (ì˜ˆì œ 4.4) - ì˜¤ë²„ë‚˜ì´íŠ¸ ìˆ˜ìµë¥ ë¡œ ê°€ì¤‘ì¹˜ ê²°ì • ===
        print("\n  [Intraday ì „ëµ (Close-to-Open -> Open-to-Close)]")
        retC2O = (op - cl.shift(1)) / cl.shift(1)
        marketRetC2O = retC2O.mean(axis=1)

        weights_intra = -(retC2O.subtract(marketRetC2O, axis=0))
        abs_sum_intra = weights_intra.abs().sum(axis=1)
        abs_sum_intra = abs_sum_intra.replace(0, np.nan)
        weights_intra = weights_intra.div(abs_sum_intra, axis=0)
        weights_intra = weights_intra.fillna(0)

        # Open-to-Close ìˆ˜ìµë¥ 
        retO2C = (cl - op) / op
        capital_intra = weights_intra.abs().sum(axis=1).replace(0, np.nan)
        dailyret_intra = (weights_intra * retO2C).sum(axis=1) / capital_intra
        dailyret_intra = dailyret_intra.iloc[1:].fillna(0)

        cumret_intra = (1 + dailyret_intra).cumprod() - 1
        apr_intra = (1 + dailyret_intra).prod() ** (252 / len(dailyret_intra)) - 1
        sharpe_intra = np.sqrt(252) * dailyret_intra.mean() / dailyret_intra.std() if dailyret_intra.std() > 0 else 0
        maxDD_intra, maxDDD_intra, _ = calculateMaxDD(cumret_intra)

        print(f"    APR = {apr_intra:.4f} ({apr_intra*100:.2f}%)")
        print(f"    Sharpe = {sharpe_intra:.4f}")
        print(f"    Max DD = {maxDD_intra:.4f} ({maxDD_intra*100:.2f}%)")

        self.results['crossSectional'] = {
            'c2c': {
                'apr': apr_c2c,
                'sharpe': sharpe_c2c,
                'maxDD': maxDD_c2c,
                'maxDDD': maxDDD_c2c,
            },
            'intraday': {
                'apr': apr_intra,
                'sharpe': sharpe_intra,
                'maxDD': maxDD_intra,
                'maxDDD': maxDDD_intra,
            }
        }

        # ì—°ë„ë³„ ì„±ê³¼ ë¶„ì„
        print("\n  [ì—°ë„ë³„ ì„±ê³¼ ë¹„êµ]")
        print(f"    {'ì—°ë„':<8} {'C2C APR':>10} {'C2C Sharpe':>12} {'Intra APR':>12} {'Intra Sharpe':>14}")
        print(f"    {'-'*56}")

        yearly_results = {}
        for year in sorted(dailyret.index.year.unique()):
            yr_mask = dailyret.index.year == year
            yr_ret = dailyret[yr_mask]
            yr_apr = (1 + yr_ret).prod() ** (252/len(yr_ret)) - 1
            yr_sharpe = np.sqrt(252) * yr_ret.mean() / yr_ret.std() if yr_ret.std() > 0 else 0

            yr_mask_i = dailyret_intra.index.year == year
            yr_ret_i = dailyret_intra[yr_mask_i]
            yr_apr_i = (1 + yr_ret_i).prod() ** (252/len(yr_ret_i)) - 1 if len(yr_ret_i) > 0 else 0
            yr_sharpe_i = np.sqrt(252) * yr_ret_i.mean() / yr_ret_i.std() if len(yr_ret_i) > 0 and yr_ret_i.std() > 0 else 0

            yearly_results[year] = {
                'c2c_apr': yr_apr, 'c2c_sharpe': yr_sharpe,
                'intra_apr': yr_apr_i, 'intra_sharpe': yr_sharpe_i
            }
            print(f"    {year:<8} {yr_apr*100:>9.2f}% {yr_sharpe:>11.2f} {yr_apr_i*100:>11.2f}% {yr_sharpe_i:>13.2f}")

        self.results['crossSectional']['yearly'] = yearly_results

        # ì°¨íŠ¸ ìƒì„±
        fig, axes = plt.subplots(2, 1, figsize=(12, 8))

        axes[0].plot(cumret_c2c.index, cumret_c2c.values * 100, 'b-', linewidth=1, label='Close-to-Close')
        axes[0].set_title('Cross-Sectional Mean Reversion: Close-to-Close (Example 4.3)', fontsize=14)
        axes[0].set_ylabel('Cumulative Return (%)')
        axes[0].grid(True, alpha=0.3)
        axes[0].legend()

        axes[1].plot(cumret_intra.index, cumret_intra.values * 100, 'r-', linewidth=1, label='Intraday (C2O -> O2C)')
        axes[1].set_title('Cross-Sectional Mean Reversion: Intraday (Example 4.4)', fontsize=14)
        axes[1].set_ylabel('Cumulative Return (%)')
        axes[1].grid(True, alpha=0.3)
        axes[1].legend()

        plt.tight_layout()
        fig_path = FIGURES_DIR / "ch4_cross_sectional.png"
        plt.savefig(fig_path, dpi=150, bbox_inches='tight')
        plt.close()
        self.figures.append(('ch4_cross_sectional.png', 'íš¡ë‹¨ë©´ í‰ê·  íšŒê·€ ì „ëµ ë¹„êµ'))
        print(f"\n  âœ“ ì°¨íŠ¸ ì €ì¥: {fig_path.name}")
        print()

    def analyze_pead(self):
        """PEAD (Post-Earnings Announcement Drift) ë¶„ì„

        ì–´ë‹ ë°œí‘œì¼ì— ê°­ì´ í° ì£¼ì‹ì— ëŒ€í•´ ì¼ì¤‘ ëª¨ë©˜í…€ í¬ì§€ì…˜.
        """
        print("=" * 60)
        print("ğŸ“ˆ ë¶„ì„ 4: ì‹¤ì  ë°œí‘œ í›„ í‘œë¥˜ (PEAD)")
        print("=" * 60)

        if self.earnann is None:
            print("  âœ— ì–´ë‹ ë°œí‘œ ë°ì´í„°ê°€ ì—†ì–´ ë¶„ì„ì„ ê±´ë„ˆëœë‹ˆë‹¤")
            self.results['pead'] = None
            print()
            return

        # ê³µí†µ ë‚ ì§œì™€ ì£¼ì‹
        common_dates = self.cl.index.intersection(self.earnann.index)
        common_stocks = [s for s in self.cl.columns if s in self.earnann.columns]

        cl = self.cl.loc[common_dates, common_stocks]
        op = self.op.loc[common_dates, common_stocks]
        earnann = self.earnann.loc[common_dates, common_stocks]

        print(f"  ê³µí†µ ë°ì´í„°: {len(common_dates)} ê±°ë˜ì¼ x {len(common_stocks)} ì£¼ì‹")

        lookback = 90
        maxPositions = 30

        # Close-to-Open ìˆ˜ìµë¥ 
        retC2O = (op - cl.shift(1)) / cl.shift(1)

        # 90ì¼ ë¡¤ë§ í‘œì¤€í¸ì°¨
        stdC2O = retC2O.rolling(lookback).std()

        # ì–´ë‹ ë°œí‘œì¼ì— ê°­ì´ í° ì£¼ì‹
        longs = (retC2O >= 0.5 * stdC2O) & (earnann == 1)
        shorts = (retC2O <= -0.5 * stdC2O) & (earnann == 1)

        # Open-to-Close ìˆ˜ìµë¥ 
        retO2C = (cl - op) / op

        # í¬ì§€ì…˜ ë° PnL
        positions = pd.DataFrame(0.0, index=cl.index, columns=cl.columns)
        positions[longs] = 1
        positions[shorts] = -1

        pnl = (positions * retO2C).sum(axis=1) / maxPositions
        pnl = pnl.iloc[lookback:]  # ë¡¤ë§ ìœˆë„ìš° ì´í›„

        cumret = (1 + pnl).cumprod() - 1

        apr = (1 + pnl).prod() ** (252 / len(pnl)) - 1
        sharpe = np.sqrt(252) * pnl.mean() / pnl.std() if pnl.std() > 0 else 0
        maxDD, maxDDD, _ = calculateMaxDD(cumret)

        # ì¼ë³„ í¬ì§€ì…˜ ìˆ˜
        daily_positions = (positions.abs().sum(axis=1)).iloc[lookback:]
        avg_positions = daily_positions[daily_positions > 0].mean() if (daily_positions > 0).any() else 0

        self.results['pead'] = {
            'apr': apr,
            'sharpe': sharpe,
            'maxDD': maxDD,
            'maxDDD': maxDDD,
            'avg_positions': avg_positions,
        }

        print(f"  APR = {apr:.4f} ({apr*100:.2f}%)")
        print(f"  Sharpe = {sharpe:.4f}")
        print(f"  Max DD = {maxDD:.4f} ({maxDD*100:.2f}%)")
        print(f"  Max DD Duration = {maxDDD:.0f} ì¼")
        print(f"  í‰ê·  ë™ì‹œ í¬ì§€ì…˜ ìˆ˜ = {avg_positions:.1f}")

        # ì°¨íŠ¸ ìƒì„±
        fig, ax = plt.subplots(1, 1, figsize=(12, 5))
        ax.plot(cumret.index, cumret.values * 100, 'g-', linewidth=1)
        ax.set_title('Post-Earnings Announcement Drift (PEAD) - Cumulative Returns', fontsize=14)
        ax.set_ylabel('Cumulative Return (%)')
        ax.grid(True, alpha=0.3)
        ax.axhline(y=0, color='k', linewidth=0.5)

        plt.tight_layout()
        fig_path = FIGURES_DIR / "ch4_pead.png"
        plt.savefig(fig_path, dpi=150, bbox_inches='tight')
        plt.close()
        self.figures.append(('ch4_pead.png', 'PEAD ì „ëµ ëˆ„ì  ìˆ˜ìµë¥ '))
        print(f"  âœ“ ì°¨íŠ¸ ì €ì¥: {fig_path.name}")
        print()

    def generate_report(self):
        """ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("=" * 60)
        print("ğŸ“ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
        print("=" * 60)

        report = []
        report.append("# Chapter 4: ì£¼ì‹ê³¼ ETFì˜ í‰ê·  íšŒê·€ (Mean Reversion of Stocks and ETFs)")
        report.append(f"\n> ë¶„ì„ ì‹¤í–‰ì¼: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")

        # 1. ê°œìš”
        report.append("## 1. ê°œìš” ë° ë¬¸ì œ ì •ì˜\n")
        report.append("Chapter 4ëŠ” ì£¼ì‹ê³¼ ETF ì‹œì¥ì—ì„œì˜ í‰ê·  íšŒê·€ ì „ëµì„ ë‹¤ë£¬ë‹¤. í•µì‹¬ ì§ˆë¬¸:")
        report.append("- ê°œë³„ ì£¼ì‹ì˜ í˜ì–´ íŠ¸ë ˆì´ë”©ì€ ì™œ ì–´ë ¤ìš´ê°€?")
        report.append("- ETFì™€ êµ¬ì„± ì£¼ì‹ ê°„ ì°¨ìµê±°ë˜ëŠ” ì–´ë–»ê²Œ êµ¬í˜„í•˜ëŠ”ê°€?")
        report.append("- íš¡ë‹¨ë©´(cross-sectional) í‰ê·  íšŒê·€ ì „ëµì˜ ì›ë¦¬ì™€ ì„±ê³¼ëŠ”?\n")
        report.append("### í•µì‹¬ ìˆ˜í•™ì  ê°œë…\n")
        report.append("**íš¡ë‹¨ë©´ ì„ í˜• ë¡±-ìˆ ê°€ì¤‘ì¹˜ (ì‹ 4.1):**\n")
        report.append("$$w_i = -\\frac{r_i - \\langle r_j \\rangle}{\\sum_k |r_k - \\langle r_j \\rangle|}$$\n")
        report.append("ì—¬ê¸°ì„œ $r_i$ëŠ” $i$ë²ˆì§¸ ì£¼ì‹ì˜ ì¼ì¼ ìˆ˜ìµë¥ , $\\langle r_j \\rangle$ëŠ” ìœ ë‹ˆë²„ìŠ¤ ë‚´ ëª¨ë“  ì£¼ì‹ì˜ í‰ê·  ì¼ì¼ ìˆ˜ìµë¥ ì´ë‹¤.")
        report.append("ë¶„ëª¨ì˜ ì •ê·œí™” ê³„ìˆ˜ë¡œ ì¸í•´ ë§¤ì¼ ë™ì¼í•œ ì´ ìë³¸($1)ì„ íˆ¬ìí•œë‹¤.\n")
        report.append("**ì‹œê³„ì—´ vs íš¡ë‹¨ë©´ í‰ê·  íšŒê·€ì˜ ì°¨ì´:**")
        report.append("- **ì‹œê³„ì—´ í‰ê·  íšŒê·€**: ê°€ê²©ì´ ìê¸° ê³¼ê±° í‰ê· ìœ¼ë¡œ íšŒê·€")
        report.append("- **íš¡ë‹¨ë©´ í‰ê·  íšŒê·€**: ìƒëŒ€ ìˆ˜ìµë¥ ì˜ ì§ë ¬ ì—­ìƒê´€ì— ì˜ì¡´. ìœ ë‹ˆë²„ìŠ¤ ëŒ€ë¹„ ìƒëŒ€ì  ì„±ê³¼ê°€ ë°˜ì „\n")

        # 2. ì‚¬ìš© ë°ì´í„°
        report.append("## 2. ì‚¬ìš© ë°ì´í„°\n")
        report.append("| íŒŒì¼ëª… | ë‚´ìš© | ì»¬ëŸ¼ ìˆ˜ | ê¸°ê°„ | ìš©ë„ |")
        report.append("|--------|------|---------|------|------|")
        report.append("| `inputDataOHLCDaily_20120424_cl.csv` | S&P 500 ì¼ì¼ ì¢…ê°€ | 498 | 2006-05~2012-04 | ëª¨ë“  ì „ëµ |")
        report.append("| `inputDataOHLCDaily_20120424_op.csv` | S&P 500 ì¼ì¼ ì‹œê°€ | 498 | 2006-05~2012-04 | BoG, ì¼ì¤‘ ì „ëµ |")
        report.append("| `inputDataOHLCDaily_20120424_hi.csv` | S&P 500 ì¼ì¼ ê³ ê°€ | 498 | 2006-05~2012-04 | BoG |")
        report.append("| `inputDataOHLCDaily_20120424_lo.csv` | S&P 500 ì¼ì¼ ì €ê°€ | 498 | 2006-05~2012-04 | BoG |")
        report.append("| `inputDataOHLCDaily_20120424_stocks.csv` | ì£¼ì‹ í‹°ì»¤ëª… | 497 | - | ì»¬ëŸ¼ëª… ë§¤í•‘ |")
        report.append("| `inputData_ETF_cl.csv` | 67ê°œ ETF ì¼ì¼ ì¢…ê°€ | 68 | 2006-04~2012-04 | ì¸ë±ìŠ¤ ì°¨ìµê±°ë˜ |")
        report.append("| `inputData_ETF_stocks.csv` | ETF í‹°ì»¤ëª… | 67 | - | ì»¬ëŸ¼ëª… ë§¤í•‘ |")
        report.append("| `earnannFile.csv` | ì–´ë‹ ë°œí‘œ í”Œë˜ê·¸ | 498 | 2011~ | PEAD ì „ëµ |\n")
        report.append("**ë°ì´í„° íŠ¹ì„±**: S&P 500 êµ¬ì„± ì£¼ì‹ ì•½ 497ê°œì˜ ì¼ì¼ OHLC ë°ì´í„°. ìƒì¡´ì í¸í–¥(survivorship bias)ì´ ìˆìŒì— ìœ ì˜.\n")

        # 3. ë¶„ì„ 1: Buy-on-Gap
        report.append("## 3. ë¶„ì„ 1: Buy-on-Gap ëª¨ë¸ (ì˜ˆì œ 4.1)\n")
        report.append("### ì „ëµ ì›ë¦¬\n")
        report.append("ì£¼ê°€ ì§€ìˆ˜ ì„ ë¬¼ì´ ê°œì¥ ì „ í•˜ë½í•˜ëŠ” ë‚ , íŠ¹ì • ì£¼ì‹ì´ íŒ¨ë‹‰ ì…€ë§ìœ¼ë¡œ ê³¼ë„í•˜ê²Œ í•˜ë½í•œë‹¤.")
        report.append("ì´ íŒ¨ë‹‰ì´ ëë‚˜ë©´ ì£¼ì‹ì€ í•˜ë£¨ ë™ì•ˆ ì ì°¨ ìƒìŠ¹í•˜ëŠ” ì¼ì¤‘ í‰ê·  íšŒê·€ í˜„ìƒì„ ì´ìš©í•œë‹¤.\n")
        report.append("**ì „ëµ ê·œì¹™:**")
        report.append("1. ì „ì¼ ì €ê°€ì—ì„œ 1 í‘œì¤€í¸ì°¨(90ì¼) ì´ìƒ ê°­ë‹¤ìš´í•œ ì£¼ì‹ì„ ì„ íƒ")
        report.append("2. ì‹œê°€ê°€ 20ì¼ ì´ë™í‰ê· ë³´ë‹¤ ë†’ì€ ì£¼ì‹ë§Œ í•„í„°ë§ (ëª¨ë©˜í…€ í•„í„°)")
        report.append("3. ê°­ì´ ê°€ì¥ í° 10ê°œ ì£¼ì‹ ë§¤ìˆ˜")
        report.append("4. ì¥ ë§ˆê° ì‹œ ì²­ì‚°\n")
        report.append("**ëª¨ë©˜í…€ í•„í„°ì˜ ì¤‘ìš”ì„±**: ì‹œê°€ > 20ì¼ MA ì¡°ê±´ì€ ì¥ê¸° í•˜ë½ ì¶”ì„¸ì— ìˆëŠ” ì£¼ì‹(ë¶€ì •ì  ë‰´ìŠ¤)ì„")
        report.append("ê±¸ëŸ¬ë‚´ê³ , ì¼ì‹œì  ìœ ë™ì„± ìˆ˜ìš”ë¡œ ì¸í•œ í•˜ë½ë§Œ í¬ì°©í•œë‹¤.\n")

        if 'bog' in self.results:
            r = self.results['bog']
            report.append("### ê²°ê³¼\n")
            report.append("| ì§€í‘œ | ê°’ | ì±… ê¸°ëŒ€ê°’ |")
            report.append("|------|-----|----------|")
            report.append(f"| APR | {r['apr']*100:.2f}% | 8.7% |")
            report.append(f"| Sharpe Ratio | {r['sharpe']:.4f} | 1.5 |")
            report.append(f"| Max Drawdown | {r['maxDD']*100:.2f}% | - |")
            report.append(f"| Max DD Duration | {r['maxDDD']:.0f}ì¼ | - |")
            report.append(f"| í™œì„± ê±°ë˜ì¼ | {r['active_trading_days']}/{r['total_days']} | - |")
            report.append(f"| í‰ê·  ì¢…ëª©ìˆ˜/ì¼ | {r['avg_trades_per_day']:.1f} | - |\n")
            report.append("![Buy-on-Gap ëª¨ë¸](figures/ch4_buy_on_gap.png)\n")

        # 4. ë¶„ì„ 2: ì¸ë±ìŠ¤ ì°¨ìµê±°ë˜
        report.append("## 4. ë¶„ì„ 2: SPY ì¸ë±ìŠ¤ ì°¨ìµê±°ë˜ (ì˜ˆì œ 4.2)\n")
        report.append("### ë°©ë²•ë¡ \n")
        report.append("1. **í›ˆë ¨ ë‹¨ê³„** (2007): ê° SPX ì£¼ì‹ê³¼ SPYì— ëŒ€í•´ ìš”í•œì„¼ ê³µì ë¶„ ê²€ì • ìˆ˜í–‰")
        report.append("2. ê³µì ë¶„í•˜ëŠ” ì£¼ì‹ìœ¼ë¡œ ë™ì¼ ìë³¸ ë°°ë¶„ ë¡±ì˜¨ë¦¬ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±")
        report.append("3. í¬íŠ¸í´ë¦¬ì˜¤ì™€ SPYì˜ ê³µì ë¶„ ì¬í™•ì¸")
        report.append("4. **í…ŒìŠ¤íŠ¸ ë‹¨ê³„** (2008~): 5ì¼ ë£©ë°±ì˜ ì„ í˜• í‰ê·  íšŒê·€ ì „ëµ ì ìš©\n")
        report.append("**ê³µì ë¶„ ê²€ì • ìˆ˜ì‹** (ìš”í•œì„¼ ê²€ì •):")
        report.append("$$\\Delta Y_t = \\Pi Y_{t-1} + \\epsilon_t$$")
        report.append("ì—¬ê¸°ì„œ $\\Pi = \\alpha \\beta'$, $\\beta$ëŠ” ê³µì ë¶„ ë²¡í„°(ê³ ìœ ë²¡í„°), $\\alpha$ëŠ” ì¡°ì • ì†ë„\n")

        if 'indexArb' in self.results:
            r = self.results['indexArb']
            report.append("### ê²°ê³¼\n")
            report.append(f"- SPYì™€ ê³µì ë¶„í•˜ëŠ” ì£¼ì‹: **{r.get('coint_count', 'N/A')}**ê°œ")
            if 'evec' in r:
                report.append(f"- ê³ ìœ ë²¡í„°: [{r['evec'][0]:.4f}, {r['evec'][1]:.4f}]\n")
            report.append("| ì§€í‘œ | ê°’ | ì±… ê¸°ëŒ€ê°’ |")
            report.append("|------|-----|----------|")
            report.append(f"| APR | {r['apr']*100:.2f}% | 4.5% |")
            report.append(f"| Sharpe Ratio | {r['sharpe']:.4f} | 1.3 |")
            report.append(f"| Max Drawdown | {r['maxDD']*100:.2f}% | - |")
            report.append(f"| Max DD Duration | {r['maxDDD']:.0f}ì¼ | - |\n")
            report.append("![SPY ì¸ë±ìŠ¤ ì°¨ìµê±°ë˜](figures/ch4_index_arbitrage.png)\n")

        # 5. ë¶„ì„ 3: íš¡ë‹¨ë©´ í‰ê·  íšŒê·€
        report.append("## 5. ë¶„ì„ 3: íš¡ë‹¨ë©´ ì„ í˜• ë¡±-ìˆ ëª¨ë¸ (ì˜ˆì œ 4.3, 4.4)\n")
        report.append("### ì „ëµ ì›ë¦¬\n")
        report.append("Khandani & Lo (2007)ê°€ ì œì•ˆí•œ ì „ëµ. ë§¤ì¼ ê° ì£¼ì‹ì˜ ìˆ˜ìµë¥ ì—ì„œ ì‹œì¥ í‰ê· ì„ ë¹¼ê³ ,")
        report.append("ì´ ìƒëŒ€ ìˆ˜ìµë¥ ì„ ì—­ë°©í–¥ìœ¼ë¡œ íˆ¬ìí•œë‹¤.\n")
        report.append("$$w_i = -\\frac{r_i - \\langle r_j \\rangle}{\\sum_k |r_k - \\langle r_j \\rangle|}$$\n")
        report.append("**íŠ¹ì§•**: ì™„ì „íˆ ì„ í˜•, ë§¤ê°œë³€ìˆ˜ ì—†ìŒ, ë‹¬ëŸ¬ ì¤‘ë¦½. 2008ë…„ ë¦¬ë¨¼ ìœ„ê¸°ì—ì„œë„ ì–‘ì˜ ìˆ˜ìµ.\n")
        report.append("**ë‘ ê°€ì§€ ë³€í˜•:**")
        report.append("- **Close-to-Close (ì˜ˆì œ 4.3)**: ì „ì¼ ì¢…ê°€â†’ë‹¹ì¼ ì¢…ê°€ ìˆ˜ìµë¥ ë¡œ ê°€ì¤‘ì¹˜ ê²°ì •")
        report.append("- **Intraday (ì˜ˆì œ 4.4)**: ì „ì¼ ì¢…ê°€â†’ë‹¹ì¼ ì‹œê°€ ìˆ˜ìµë¥ ë¡œ ê°€ì¤‘ì¹˜, ì‹œê°€â†’ì¢…ê°€ë¡œ ìˆ˜ìµ ì‹¤í˜„\n")

        if 'crossSectional' in self.results:
            cs = self.results['crossSectional']
            c = cs['c2c']
            i = cs['intraday']

            report.append("### ì „ì²´ ê¸°ê°„ ì„±ê³¼ ë¹„êµ\n")
            report.append("| ì§€í‘œ | Close-to-Close | Intraday | ì±… ê¸°ëŒ€ê°’ (C2C) | ì±… ê¸°ëŒ€ê°’ (Intra) |")
            report.append("|------|---------------|----------|---------------|-----------------|")
            report.append(f"| APR | {c['apr']*100:.2f}% | {i['apr']*100:.2f}% | 13.7% | 73% |")
            report.append(f"| Sharpe | {c['sharpe']:.4f} | {i['sharpe']:.4f} | 1.3 | 4.7 |")
            report.append(f"| Max DD | {c['maxDD']*100:.2f}% | {i['maxDD']*100:.2f}% | - | - |")
            report.append(f"| Max DDD | {c['maxDDD']:.0f}ì¼ | {i['maxDDD']:.0f}ì¼ | - | - |\n")

            if 'yearly' in cs:
                report.append("### ì—°ë„ë³„ ì„±ê³¼\n")
                report.append("| ì—°ë„ | C2C APR | C2C Sharpe | Intraday APR | Intraday Sharpe |")
                report.append("|------|---------|-----------|-------------|----------------|")
                for year, yr in sorted(cs['yearly'].items()):
                    report.append(f"| {year} | {yr['c2c_apr']*100:.2f}% | {yr['c2c_sharpe']:.2f} | {yr['intra_apr']*100:.2f}% | {yr['intra_sharpe']:.2f} |")
                report.append("")

            report.append("![íš¡ë‹¨ë©´ í‰ê·  íšŒê·€](figures/ch4_cross_sectional.png)\n")

        # 6. ë¶„ì„ 4: PEAD
        if self.results.get('pead') is not None:
            report.append("## 6. ë¶„ì„ 4: ì‹¤ì  ë°œí‘œ í›„ í‘œë¥˜ (PEAD)\n")
            report.append("### ì „ëµ ì›ë¦¬\n")
            report.append("ì–´ë‹ ë°œí‘œì¼ì— ì¢…ê°€â†’ì‹œê°€ ê°­ì´ 90ì¼ í‘œì¤€í¸ì°¨ì˜ 0.5ë°°ë¥¼ ì´ˆê³¼í•˜ë©´ ë¡±,")
            report.append("-0.5ë°° ë¯¸ë§Œì´ë©´ ìˆ. ë‹¹ì¼ ì¢…ê°€ì— ì²­ì‚°í•˜ëŠ” ì¼ì¤‘ ì „ëµ.\n")

            r = self.results['pead']
            report.append("### ê²°ê³¼\n")
            report.append("| ì§€í‘œ | ê°’ | ì±… ê¸°ëŒ€ê°’ |")
            report.append("|------|-----|----------|")
            report.append(f"| APR | {r['apr']*100:.2f}% | 6.8% |")
            report.append(f"| Sharpe Ratio | {r['sharpe']:.4f} | 1.49 |")
            report.append(f"| Max Drawdown | {r['maxDD']*100:.2f}% | -2.6% |")
            report.append(f"| Max DD Duration | {r['maxDDD']:.0f}ì¼ | 109 |")
            report.append(f"| í‰ê·  ë™ì‹œ í¬ì§€ì…˜ | {r['avg_positions']:.1f} | - |\n")
            report.append("![PEAD ì „ëµ](figures/ch4_pead.png)\n")

        # 7. ì „ëµ ì¢…í•© ë¹„êµ
        report.append("## 7. ì „ëµ ì¢…í•© ë¹„êµ\n")
        report.append("| ì „ëµ | APR | Sharpe | Max DD | íŠ¹ì„± |")
        report.append("|------|-----|--------|--------|------|")

        if 'bog' in self.results:
            r = self.results['bog']
            report.append(f"| Buy-on-Gap | {r['apr']*100:.2f}% | {r['sharpe']:.2f} | {r['maxDD']*100:.2f}% | ì¼ì¤‘, ë¡±ì˜¨ë¦¬ |")

        if 'indexArb' in self.results:
            r = self.results['indexArb']
            report.append(f"| SPY Index Arb | {r['apr']*100:.2f}% | {r['sharpe']:.2f} | {r['maxDD']*100:.2f}% | ì¼ê°„, ë¡±-ìˆ |")

        if 'crossSectional' in self.results:
            c = self.results['crossSectional']['c2c']
            i = self.results['crossSectional']['intraday']
            report.append(f"| Linear L/S (C2C) | {c['apr']*100:.2f}% | {c['sharpe']:.2f} | {c['maxDD']*100:.2f}% | ì¼ê°„, ë‹¬ëŸ¬ ì¤‘ë¦½ |")
            report.append(f"| Linear L/S (Intra) | {i['apr']*100:.2f}% | {i['sharpe']:.2f} | {i['maxDD']*100:.2f}% | ì¼ì¤‘, ë‹¬ëŸ¬ ì¤‘ë¦½ |")

        if self.results.get('pead') is not None:
            r = self.results['pead']
            report.append(f"| PEAD | {r['apr']*100:.2f}% | {r['sharpe']:.2f} | {r['maxDD']*100:.2f}% | ì¼ì¤‘, ì´ë²¤íŠ¸ ê¸°ë°˜ |")
        report.append("")

        # 8. ê²°ë¡ 
        report.append("## 8. ê²°ë¡  ë° ê¶Œê³ ì‚¬í•­\n")
        report.append("### í•µì‹¬ ë°œê²¬\n")
        report.append("1. **ê°œë³„ ì£¼ì‹ í˜ì–´ íŠ¸ë ˆì´ë”©ì˜ í•œê³„**: ê¸°ì—… í€ë”ë©˜í„¸ ë³€í™”ë¡œ ê³µì ë¶„ ê´€ê³„ê°€ ë¬´ë„ˆì§ˆ ìœ„í—˜ì´ ë†’ë‹¤")
        report.append("2. **ETF ê¸°ë°˜ ì „ëµì˜ ì•ˆì •ì„±**: ETFëŠ” ë°”ìŠ¤ì¼“ ê²½ì œ ë³€í™”ê°€ ëŠë ¤ ê³µì ë¶„ ê´€ê³„ê°€ ë” ì•ˆì •ì ")
        report.append("3. **íš¡ë‹¨ë©´ ì „ëµì˜ ê°•ê±´ì„±**: Khandani-Lo ëª¨ë¸ì€ ë§¤ê°œë³€ìˆ˜ ì—†ì´ë„ ì•ˆì •ì  ìˆ˜ìµ ë‹¬ì„±")
        report.append("4. **ì¼ì¤‘ ì „ëµì˜ ë†’ì€ ì„±ê³¼**: ì‹œê°€-ì¢…ê°€ ì „ëµì´ ì¢…ê°€-ì¢…ê°€ë³´ë‹¤ ì›”ë“±íˆ ë†’ì€ ìˆ˜ìµë¥ \n")
        report.append("### íŠ¸ë ˆì´ë”© ê¶Œê³ \n")
        report.append("- í‰ê·  íšŒê·€ ì „ëµì— **ëª¨ë©˜í…€ í•„í„°**ë¥¼ ì¤‘ì²©í•˜ë©´ ì¼ê´€ì„± í–¥ìƒ")
        report.append("- íš¡ë‹¨ë©´ ì „ëµì—ì„œ **ì†Œí˜•ì£¼ ìœ ë‹ˆë²„ìŠ¤**ë¥¼ ì‚¬ìš©í•˜ë©´ ë” ë†’ì€ ìˆ˜ìµë¥  ê¸°ëŒ€ ê°€ëŠ¥")
        report.append("- ì¸ë±ìŠ¤ ì°¨ìµê±°ë˜ëŠ” **ì£¼ê¸°ì  ì¬í›ˆë ¨**ì´ í•„ìˆ˜ì \n")
        report.append("### ì£¼ì˜ì‚¬í•­\n")
        report.append("- **ìƒì¡´ì í¸í–¥**: ì‚¬ìš©ëœ S&P 500 ë°ì´í„°ì— ìƒì¡´ì í¸í–¥ ì¡´ì¬")
        report.append("- **ê±°ë˜ë¹„ìš©**: ëª¨ë“  ë°±í…ŒìŠ¤íŠ¸ì— ê±°ë˜ë¹„ìš© ë¯¸í¬í•¨. íŠ¹íˆ ì¼ì¤‘ ì „ëµì€ ê±°ë˜ë¹„ìš© 2ë°°")
        report.append("- **ì‹œê·¸ë„ ë…¸ì´ì¦ˆ**: ì‹œê°€ ê¸°ë°˜ ì§„ì… ì‹œ ì‚¬ì „ê°œì¥ ê°€ê²©ê³¼ ì‹¤ì œ ì‹œê°€ì˜ ì°¨ì´")
        report.append("- **ê³µë§¤ë„ ì œì•½**: ìˆ í¬ì§€ì…˜ì˜ Alternative Uptick Rule, NBBO ê·œëª¨ ì œí•œ")
        report.append("- **ìŠ¬ë¦¬í”¼ì§€**: í†µí•© ê°€ê²© vs ê¸°ë³¸ ê±°ë˜ì†Œ ê°€ê²© ì°¨ì´ë¡œ ì¸í•œ ë°±í…ŒìŠ¤íŠ¸ ê³¼ëŒ€í‰ê°€ ê°€ëŠ¥ì„±\n")

        # ë¦¬í¬íŠ¸ ì €ì¥
        report_path = REPORT_DIR / "chapter4_report.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write('\n'.join(report))

        print(f"  âœ“ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")
        print()

    def run(self):
        """ì „ì²´ ë¶„ì„ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜"""
        print("\n" + "ğŸ”¬" * 30)
        print("  Chapter 4: ì£¼ì‹ê³¼ ETFì˜ í‰ê·  íšŒê·€ - ì¢…í•© ë¶„ì„")
        print("ğŸ”¬" * 30 + "\n")

        self.load_data()
        self.analyze_buy_on_gap()
        self.analyze_index_arbitrage()
        self.analyze_cross_sectional_mean_reversion()
        self.analyze_pead()
        self.generate_report()

        print("=" * 60)
        print("âœ… Chapter 4 ë¶„ì„ ì™„ë£Œ!")
        print(f"   ë¦¬í¬íŠ¸: reports/chapter4_report.md")
        print(f"   ì°¨íŠ¸: {len(self.figures)}ê°œ ìƒì„±")
        for fig_name, fig_desc in self.figures:
            print(f"     - {fig_name}: {fig_desc}")
        print("=" * 60)


if __name__ == "__main__":
    analyzer = Chapter4Analyzer()
    analyzer.run()
