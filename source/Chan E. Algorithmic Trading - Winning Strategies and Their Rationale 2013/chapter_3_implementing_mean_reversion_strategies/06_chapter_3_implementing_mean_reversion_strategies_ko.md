# 평균 회귀 전략 구현하기 (Implementing Mean Reversion Strategies)

이전 장에서 가격 시계열이 정상적(stationary)인지, 따라서 평균 회귀 거래에 적합한지 결정하기 위한 통계적 검정을 설명했다. 이 가격 시계열은 단일 자산의 시장 가치일 수 있지만, 그러한 정상 자산이 존재하는 경우는 드물다. 또는 익숙한 롱-숏 주식 페어와 같은 공적분 자산 포트폴리오의 시장 가치일 수 있다.

그러나 실제로는 성공적인 평균 회귀 전략을 구현하기 위해 반드시 진정한 정상성이나 공적분이 필요하지 않다는 것을 기억해야 한다: 영리하다면, 단기 또는 계절적 평균 회귀를 포착하고, 가격이 다음 균형 수준으로 가기 전에 포지션을 청산할 수 있다. (계절적 평균 회귀란 가격 시계열이 하루 중 특정 기간이나 특정 조건에서만 평균 회귀한다는 것을 의미한다.) 반대로, 모든 정상 시계열이 큰 수익으로 이어지는 것은 아니다 - 평균 회귀의 반감기가 10년이라면 그렇지 않다.

우리는 또한 자산의 가격이 평균에서 벗어난 정도에 비례하여 단순히 자산에 "스케일 인(scale in)"하는 간단한 선형 평균 회귀 전략을 설명했다. 지속적인 무한소 리밸런싱과 무제한 구매력 요구로 인해 매우 실용적인 전략은 아니다. 이 장에서는 더 실용적이지만 여전히 간단한 평균 회귀 전략인 볼린저 밴드(Bollinger bands)를 논의한다. 여러 진입 및 청산 수준 사용("스케일링 인")의 장단점과 헤지 비율 및 평균 가격 추정을 위한 칼만 필터(Kalman filter) 사용을 포함한 이 기법의 변형을 설명한다. 마지막으로, 데이터 오류가 평균 회귀 전략에 미치는 위험을 강조한다.

이 책에서 어떤 전략의 백테스트를 제시할 때, 거래 비용은 포함하지 않는다. 우리는 때때로 매개변수 최적화(예: 최적의 헤지 비율 찾기)와 백테스트에 동일한 데이터를 사용함으로써 미래 예측 편향(look-ahead bias)을 도입하는 더 큰 오류를 범하기도 한다. 이것들은 모두 1장에서 경고한 함정이다. 이렇게 하는 유일한 변명은 프레젠테이션과 소스 코드를 이해하기 쉽게 만든다는 것이다. 독자들이 이러한 프로토타입 전략의 자체 백테스트를 구현할 때 이러한 함정을 정리하는 힘든 작업을 수행할 것을 권한다.

# ■ **가격 스프레드, 로그 가격 스프레드 또는 비율을 사용한 페어 트레이딩 (Trading Pairs Using Price Spreads, Log Price Spreads, or Ratios)**

2장에서 평균 회귀 거래를 위한 포트폴리오를 구성할 때, 우리는 단순히 "단위" 포트폴리오의 시장 가치를 거래 신호로 사용했다. 이 시장 가치 또는 가격은 구성 가격 시계열의 가중 합이며, 가중치는 선형 회귀 또는 요한센 검정의 고유벡터에서 찾은 헤지 비율이다:

$$y = h_1 y_1 + h_2 y_2 + \dots + h_n y_n \qquad (3.1)$$

*y*는 구조상 정상 시계열이고, $h_i$들은 각 구성 주식의 주식 수를 알려준다(주식 포트폴리오를 거래한다고 가정). 두 주식만 있는 경우, 이것은 많은 페어 트레이더에게 익숙한 스프레드로 축소된다:

$$y = y_1 - h y_2 \qquad (3.2)$$

(식 3.2에서 마이너스 기호를 삽입했는데, 이는 보통 한 주식은 롱하고 다른 주식은 숏하므로, 이렇게 정의된 $h$가 양수가 될 것이라는 사실을 예상한 것이다.) 가격 시계열 대신 가격의 로그가 공적분한다고 가정하면,

$$\log(q) = h_1 \log(y_1) + h_2 \log(y_2) + \dots + h_n \log(y_n) \qquad (3.3)$$

이 회귀 적합 또는 요한센의 고유벡터에서 도출된 어떤 $h$ 집합에 대해 정상이다. 이 방정식을 어떻게 해석해야 할까? $q$("query"의 약자)는 포트폴리오의 시장 가치일 수도 있고 아닐 수도 있는 정상 시계열에 주어진 이름일 뿐이기 때문이다. 그 속성을 알아내기 위해 시간에 대한 1차 차분을 취하자:

$$\Delta \log(q) = h_1 \Delta \log(y_1) + h_2 \Delta \log(y_2) + \dots + h_n \Delta \log(y_n) \qquad (3.4)$$

$x$의 작은 변화에 대해 $\Delta \log(x) \equiv \log(x(t)) - \log(x(t-1)) = \log(x(t)/x(t-1)) \approx \Delta x/x$임을 기억하면, 식 3.4의 우변은 $h_1 \Delta y_1/y_1 + h_2 \Delta y_2/y_2 + \dots + h_n \Delta y_n/y_n$가 되는데, 이것은 가중치 $h$를 가진 $n$개 자산으로 구성된 포트폴리오의 수익률에 다름 아니다. 그러나 식 3.1의 헤지 비율 $h$가 각 자산의 주식 수를 나타냈던 것과 달리, 여기서는 각 자산의 시장 가치를 $h$로 설정할 수 있다. 따라서 $q$를 가격이 $y_1, y_2, \dots, y_n$이고 일정한 자본 가중치가 $h_1, h_2, \dots, h_n$인 자산 포트폴리오의 시장 가치로 해석할 수 있으며, 암묵적으로 현금 구성 요소가 포함되어 있고, 이 시장 가치는 정상 시계열을 형성할 것이다. 자본 가중치 $h$가 일정하게 유지된다면, 포트폴리오의 시장 가치가 시간에 따라 변할 수 있는 다른 방법이 없기 때문에 현금 구성 요소가 포트폴리오 $q$에 암묵적으로 포함되어야 한다는 점에 유의하라. 이 현금은 식 3.4에 나타나지 않는데, 물론 시장 움직임의 결과로 $t - 1$에서 $t$로 시장 가치가 변하지 않기 때문이지만, 트레이더가 자본 가중치의 일정함을 유지하기 위해 포트폴리오를 리밸런싱하고 일부 이익이나 손실을 실현하며 현금 잔고에 추가하거나 빼면 $t$에서 그 값이 변할 것이다. 따라서 이 포트폴리오의 시장 가치를 정상적(그러나 일정하지는 않음!)으로 유지하려면 트레이더에게 많은 작업이 필요하다. 가격의 로그를 사용함으로써 필요해진 포트폴리오를 지속적으로 리밸런싱해야 하기 때문이다.

이 모든 것의 결론은 가격 스프레드를 사용한 평균 회귀 거래가 로그 가격 스프레드를 사용하는 것보다 간단하지만, 가격과 로그 가격 시계열이 모두 공적분하면 둘 다 이론적으로 정당화될 수 있다는 것이다. 그러나 많은 트레이더가 페어의 신호로 선호하는 가격 비율 $y_1/y_2$는 어떨까? 두 가격 시계열만 있는 경우 식 3.1을 보면, $h_1 = -h_2$이면 실제로 $\log(y_1/y_2)$ 또는 $y_1/y_2$가 정상임을 알 수 있다. 그러나 이것은 특수한 경우이다: 일반적으로 헤지 비율이 크기가 같거나 정규화하면 $-1$과 같을 것으로 기대하지 않는다. 따라서 비율 $y_1/y_2$가 반드시 정상 시계열을 형성하는 것은 아니다. 그러나 한 독자가 언급했듯이, 기초 페어가 진정으로 공적분하지 않을 때 비율 사용이 이점이 있을 수 있다([http://epchan.blogspot.com/2012/02/ideas-from-psychologist.html?showComment=1329801874131#c3278677864367113894](http://epchan.blogspot.com/2012/02/ideas-from-psychologist.html?showComment=1329801874131#c3278677864367113894)). 가격 A = \$10이고 가격 B = \$5라고 가정하면, 비율은 2이다. 얼마 후 가격 A가 \$100으로, 가격 B가 \$50으로 증가한다. 스프레드는 \$5에서 \$50으로 갔고, 아마도 정상이 아님을 발견할 것이다. 그러나 비율은 2로 유지되고, 비율에 기반한 평균 회귀 전략은 가격이 \$10 대 \$5이든 \$100 대 \$50이든 똑같이 효과적일 수 있다. 다시 말해, 두 자산이 실제로 공적분하지 않지만 스프레드가 단기적으로 여전히 평균 회귀한다고 믿는다면, 비율을 지표로 사용하는 것이 가격 스프레드나 로그 가격 스프레드보다 더 잘 작동할 수 있다. (이것은 선형 평균 회귀 전략에서 이동 평균과 표준 편차를 사용하는 것과 같은 아이디어이다.)

페어가 진정으로 공적분하지 않을 때 비율을 사용해야 하는 또 다른 좋은 이유가 있다. 그러한 페어의 경우, 스프레드를 구성하기 위해 동적으로 변하는 헤지 비율을 사용해야 하는 경우가 많다. 그러나 이 상황에서 비율을 신호로 사용하면 이 문제를 생략할 수 있다. 그러나 비율이 가격(또는 로그 가격) 스프레드와 적응적 헤지 비율보다 더 잘 작동할까? 이에 대한 일반적인 답은 모르지만, 예제 3.1을 볼 수 있다. 거기서 금과 원유 상장지수펀드(ETF)인 GLD와 USO를 포함하는 선형 평균 회귀 전략에서 가격 스프레드, 로그 가격 스프레드, 비율 사용을 비교한다. 적어도 그 예제에서는 적응적 헤지 비율이 있는 가격 스프레드가 비율보다 훨씬 더 잘 작동한다는 것을 알게 될 것이다.

흥미로운 특수 사례는 통화 거래이다. 통화 페어 EUR.GBP를 거래하면, EUR.USD/GBP.USD를 거래하는 것과 정확히 같기 때문에 비율을 사용하는 것이다. 우리는 이미 예제 2.5에서 USD.CAD에 대해 비율을 신호로 사용하여 이러한 통화 페어를 거래하는 간단한 평균 회귀 전략을 시연했다. 그러나 많은 중개업체나 거래소에서 기성 교차 환율이 없는 페어, 예를 들어 MXN.NOK는 어떨까? 비율 USD.NOK/USD.MXN을 신호로 사용해야 할까, 아니면 스프레드 USD.NOK-USD.MXN을 대신 사용해야 할까? 다시 말하지만, MXN.NOK가 진정으로 정상이 아니기 때문에 비율 MXN.NOK를 사용하는 것이 더 효과적일 수 있다. MXN.NOK를 직접 거래할 수 없고 대신 USD.NOK와 USD.MXN을 거래해야 하더라도 마찬가지이다. (USD.NOK와 USD.MXN을 거래하면 NOK와 MXN 모두로 표시된 손익(P&L)이 발생한다. MXN.NOK를 거래했다면 NOK로만 표시된 P&L이 발생했을 것이다. 따라서 두 방법은 동일하지 않다.)

# **예제 3.1: 가격 스프레드, 로그 가격 스프레드, 비율 거래하기 (Example 3.1: Trading Price Spread, Log Price Spread, and Ratio)**

예제 2.5와 2.8의 선형 평균 회귀 전략을 ETF GLD와 USO에 적용한다. 그러나 비교를 위해 가격 스프레드, 로그 가격 스프레드, 비율에 대해 이 전략을 시도한다.

일부 트레이더는 유가가 오르면 금 가격도 오른다고 믿는다. 논리는 높은 유가가 인플레이션을 촉진하고, 금 가격은 인플레이션과 양의 상관관계가 있다는 것이다. 그러나 2장에서 공부한 공적분 검정 중 하나를 사용하여 금(ETF GLD로 대표)과 유가(USO로 대표)가 실제로 공적분하지 않음을 확인할 수 있다. (현물 유가 대 유선물의 차이는 무시할 것이며, 이것이 실제로 USO를 구성한다. 이 차이는 5장에서 다시 다룰 것이다.) 그럼에도 불구하고, 평균 회귀 전략을 수익성 있게 만들기에 충분한 단기 평균 회귀가 있는지 살펴볼 것이다.

먼저 가격 스프레드를 신호로 사용해 볼 것이다. 그러나 시간이 지남에 따라 ETF의 변화하는 수준에 적응하기 위해 짧은 룩백 기간(사후에 근 최적인 20 거래일로 설정)을 사용하여 매일 헤지 비율을 동적으로 재계산해야 한다. 헤지 비율을 계산하는 데 사용한 방법은 이전과 마찬가지로 jplv7 패키지의 *ols* 함수를 사용한 선형 회귀이다. 물론 요한센 검정의 첫 번째 고유벡터를 대신 사용할 수도 있다.

MATLAB 소스 코드는 내 웹사이트에서 *PriceSpread.m*으로 다운로드할 수 있다. GLD의 가격 시계열이 Tx1 배열 *x*에 포함되어 있고, USO는 Tx1 배열 *y*에 포함되어 있다고 가정한다. 일반적으로 "스프레드" USO-hedgeRatio*GLD로 불리는 것은 단위 포트폴리오의 가격과 같으며, 프로그램에서 *yport*로 표시한다.

```
% lookback period for calculating the dynamically changing
 % hedge ratio
lookback=20;
hedgeRatio=NaN(size(x, 1), 1);
for t=lookback:size(hedgeRatio, 1)
    regression_result=ols(y(t-lookback+1:t), ...
     [x(t-lookback+1:t) ones(lookback, 1)]);
    hedgeRatio(t)=regression_result.beta(1);
                                                     (계속)
```

#### **예제 3.1 (***계속***)**

```
end
y2=[x y];
yport=sum([-hedgeRatio ones(size(hedgeRatio))].*y2, 2);
```

그림 3.1에서 이 스프레드를 플롯하면 매우 정상적으로 보임을 알 수 있다. 이제 수익성 있는 선형 평균 회귀 전략을 만들 수 있는지 살펴볼 것이다. 다시 한번, 우리가 소유해야 하는 단위 포트폴리오의 단위(주식) 수는 음의 Z-점수로 설정되고, Tx2 *positions* 배열은 투자해야 하는 각 구성 ETF의 시장 가치(달러)를 나타낸다.

```
numUnits=-(spread-movingAvg(spread, lookback)) ...
 ./movingStd(spread, lookback);
positions=repmat(numUnits, [1 size(y2, 2)]).*[hedgeRatio ...
 -ones(size(hedgeRatio))].*y2; pnl=sum(lag(positions, ...
 1).*(y2-lag(y2, 1))./lag(y2, 1), 2); % daily P&L of the
 % strategy
ret=pnl./sum(abs(lag(positions, 1)), 2); % return is P&L
 % divided by gross market value of portfolio
```

GLD와 USO가 결코 공적분하지 않음에도 불구하고, 동적 헤지 비율이 있는 가격 스프레드를 사용하여 약 10.9%의 연간 수익률(APR)과 약 0.59의 샤프 비율을 얻는다.

다음으로 로그 가격 사용이 어떤 차이를 만드는지 살펴볼 것이다. 이에 대한 소스 코드는 *LogPriceSpread.m*에 있지만, *PriceSpread.m*과 다른 두 줄만 여기에 표시한다:

![](_page_5_Figure_8.jpeg)

**그림 3.1**변화하는 헤지 비율을 사용한 USO와 GLD 사이의 스프레드

# ** 예제 3.1 (***계속***)**

```
regression_result=ols(log(y(t-lookback+1:t)), ...
   [log(x(t-lookback+1:t)) ones(lookback, 1)]);
and
  yport=sum([-hedgeRatio ones(size(hedgeRatio))].*log(y2), ...
   2); % The net market value of the portfolio is same as
    % the "spread"
```

APR 9%와 샤프 비율 0.5는 실제로 가격 스프레드 전략을 사용한 것보다 낮으며, 이것은 각 ETF에 대한 자본 배분을 유지하기 위해 매일 포트폴리오를 리밸런싱하는 것과 관련된 추가 거래 비용을 고려하기 전이다.

다음으로 비율을 신호로 사용해 볼 것이다. 이 경우 롱 측과 숏 측이 동일한 달러 자본을 갖도록 요구할 것이다. 소스 코드는 *Ratio.m*에 있다. 먼저 그림 3.2에서 비율의 플롯을 보는 것이 흥미롭다.

가격 스프레드나 적응적 헤지 비율과 비교할 때 비율이 실제로 그다지 정상적으로 보이지 않음을 알 수 있다. 따라서 평균 회귀 전략이 음의 APR로 저조하게 수행되더라도 놀라지 않을 것이다.

![](_page_6_Figure_7.jpeg)

**그림 3.2** 비율 = USO/GLD

(*계속*)

## **예제 3.1 (***계속***)**

```
lookback=20; % Lookback is set arbitrarily
ratio=y./x;
ratio(1:lookback)=[]; % Removed to have same test set as
 % price spread and log price spread strategies
x(1:lookback)=[];
y(1:lookback)=[];
% Apply a simple linear mean reversion strategy to GLD-USO
numUnits=-(ratio-movingAvg(ratio, lookback))...
 ./movingStd(ratio, lookback); positions=repmat(numUnits, ...
 [1 2]).*[-ones(size(x, 1), 1) ones(size(x, 1), 1)];
 pnl=sum(lag(positions, 1).*([x y]-lag([x y], 1)). ...
 /lag([x y], 1), 2); ret=pnl./sum(abs(lag(positions, 1)), 2);
```

# ■ **볼린저 밴드 (Bollinger Bands)**

지금까지 설명한 유일한 평균 회귀 전략은 선형 전략이다: 정상 단위 포트폴리오에 투자한 단위 수를 이동 평균에서 단위 포트폴리오의 시장 가치(가격) 편차에 비례하게 스케일링하기만 하면 된다. 이 간단한 전략은 사실상 매개변수가 없고, 따라서 데이터 스누핑 편향에 가장 적게 영향을 받기 때문에 선택되었다. 이 선형 전략은 주어진 포트폴리오에 대해 평균 회귀 거래가 수익성이 있는지 시연하는 데 유용하지만, 가격이 평균에서 일시적으로 편차되는 데 제한이 없기 때문에 사전에 배치될 최대 자본이 얼마인지 알 수 없어 실용적이지 않다.

실용적인 거래를 위해 볼린저 밴드를 사용할 수 있는데, 가격이 평균에서 *entryZscore* 표준 편차 이상 벗어날 때만 포지션에 진입한다. *entryZscore*는 훈련 세트에서 최적화할 자유 매개변수이며, 표준 편차와 평균 모두 룩백 기간 내에서 계산되는데, 그 길이도 최적화할 자유 매개변수이거나 평균 회귀의 반감기와 같게 설정할 수 있다. 가격이 평균에서 *exitZscore* 표준 편차로 평균 회귀할 때 청산할 수 있으며, 여기서 *exitZscore* < *entryZscore*이다. *exitZscore* = 0이면 가격이 현재 평균으로 평균 회귀할 때 청산한다는 것을 의미한다. *exitZscore* = −*entryZscore*이면 가격이 반대쪽 밴드를 넘어가서 반대 부호의 거래 신호를 유발할 때 청산한다. 언제든지 0 또는 1 단위(롱 또는 숏)가 투자될 수 있으므로 이 전략에 자본을 할당하거나 리스크를 관리하기가 매우 쉽다. 룩백을 짧은 기간으로, *entryZscore*와 *exitZscore* 크기를 작게 설정하면 보유 기간이 짧아지고 왕복 거래가 더 많아지며 일반적으로 수익이 더 높아진다. 예제 3.2에서 위에서 논의한 페어 GLD-USO를 사용하여 볼린저 밴드 기법을 설명한다.

# **예제 3.2: 볼린저 밴드 평균 회귀 전략 (Example 3.2: Bollinger Band Mean Reversion Strategy)**

예제 3.1에서 선형 평균 회귀 전략으로 가격 스프레드 USO-hedgeRatio*GLD를 신호로 사용하여 GLD-USO를 거래했다. 여기서는 *entryZscore* = 1과 *exitZscore* = 0을 사용하여 볼린저 밴드 전략으로 전환하고, 프로그램의 첫 부분은 *PriceSpread.m*과 동일하다. 현재 소스 코드는 *bollinger.m*에 있다. 진입 신호 *longsEntry*와 *shortsEntry*는 Tx1 논리 배열이며, 청산 신호 *longsExit*와 *shortsExit*도 마찬가지이다. 롱 측의 단위 포트폴리오 단위 수인 *numUnitsLong*(Tx1 배열)을 초기화한 다음, 롱 진입 신호가 있으면 값 중 하나를 1로, 롱 청산 신호가 있으면 0으로 설정한다. 숏 측의 단위 수도 마찬가지이다. 진입이나 청산 신호가 없는 날에는 *fillMissingData* 함수를 사용하여 전날의 단위를 이월한다. (*fillMissingData*는 배열의 두 번째 행부터 시작하여 셀의 NaN 값을 이전 행의 해당 셀 값으로 덮어쓴다. 내 웹사이트에서 다운로드할 수 있다.) *numUnitsLong*과 *numUnitsShort*가 계산되면, 이들을 결합하여 *numUnits*로 표시되는 순 단위 수를 찾을 수 있다. 프로그램의 나머지는 예제 3.1의 *PriceSpread.m*과 동일하다.

```
% Bollinger band strategy
entryZscore=1;
exitZscore=0;
zScore=(yport-movingAvg(yport, lookback))./movingStd(yport, ...
 lookback);
longsEntry=zScore < -entryZscore; % a long position means we
 % should buy EWC
longsExit=zScore >= -exitZscore;
shortsEntry=zScore > entryZscore;
shortsExit=zScore <= exitZscore;
numUnitsLong=NaN(length(yport), 1);
                                                      (계속)
```

## **예제 3.2 (***계속***)**```
numUnitsShort=NaN(length(yport), 1);
numUnitsLong(1)=0;
numUnitsLong(longsEntry)=1;
numUnitsLong(longsExit)=0;
numUnitsLong =fillMissingData(numUnitsLong);
numUnitsShort(1)=0;
numUnitsShort(shortsEntry)=-1;
numUnitsShort(shortsExit)=0;
numUnitsShort =fillMissingData(numUnitsShort);
numUnits= numUnitsLong + numUnitsShort;
```

볼린저 밴드 전략은 APR = 17.8%, 샤프 비율 0.96으로, 선형 평균 회귀 전략에서 상당한 개선이다! 누적 수익률 곡선은 그림 3.3에 표시되어 있다.

![](_page_9_Figure_5.jpeg)

** 그림 3.3**GLD-USO에 대한 볼린저 밴드 전략의 누적 수익률

# ■ ** 스케일링 인이 작동하는가? (Does Scaling-in Work?)**

평균 회귀 전략으로 포지션에 스케일 인(scale in)하는 개념은 많은 트레이더에게 익숙하다. (다른 이름은 *평균 매입(averaging-in)*이다.) 자산, 스프레드 또는 포트폴리오의 가격이 평균에서 점점 더 벗어날수록 최종 회귀에서 거둘 잠재적 이익도 증가하므로, 투자 자본을 늘리는 것이 합리적이다. 이것이 바로 우리의 선형 평균 회귀 전략이 하는 것이다. 또한 이러한 유형의 스케일 인 전략은 점진적으로 스케일 아웃도 한다는 점에 유의하라: 수익을 취하기 전에 가격이 평균으로 회귀할 때까지 기다릴 필요가 없다. 가격이 작은 증분만큼 회귀할 때마다 청산할 수 있는 장점은 가격 시계열이 실제로 정상이 아니어서 평균으로 결코 회귀하지 않더라도 지속적으로 작은 이익을 실현하여 여전히 수익성이 있을 수 있다는 것이다. 추가 이점은 큰 규모로 거래하는 경우 스케일 인과 아웃이 진입 및 청산 거래의 시장 영향을 줄인다는 것이다. 볼린저 밴드를 사용하여 스케일 인을 구현하려면 여러 진입과 청산을 가질 수 있다: 예를 들어, *entryZscore* = 1, 2, 3, ..., $N$ 및 *exitZscore* = 0, 1, 2, ..., $N$ − 1. 물론 *N*은 훈련 데이터 세트를 사용하여 최적화할 또 다른 매개변수이다.

이 모든 것이 쇤베르크와 코윈(Schoenberg and Corwin)의 연구가 두 개 이상의 볼린저 밴드에서 진입하거나 청산하는 것이 결코 최적이 아니라는 것을 증명할 때까지 매우 상식적으로 보였다. 즉, 백테스트에서 더 높은 평균 수익률을 생성하는 단일 진입/청산 수준을 항상 찾을 수 있다(Schoenberg and Corwin, 2010). 그들은 이 최적의 단일 진입 방법을 "올인(all-in)"이라고 부른다.

그들의 요점을 설명하기 위해, 선물 계약이 최근 가격 $L_1$으로 떨어졌고, $F > L_1$인 더 높은 최종 가격 $F$로 회귀할 것으로 예상한다고 가정하자(평균 매입 대 올인을 비교하기 위해 평균 회귀를 가정해야 한다). 그러나 가격이 $F$로 반등하기 전에 $L_2 < L_1$로 더 낮아질 확률 $p$가 있다. 이러한 가능성은 그림 3.4에 설명되어 있다. 우리는 가격 $L_1$, $L_2$ 또는 $F$에서 총 두 개의 계약에 투자할 충분한 구매력만 가지고 있다. 세 가지 다른 진입 방법을 비교해 보자:

I. $L_1$에서 올인: 가격이 $L_1$에 도달하면 $L_2$로 더 낮아질지 신경 쓰지 않고 모든 자본을 투자한다.

![](_page_10_Figure_6.jpeg)

**그림 3.4** 평균 회귀의 두 가지 가능한 경로. 경로 1(확률 *p*)은 가격이 $L_1$에서 $L_2$로 더 떨어진 후 $F$로 회귀한다. 경로 2(확률 1 − *p*)는 가격이 즉시 $F$로 회귀한다. (이 예에서는 어떤 식으로든 평균 회귀가 보장된다.)

- II. $L_2$에서 올인: 가격이 $L_2$에 도달할 때까지 기다린 후 모든 자본을 투자한다. (따라서 가격이 $L_2$에 도달하지 않으면 아무것도 투자하지 않고 수익률은 0이다.)
- III. 평균 매입: 가격이 $L_1$에 도달하면 한 계약에 투자하고, 가격이 $L_2$에 도달하면 다른 계약에 투자한다.

모든 경우에 가격이 $F$에 도달할 때만 모든 계약을 청산한다(평균 매입이 있더라도 평균 청산은 없다). 각 대안의 기대 이익은 얼마인가? 포인트 단위의 기대 이익은:

I.
$$2(F-L_1)$$

II.  $2p(F-L_2)$
III.  $p[(F-L_1) + (F-L_2)] + (1-p)(F-L_1) = (F-L_1) + p(F-L_2)$

분명히 $p = 0$이면 방법 I이 가장 수익성이 높다. $p = 1$이면 방법 II가 가장 수익성이 높다. 실제로 $\hat{p} = (F - L_1) / (F - L_2)$라는 전환 확률이 있어서 $p < \hat{p}$이면 방법 I이 II보다 수익성이 높고, $p > \hat{p}$이면 그 반대이다. $p < \hat{p}$이면 방법 I이 III보다도 수익성이 높고, $p > \hat{p}$이면 방법 II가 III보다 수익성이 높다는 것도 쉽게 보여줄 수 있다. 따라서 평균 매입 전략이 가장 수익성이 높은 상황은 없다!

그렇다면 스케일 인/평균 매입의 전체 아이디어가 무효화된 것일까? 반드시 그렇지는 않다. 내 설명에서 암묵적인 가정에 주목하라: $F$로 회귀하기 전에 $L_2$로 편차될 확률이 시간 내내 일정하다. 실제 생활에서 이 확률이 일정하다고 찾을 수도 있고 아닐 수도 있다. 사실, 변동성은 보통 일정하지 않으므로 $p$도 일정하지 않을 것이다. 이 상황에서 스케일 인은 이익이 아니더라도 더 나은 실현 샤프 비율을 초래할 가능성이 높다. 다른 방식으로 말하면, 스케일 인이 인샘플에서 결코 최적이 아님을 발견하더라도 아웃오브샘플에서는 올인 방법을 능가할 수 있다는 것이다.

# ■ **동적 선형 회귀로서의 칼만 필터 (Kalman Filter as Dynamic Linear Regression)**

진정으로 공적분하는 한 쌍의 가격 시계열에 대해 헤지 비율 결정은 꽤 쉽다: 찾을 수 있는 만큼의 과거 데이터를 가져와서 회귀 적합을 위해 최소자승법(OLS)을 사용하거나 요한센 검정을 사용하여 고유벡터를 찾으면 된다. 그러나 앞서 강조했듯이, 정상성과 공적분은 실제 가격 시계열이 거의 달성할 수 없는 이상이다. 그렇다면 시간에 따라 변할 수 있는 실제 가격 시계열 쌍에 대한 현재 헤지 비율을 어떻게 가장 잘 추정할 수 있을까? 지금까지 논의한 모든 평균 회귀 전략에서 우리는 이동 룩백 기간을 가져와 그 기간의 데이터에 대해서만 회귀 계수나 요한센 고유벡터를 계산했다. 이것은 룩백 기간이 짧으면 시간이 앞으로 이동함에 따라 가장 이른 봉의 삭제와 최신 봉의 포함이 헤지 비율에 갑작스럽고 인위적인 영향을 미칠 수 있다는 단점이 있다. 이동 평균이나 이동 표준 편차를 사용하여 가격 시계열의 현재 평균과 표준 편차를 계산할 때도 같은 문제에 직면한다. 모든 경우에, 임의의 절단점 없이 최신 데이터에 더 많은 가중치를 주고 이전 데이터에 더 적은 가중치를 주는 가중 방식을 사용하여 추정을 개선할 수 있다. 익숙한 지수이동평균(EMA)이 그러한 가중 방식 중 하나이지만, 가중치의 지수적 감소가 왜 최적인지도 명확하지 않다. 여기서는 가중 방식을 임의로 선택하는 문제를 피하는 칼만 필터를 사용하여 헤지 비율을 업데이트하는 방식을 설명할 것이다(Montana, Triantafyllopoulos, and Tsagaris, 2009).

칼만 필터는 관찰 가능한 변수의 최신 값에 기반하여 숨겨진 변수의 기대값을 업데이트하는 최적의 선형 알고리즘이다. (이 주제에 대한 좋은 설명은 Kleeman, 2007을 참조하라.) 관찰 가능한 변수가 노이즈가 있는 숨겨진 변수의 선형 함수라고 가정하기 때문에 선형이다. 또한 시간 *t*에서의 숨겨진 변수가 노이즈가 있는 시간 $t$ − 1에서의 자신의 선형 함수이며, 이러한 함수에 존재하는 노이즈가 가우시안 분포를 가진다고 가정한다(따라서 평균을 0으로 가정하면 진화하는 공분산 행렬로 지정할 수 있다). 이러한 모든 선형 관계 때문에, 시간 *t*에서 숨겨진 변수의 기대값은 *t*에서의 관찰 전의 기대값의 선형 함수일 뿐만 아니라 *t*에서의 관찰된 변수 값의 선형 함수이기도 하다. 칼만 필터는 노이즈가 가우시안이라고 가정하면 사용 가능한 최상의 추정치이고, 추정된 변수의 평균 제곱 오차를 최소화한다는 점에서 최적이다.

칼만 필터링의 모든 응용에서 먼저 이러한 변수와 행렬이 무엇인지 파악해야 한다:

- 관찰 가능한 변수(벡터)
- 숨겨진 변수(벡터)
- 상태 전이 모델(행렬)
- 관측 모델(행렬)

이것이 실제로 응용의 유일한 창의적 부분인데, 이러한 양이 지정되면 나머지는 기존 알고리즘의 기계적 적용일 뿐이기 때문이다. 트레이더로서 우리는 이러한 양들 사이의 관계를 어떻게 도출하는지 알 필요가 없다 - 올바른 답을 제공하는 좋은 소프트웨어 패키지를 어디서 찾을 수 있는지만 알면 된다.

헤지 비율과 스프레드의 평균과 변동성을 찾는 것이 초점인 우리 응용에서, *관찰 가능한 변수*는 가격 시계열 $y$ 중 하나이고, *숨겨진 변수*는 헤지 비율 $\beta$이다. $y$와 $\beta$를 관련시키는 선형 함수는 물론

$$y(t) = x(t) \beta(t) + \epsilon(t) \qquad \text{("측정 방정식")} \qquad (3.5)$$

이며, 여기서 $x$는 다른 자산의 가격 시계열이고, $\epsilon$은 분산 $V_\epsilon$를 가진 가우시안 노이즈이다. 일반적으로 $x$와 $y$ 사이의 스프레드가 0이 아닌 평균을 갖도록 허용하므로, 절편 $\mu$와 $x$와 $y$ 사이 선형 관계의 기울기 둘 다를 나타내기 위해 $2 \times 1$ 벡터 $\beta$를 사용할 것이며, $x$와 $y$ 사이의 상수 오프셋을 허용하기 위해 $x(t)$에 1로 된 열 벡터를 추가하여 $N \times 2$ 배열을 만들 것이다. $x$는 실제로 칼만 필터 용어로 *관측 모델* 역할을 한다.

$x(t)$가 아닌 $y(t)$만 관찰 가능한 것으로 간주하는 것이 이상하게 보일 수 있지만, 이것은 단지 수학적 트릭일 뿐이다. 칼만 필터 방정식의 모든 변수는 숨겨진 변수와 노이즈를 제외하고는 관찰 가능하므로, 어떤 변수가 *그* "관찰 가능"($y$)이고 어떤 변수가 "관측 모델"($x$)인지 지정할 자유가 있다. 다음으로, 시간 $t$에서의 회귀 계수(우리의 숨겨진 변수)가 시간 $t - 1$에서와 같고 노이즈가 더해진다는 중요한 가정을 한다:

$$\beta(t) = \beta(t-1) + \omega(t-1) \qquad \text{("상태 전이")} \qquad (3.6)$$

여기서 $\omega$도 가우시안 노이즈이지만 공분산 $V_\omega$를 가진다. 다시 말해, 여기서 *상태 전이 모델*은 단위 행렬일 뿐이다.

이탤릭체로 된 네 가지 중요한 양의 지정이 주어지면, 칼만 필터링은 이제 $t$에서의 관찰이 주어졌을 때 숨겨진 변수 $\beta$의 기대값을 반복적으로 생성할 수 있다. $\beta$를 찾기 위해 칼만 필터를 사용하는 주목할 만한 이점 중 하나는 두 자산 사이의 동적 헤지 비율을 얻을 뿐만 아니라 이전에 스프레드의 "이동 평균"이라고 불렀던 것도 동시에 얻는다는 것이다. 이는 언급했듯이 $\beta$가 기울기와 $y$와 $x$ 사이의 절편 둘 다를 포함하기 때문이다. 절편의 최상의 현재 추정치는 스프레드의 이동 평균 대신 사용된다. 그러나 텔레마케터가 종종 상기시키듯이, 그게 전부가 아니다! 부산물로, 관찰 가능한 변수의 예측 오차 표준 편차 추정치도 생성하는데, 이것을 볼린저 밴드의 이동 표준 편차 대신 사용할 수 있다.

칼만 필터링의 선형성에도 불구하고, 다양한 양을 관련시키는 행렬 관계는 꽤 복잡해 보일 수 있으므로, 인내심 있는 독자가 숙독할 수 있도록 박스 3.1에 설명을 남겨둔다.

실제로 반복 방정식 외에도 측정 및 상태 전이 방정식의 (공)분산 $V_\epsilon$과 $V_\omega$도 지정해야 한다. 이러한 지정도 박스 3.1에 포함될 것이다.

#### **칼만 필터의 반복 방정식 (The Iterative Equations of the Kalman Filter)**
** 박스 3.1**

$t - 1$에서의 관찰이 주어졌을 때 $t$에서의 $\beta$의 기대값을 $\hat{\beta}(t | t - 1)$로, $t$에서의 관찰이 주어졌을 때 $\beta$의 기대값을 $\hat{\beta}(t | t)$로, $t - 1$에서의 관찰이 주어졌을 때 $y(t)$의 기대값을 $\hat{y}(t | t - 1)$로 표기한다. 시간 $t - 1$에서 양 $\hat{\beta}(t - 1 | t - 1)$과 $R(t - 1 | t - 1)$이 주어지면, 1단계 예측을 할 수 있다:

$$\hat{\beta}(t|t-1) = \hat{\beta}(t-1|t-1) \qquad \text{("상태 예측")} \qquad (3.7)$$

$$R(t|t-1) = R(t-1|t-1) + V_w \qquad \text{("상태 공분산 예측")} \qquad (3.8)$$

$$\hat{y}(t) = x(t)\hat{\beta}(t|t-1) \qquad \text{("측정 예측")} \qquad (3.9)$$

$$Q(t) = x(t)'R(t|t-1)x(t) + V_e \qquad \text{("측정 분산 예측")} \qquad (3.10)$$

여기서 $R(t | t - 1)$은 $\text{cov}(\beta(t) - \hat{\beta}(t | t - 1))$로, 숨겨진 변수 추정치의 오차 공분산을 측정한다. ($\beta$가 두 개의 독립 구성 요소를 가지므로 분산이 아닌 공분산이다.) 마찬가지로 $R(t | t)$는 $\text{cov}(\beta(t) - \hat{\beta}(t | t))$이다. 숨겨진 변수가 스프레드의 평균과 헤지 비율 둘 다로 구성됨을 기억하면, $R$은 $2 \times 2$ 행렬이다. $e(t) = y(t) - x(t)\hat{\beta}(t | t - 1)$는 $t - 1$에서의 관찰이 주어졌을 때 $y(t)$의 예측 오차이고, $Q(t)$는 $\text{var}(e(t))$로 예측 오차의 분산을 측정한다.

시간 t에서 측정을 관찰한 후, 유명한 칼만 필터 상태 추정 업데이트 및 공분산 업데이트 방정식은

$$\hat{\beta}(t|t) = \hat{\beta}(t|t-1) + K(t) * e(t) \qquad \text{("상태 업데이트")} \qquad (3.11)$$

$$R(t| t) = R(t| t - 1) - K(t) * x(t) * R(t| t - 1) \qquad \text{("상태 공분산 업데이트")} \qquad (3.12)$$

여기서 K(t)는 칼만 이득(Kalman gain)이라고 하며 다음과 같이 주어진다:

$$K(t) = \frac{R(t \mid t - 1) * x(t)}{Q(t)} \qquad (3.13)$$

이러한 재귀를 시작하기 위해 $\hat{\beta}(1 | 0) = 0, R(0 | 0) = 0$을 가정한다. 그러나 $V_\omega$와 $V_e$는 어떨까? Rajamani와 Rawlings(2007, 2009)가 개발한 자기공분산 최소자승법(autocovariance least squares)이라는 데이터에서 이러한 분산을 추정하는 방법이 있다. 이 방법을 구현하기 위한 무료 Matlab/Octave 패키지도 있다([http://jbrwww.che.wisc.edu/software/als](http://jbrwww.che.wisc.edu/software/als)). 그러나 단순화를 위해 Montana를 따라 $V_\omega = \frac{\delta}{1-\delta} V_\epsilon I$를 가정할 것이며, 여기서 $\delta$는 0과 1 사이의 매개변수이고 $I$는 $2 \times 2$ 단위 행렬이다. $\delta = 0$이면 $\beta(t) = \beta(t - 1)$을 의미하며, 이는 칼만 필터를 고정된 오프셋과 기울기를 가진 일반 최소자승 회귀로 축소한다. $\delta = 1$이면 추정된 $\beta$가 최신 관찰에 기반하여 크게 변동할 것을 의미한다. 최적의 $\delta$는 이동 선형 회귀의 최적 룩백과 마찬가지로 훈련 데이터를 사용하여 얻을 수 있다. 사후에 $\delta = 0.0001$을 선택한다. 같은 사후로 $V_e = 0.001$도 선택한다.

예제 3.3에서는 예제 2.7에서 논의한 EWA-EWC 쌍에 대한 동적 β를 추정하기 위해 칼만 필터를 사용하는 실제 구현을 설명한다.

#### **예제 3.3: 칼만 필터 평균 회귀 전략 (Example 3.3: Kalman Filter Mean Reversion Strategy)**

이제 칼만 필터 방정식 3.5부터 3.13을 구현하고 EWA-EWC 쌍에 적용할 것이다. 코드는 *KF_beta_EWA_EWC.m*으로 다운로드할 수 있다. EWA의 가격 시계열이 Tx1 배열 *x*에 저장되어 있고, EWC는 Tx1 배열 *y*에 저장되어 있다고 가정한다.

```
% Augment x with ones to accommodate possible offset in the
   % regression
% between y vs x.
x=[x ones(size(x))];
delta=0.0001; % delta=0 allows no change (like traditional
 % linear regression).
yhat=NaN(size(y)); % measurement prediction
e=NaN(size(y)); % measurement prediction error
Q=NaN(size(y)); % measurement prediction error variance
% For clarity, we denote R(t|t) by P(t).
% initialize P and beta.
P=zeros(2);
beta=NaN(2, size(x, 1));
Vw=delta/(1-delta)*diag(ones(2, 1));
Ve=0.001;
% Initialize beta(:, 1) to zero
beta(:, 1)=0;
```

#### **예제 3.3 (***계속***)**

```
for t=1:length(y)
    if (t > 1)
         beta(:, t)=beta(:, t-1); % state prediction.
          % Equation 3.7
         R=P+Vw; % state covariance prediction. Equation 3.8
    end
    yhat(t)=x(t, :)*beta(:, t); % measurement prediction.
     % Equation 3.9
    Q(t)=x(t, :)*R*x(t, :)'+Ve; % measurement variance
     % prediction. Equation 3.10
    % Observe y(t)
    e(t)=y(t)-yhat(t); % measurement prediction error
    K=R*x(t, :)'/Q(t); % Kalman gain
    beta(:, t)=beta(:, t)+K*e(t); % State update.
     % Equation 3.11
    P=R-K*x(t, :)*R; % State covariance update. Euqation 3.12
```

End

그림 3.5에서 $\delta = 0.0001$일 때 EWC ($y$)와 EWA ($x$) 사이의 선형 적합의 칼만 업데이트된 기울기 $\beta(1, t)$가 1 주위에서 진동함을 볼 수 있다.

![](_page_16_Figure_6.jpeg)

**그림 3.5** EWC (y)와 EWA (x) 사이 기울기의 칼만 필터 추정치

(*계속*)

![](_page_17_Figure_3.jpeg)

**그림 3.6** EWC (y)와 EWA (x) 사이 절편의 칼만 필터 추정치

그림 3.6에서 칼만 업데이트된 절편 $\beta(2, t)$가 시간에 따라 단조롭게 증가함을 볼 수 있다.

칼만 필터에서 계산된 이러한 양과 다른 양을 활용하여 평균 회귀 전략을 만들 수 있다. 측정 예측 오차 *e*(*t*)(이전에 $t - 1$에서의 관찰이 주어졌을 때 *y*(*t*)의 예측 오차라고 불렀던 것)는 스프레드 EWC-EWA가 예측된 평균값에서 벗어난 정도에 다름 아니며, 편차가 매우 음수일 때 이 스프레드를 매수하고, 매우 양수이면 그 반대로 할 것이다. 얼마나 음수이거나 양수여야 할까? 그것은 *e*(*t*)의 예측된 표준 편차에 달려 있는데, 이것은 *Q*(*t*)에 다름 아니다. 같은 차트에 *e*(*t*)와 *Q*(*t*)를 플롯하면(그림 3.7) 작은 δ가 주어졌을 때 *Q*(*t*)가 꽤 천천히 변함을 볼 수 있다.

진입 및 청산 신호를 결정하기 위한 Matlab 코드는 다음과 같다.

```
y2=[x(:, 1) y];
longsEntry=e < -sqrt(Q); % a long position means we should
 % buy EWC
longsExit=e > -sqrt(Q);
shortsEntry=e > sqrt(Q);
shortsExit=e < sqrt(Q);
```

## **예제 3.3 (***계속***)**

진입 및 청산 신호가 결정되면 코드의 나머지는 *bollinger.m*과 동일하다 - *hedgeRatio* 대신 *beta(1, :)*를 대체하면 된다. APR 26.2%와 샤프 비율 2.4로 합리적이다. 누적 수익률은 그림 3.8에 플롯되어 있다.

![](_page_18_Figure_4.jpeg)

**그림 3.7** 측정 예측 오차 *e*(*t*)와 *e*(*t*)의 표준 편차

![](_page_18_Figure_6.jpeg)

**그림 3.8** EWA-EWC에 대한 칼만 필터 전략의 누적 수익률

(*계속*)

#### **예제 3.3 (***계속***)**우리가 시연한 것처럼 칼만 필터를 직접 코딩하는 대신, 사용 가능한 많은 무료 오픈 소스 MATLAB 코드를 사용할 수도 있다. 그러한 패키지 중 하나는 [www.cs.ubc.ca/~murphyk/Software/Kalman/kalman.html](http://www.cs.ubc.ca/~murphyk/Software/Kalman/kalman.html)에서 찾을 수 있다. 칼만 필터는 MATLAB의 Control System Toolbox에서도 사용할 수 있다.

# ■ ** 마켓 메이킹 모델로서의 칼만 필터 (Kalman Filter as Market-Making Model)**

칼만 필터를 평균 회귀 전략에 적용하는 또 다른 주목할 만한 응용이 있다. 이 응용에서는 하나의 평균 회귀 가격 시계열에만 관심이 있다. 두 공적분 가격 시계열 사이의 헤지 비율을 찾는 것에는 관심이 없다. 그러나 이전과 마찬가지로 평균 회귀 거래를 위해 가격 시계열의 평균 가격과 표준 편차를 찾고 싶다. 따라서 평균 가격 *m*(*t*)가 여기서 숨겨진 변수이고, 가격 *y*(*t*)가 관찰 가능한 변수이다. 이 경우 측정 방정식은 간단하다:

$$y(t) = m(t) + \epsilon(t) \qquad \text{("측정 방정식")} \qquad (3.14)$$

동일한 상태 전이 방정식과 함께

$$m(t) = m(t-1) + \omega(t-1) \qquad \text{("상태 전이")} \qquad (3.15)$$

따라서 상태 업데이트 방정식 3.11은 단지

$$m(t \mid t) = m(t \mid t-1) + K(t)(y(t) - m(t \mid t-1)) \qquad \text{("상태 업데이트")} \qquad (3.16)$$

(첫 번째 읽기에서 박스 3.1을 건너뛰었다면 지금 복습할 때일 수 있다.) 예측 오차의 분산은

$$Q(t) = \text{Var}(m(t)) + V_e \qquad (3.17)$$

칼만 이득은

$$K(t) = \frac{R(t \mid t - 1)}{R(t \mid t - 1) + V_e} \qquad (3.18)$$

그리고 상태 분산 업데이트는

$$R(t \mid t) = (1 - K(t))R(t \mid t - 1) \qquad (3.19)$$

왜 이 방정식들을 강조할 가치가 있을까? 유안 싱클레어(Euan Sinclair)가 지적했듯이 이것이 마켓 메이커가 자산의 평균 가격 추정치를 업데이트하는 데 선호하는 모델이기 때문이다(Sinclair, 2010). 이 방정식을 더 실용적으로 만들기 위해 실무자들은 측정 오차 $V_e$에 대해 추가 가정을 한다. 이것은 관찰된 거래 가격의 불확실성을 측정한다는 것을 상기할 수 있다. 그러나 관찰된 거래 가격에 어떻게 불확실성이 있을 수 있을까? 거래 규모가 크면(어떤 벤치마크에 비해) 불확실성이 작고, 그 반대도 마찬가지라는 방식으로 불확실성을 해석할 수 있다. 따라서 이 경우 $V_e$도 t의 함수가 된다. 거래 규모를 T로, 벤치마크 거래 규모를 $T_{max}$로 표기하면, $V_e$는 다음과 같은 형태를 가질 수 있다:

$$V_e = R(t \mid t - 1) \left(\frac{T}{T_{max}} - 1\right) \qquad (3.20)$$

$T=T_{max}$이면 관찰된 가격에 불확실성이 없고, 칼만 이득은 1이며, 따라서 평균 가격 m(t)의 새로운 추정치는 정확히 관찰된 가격과 같다는 것을 알 수 있다! 그러나 $T_{max}$는 무엇이어야 할까? 예를 들어 전날 총 거래량의 일부 비율일 수 있으며, 정확한 비율은 훈련 데이터로 최적화해야 한다.

이 접근 방식이 자산의 평균 가격 또는 공정 가치를 결정하는 소위 거래량가중평균가격(VWAP, volume-weighted average price) 접근 방식과 유사하다는 점에 주목하라. 칼만 필터 접근 방식에서는 거래 규모가 큰 거래에 더 많은 가중치를 줄 뿐만 아니라 더 최근 거래 가격에도 더 많은 가중치를 준다. 따라서 이것을 거래량 *및* 시간 가중 평균 가격과 비교할 수 있다.

# ■ **데이터 오류의 위험 (The Danger of Data Errors)**

데이터 오류는 평균 회귀 전략의 백테스팅과 실행 모두에 특히 교활한 영향을 미친다.

백테스팅에 사용되는 과거 데이터에 오류 또는 "이상치(outliers)"가 있으면, 이러한 오류는 일반적으로 평균 회귀 전략의 백테스트 성과를 부풀린다. 예를 들어, 11:00, 11:01, 11:02의 실제 주식 거래 가격이 \$100, \$100, \$100이었지만 과거 데이터가 이를 \$100, \$110, \$100으로 잘못 기록했다면, 평균 회귀 전략의 백테스트는 11:01에 주식을 숏(\$110)하고, 11:02에 포지션을 커버(\$100)하여 깔끔하지만 허구적인 \$10의 이익을 낸 것으로 나올 가능성이 높다. 데이터 품질이 일중 데이터에 특히 중요한 이유를 알 수 있다. 그러한 오류의 기회가 훨씬 더 많기 때문이다. 그래서 신뢰할 수 있는 데이터 공급업체는 거래소에서 제공하는 취소 및 정정 코드를 통합하여 "정상"에서 너무 먼 거래 가격으로 인해 취소되었을 수 있는 거래를 수정하는 데 큰 주의를 기울였다. ("정상" 가격을 구성하는 것은 관련 거래소에 의해 때로는 사례별로 결정된다.) 토마스 팔켄베리(Thomas Falkenberry)(2002)가 데이터 정리 문제에 대해 더 많이 썼다.

그러나 이러한 유형의 데이터 오류는 모멘텀 전략의 백테스트 성과를 억제하므로 그다지 위험하지 않다. 앞의 예에서 모멘텀 전략은 백테스트에서 11:01에 주식을 매수(\$110)하고 11:02에 손실로 손절될 가능성이 높다(\$100).

같은 종류의 오류는 물론 라이브 거래에서도 잘못된 거래를 유발하며, 종종 실제 손실을 초래한다. 앞의 예에서 가격이 매수호가(bid)였고 11:02에 \$110의 잘못된 매수호가가 있다면, 실행 프로그램이 그 시점에 숏 시장가 매도 주문을 보냈을 수 있는데, 불행히도 \$110의 매수호가는 실제로 없었으므로 \$100에 체결될 것이다.

잘못된 라이브 매수/매도 호가의 이 문제는 페어나 다른 차익거래 전략을 거래할 때 특히 위험하다. 이러한 전략에서는 종종 거래 신호를 유발하기 위해 다양한 상품의 가격 호가 *차이*에 의존하기 때문이다. 한 쌍의 호가 차이는 일반적으로 호가 자체보다 훨씬 작은 규모이므로 호가의 오류는 스프레드에서 훨씬 더 큰 비율 오차를 초래한다. 예를 들어, 주식 X와 Y의 페어를 거래하고 있고 X의 실제 매수호가가 \$100이고 Y의 실제 매도호가가 \$105라면 스프레드 Y−X는 \$5로, X를 매수하고 Y를 매도하라는 시장가 주문을 유발하기에는 너무 작을 수 있다. 그러나 데이터 오류로 인해 Y가 \$106의 매도호가를 표시하면 잘못된 스프레드는 \$6이 되어 실제 스프레드 \$5보다 20% 증가하며, 이것이 X를 매수하고 Y를 매도하라는 잘못된 주문을 유발하기에 충분할 수 있다.

나는 주식 페어 트레이딩 전략을 구동하기 위해 브로커의 데이터 피드를 사용할 때 라이브 거래에서 이 문제를 보았다. 그 데이터 피드는 데이터 피드를 제3자 제공업체(Yahoo! 실시간 시세보다 더 복잡한 것은 아님)로 전환하고 나쁜 거래가 멈출 때까지 설명할 수 없는 손실 거래를 상당히 정기적으로 유발했다. 나중에 Bloomberg의 라이브 데이터 피드에 접근할 수 있게 되었고, 이러한 나쁜 거래 중 어떤 것도 유발하지 않았다.

라이브 데이터의 나쁜 틱은 모멘텀 전략이 잘못된 주문을 보내게도 한다. 따라서 그러한 전략의 실행에도 똑같이 손실을 유발한다.

#### **핵심 포인트 (KEY POINTS)**

- 거래 기간 동안 고정된 주식 수로 평균 회귀 포트폴리오를 구성하고 싶은가? 가격 시계열을 사용하여 헤지 비율을 결정하라.
- 거래 기간 동안 각 구성 요소에 대해 고정된 시장 가치로 평균 회귀 포트폴리오를 구성하고 싶은가? 로그 가격 시계열을 사용하여 헤지 비율을 결정하라.
- 비율은 스프레드 대신 통화 페어 거래에 좋은 지표인 경우가 많다.
- 스프레드의 헤지 비율, 평균, 표준 편차가 미래에 변할 수 있다고 우려하는가? 이동 룩백 기간이나 칼만 필터를 사용하라.
- 선형 거래 전략의 실용적인 구현은 스케일링 인이 있는 볼린저 밴드이다.
- 스케일링 인은 백테스트에서 최적이 아닐 수 있지만 변동성과 확률이 변하는 라이브 거래에서는 종종 유용하다.
- 최신 거래(가격과 규모)에 기반하여 상품의 예상 가격을 동적으로 업데이트하고 싶은가? 칼만 필터를 사용하라.
- 데이터 오류는 평균 회귀 전략의 백테스트 결과를 부풀릴 수 있지만 모멘텀 전략은 그렇지 않다.
- 스프레드에 기반한 전략은 백테스트든 라이브 거래든 작은 데이터 오류에 특히 민감하다.
