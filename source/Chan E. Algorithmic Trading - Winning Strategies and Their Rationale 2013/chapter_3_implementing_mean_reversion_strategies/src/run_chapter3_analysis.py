#!/usr/bin/env python3
"""
Chapter 3: í‰ê·  íšŒê·€ ì „ëµ êµ¬í˜„ - ì¢…í•© ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„±ê¸°

ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” Ernest Chanì˜ "Algorithmic Trading" Chapter 3ì˜ í•µì‹¬ ê°œë…ë“¤ì„ ì‹¤í–‰í•˜ê³ 
ë¶„ì„ ê²°ê³¼ë¥¼ ì¢…í•© ë¦¬í¬íŠ¸ í˜•íƒœë¡œ ì¶œë ¥í•©ë‹ˆë‹¤.

ë¶„ì„ ë‚´ìš©:
1. ìŠ¤í”„ë ˆë“œ ìœ í˜• ë¹„êµ (ê°€ê²© ìŠ¤í”„ë ˆë“œ, ë¡œê·¸ ê°€ê²© ìŠ¤í”„ë ˆë“œ, ë¹„ìœ¨)
2. ë³¼ë¦°ì € ë°´ë“œ ì „ëµ
3. ì¹¼ë§Œ í•„í„° ê¸°ë°˜ ë™ì  í—¤ì§€ ë¹„ìœ¨
4. ì „ëµ ì„±ê³¼ ë¹„êµ
"""

import os
import sys
import warnings
from datetime import datetime
from pathlib import Path

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import statsmodels.api as sm
import statsmodels.formula.api as smf
import statsmodels.tsa.stattools as ts

# ê²½ê³  ë©”ì‹œì§€ ì–µì œ
warnings.filterwarnings('ignore')

# ë¦¬í¬íŠ¸ ì¶œë ¥ ì„¤ì •
REPORT_DIR = Path(__file__).parent / "reports"
FIGURES_DIR = REPORT_DIR / "figures"


class Chapter3Analyzer:
    """Chapter 3 í‰ê·  íšŒê·€ ì „ëµ êµ¬í˜„ ë¶„ì„ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.results = {}
        self.figures = []
        
        # ë””ë ‰í† ë¦¬ ìƒì„±
        REPORT_DIR.mkdir(exist_ok=True)
        FIGURES_DIR.mkdir(exist_ok=True)
        
    def load_data(self):
        """ë°ì´í„° ë¡œë“œ"""
        print("=" * 60)
        print("ğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
        print("=" * 60)
        
        # GLD/USO ë°ì´í„° (Chapter 3 ì˜ˆì œ)
        gld_uso_path = Path(__file__).parent / "inputData_GLD_USO.csv"
        if gld_uso_path.exists():
            self.df_gld_uso = pd.read_csv(gld_uso_path)
            self.df_gld_uso['Date'] = pd.to_datetime(self.df_gld_uso['Date'], format='%Y%m%d')
            self.df_gld_uso.set_index('Date', inplace=True)
            print(f"  âœ“ GLD/USO: {len(self.df_gld_uso)} ë°ì´í„° í¬ì¸íŠ¸")
        else:
            self.df_gld_uso = None
            print(f"  âœ— GLD/USO ë°ì´í„° ì—†ìŒ")
        
        # EWA/EWC ë°ì´í„° (ì¹¼ë§Œ í•„í„° ì˜ˆì œìš© - Chapter 2ì—ì„œ ë³µì‚¬)
        ewa_ewc_path = Path(__file__).parent / "inputData_EWA_EWC.csv"
        # Chapter 2 í´ë”ì—ì„œ ê°€ì ¸ì˜¤ê¸° ì‹œë„
        if not ewa_ewc_path.exists():
            chapter2_path = Path(__file__).parent.parent.parent / "chapter_2_the_basics_of_mean_reversion" / "src" / "inputData_EWA_EWC.csv"
            if chapter2_path.exists():
                import shutil
                shutil.copy(chapter2_path, ewa_ewc_path)
                print(f"  â„¹ï¸ EWA/EWC ë°ì´í„°ë¥¼ Chapter 2ì—ì„œ ë³µì‚¬í•¨")
        
        if ewa_ewc_path.exists():
            self.df_ewa_ewc = pd.read_csv(ewa_ewc_path)
            self.df_ewa_ewc['Date'] = pd.to_datetime(self.df_ewa_ewc['Date'], format='%Y%m%d')
            self.df_ewa_ewc.set_index('Date', inplace=True)
            print(f"  âœ“ EWA/EWC: {len(self.df_ewa_ewc)} ë°ì´í„° í¬ì¸íŠ¸")
        else:
            self.df_ewa_ewc = None
            print(f"  âœ— EWA/EWC ë°ì´í„° ì—†ìŒ")
            
        print()
        
    def analyze_spread_types(self):
        """ìŠ¤í”„ë ˆë“œ ìœ í˜• ë¹„êµ: ê°€ê²© ìŠ¤í”„ë ˆë“œ, ë¡œê·¸ ê°€ê²© ìŠ¤í”„ë ˆë“œ, ë¹„ìœ¨"""
        print("=" * 60)
        print("ğŸ”¬ 1. ìŠ¤í”„ë ˆë“œ ìœ í˜• ë¹„êµ ë¶„ì„")
        print("=" * 60)
        
        self.results['spread_types'] = {}
        
        if self.df_gld_uso is None:
            print("  âœ— GLD/USO ë°ì´í„° ì—†ìŒ - ë¶„ì„ ê±´ë„ˆëœ€")
            return
            
        df = self.df_gld_uso.copy()
        lookback = 20
        
        # 1.1 ê°€ê²© ìŠ¤í”„ë ˆë“œ (Price Spread with Dynamic Hedge Ratio)
        print("\n### 1.1 ê°€ê²© ìŠ¤í”„ë ˆë“œ (ë™ì  í—¤ì§€ ë¹„ìœ¨)")
        print("-" * 40)
        
        from statsmodels.regression.rolling import RollingOLS
        
        # RollingOLS ì‚¬ìš©ìœ¼ë¡œ ì†ë„ ê°œì„ 
        print("  â³ RollingOLS ê³„ì‚° ì¤‘...")
        endog = df['USO']
        exog = sm.add_constant(df['GLD'])
        # window=lookbackìœ¼ë¡œ ì„¤ì •
        rols = RollingOLS(endog, exog, window=lookback)
        rres = rols.fit()
        
        # íŒŒë¼ë¯¸í„° ì¶”ì¶œ (GLDì˜ ê³„ìˆ˜)
        # paramsëŠ” [const, GLD] ìˆœì„œì¼ ìˆ˜ ìˆìŒ (add_constantì— ë”°ë¼)
        # í•˜ì§€ë§Œ RollingOLSì˜ paramsëŠ” ì»¬ëŸ¼ ì´ë¦„ì„ ìœ ì§€í•¨
        hedge_ratio_price = rres.params['GLD']
        
        # ìŠ¤í”„ë ˆë“œ = USO - hedge_ratio * GLD
        spread_price = df['USO'] - hedge_ratio_price * df['GLD']
        
        # ì„ í˜• í‰ê·  íšŒê·€ ì „ëµ
        numUnits = -(spread_price - spread_price.rolling(lookback).mean()) / spread_price.rolling(lookback).std()
        
        positions = pd.DataFrame({
            'GLD': -numUnits * hedge_ratio_price * df['GLD'],
            'USO': numUnits * df['USO']
        })
        
        pnl = (positions.shift() * df.pct_change()).sum(axis=1)
        ret = pnl / positions.shift().abs().sum(axis=1)
        ret_clean = ret.replace([np.inf, -np.inf], np.nan).dropna()
        
        apr_price = np.prod(1 + ret_clean) ** (252 / len(ret_clean)) - 1
        sharpe_price = np.sqrt(252) * ret_clean.mean() / ret_clean.std()
        
        self.results['spread_types']['price_spread'] = {
            'apr': apr_price,
            'sharpe': sharpe_price
        }
        
        print(f"  APR: {apr_price*100:.2f}%")
        print(f"  ìƒ¤í”„ ë¹„ìœ¨: {sharpe_price:.4f}")
        
        # 1.2 ë¡œê·¸ ê°€ê²© ìŠ¤í”„ë ˆë“œ (Log Price Spread)
        print("\n### 1.2 ë¡œê·¸ ê°€ê²© ìŠ¤í”„ë ˆë“œ")
        print("-" * 40)
        
        print("  â³ RollingOLS (Log) ê³„ì‚° ì¤‘...")
        log_df = np.log(df)
        endog_log = log_df['USO']
        exog_log = sm.add_constant(log_df['GLD'])
        rols_log = RollingOLS(endog_log, exog_log, window=lookback)
        rres_log = rols_log.fit()
        
        hedge_ratio_log = rres_log.params['GLD']
        
        spread_log = np.log(df['USO']) - hedge_ratio_log * np.log(df['GLD'])
        
        numUnits_log = -(spread_log - spread_log.rolling(lookback).mean()) / spread_log.rolling(lookback).std()
        
        positions_log = pd.DataFrame({
            'GLD': -numUnits_log * hedge_ratio_log,
            'USO': numUnits_log
        })
        
        pnl_log = (positions_log.shift() * df.pct_change()).sum(axis=1)
        ret_log = pnl_log / positions_log.shift().abs().sum(axis=1)
        ret_log_clean = ret_log.replace([np.inf, -np.inf], np.nan).dropna()
        
        apr_log = np.prod(1 + ret_log_clean) ** (252 / len(ret_log_clean)) - 1
        sharpe_log = np.sqrt(252) * ret_log_clean.mean() / ret_log_clean.std()
        
        self.results['spread_types']['log_spread'] = {
            'apr': apr_log,
            'sharpe': sharpe_log
        }
        
        print(f"  APR: {apr_log*100:.2f}%")
        print(f"  ìƒ¤í”„ ë¹„ìœ¨: {sharpe_log:.4f}")
        
        # 1.3 ë¹„ìœ¨ (Ratio)
        print("\n### 1.3 ë¹„ìœ¨ (USO/GLD)")
        print("-" * 40)
        
        ratio = df['USO'] / df['GLD']
        
        numUnits_ratio = -(ratio - ratio.rolling(lookback).mean()) / ratio.rolling(lookback).std()
        
        # ë¡±/ìˆ ë™ì¼ ìë³¸ ë°°ë¶„
        positions_ratio = pd.DataFrame({
            'GLD': -numUnits_ratio * df['GLD'],
            'USO': numUnits_ratio * df['USO']
        })
        
        pnl_ratio = (positions_ratio.shift() * df.pct_change()).sum(axis=1)
        ret_ratio = pnl_ratio / positions_ratio.shift().abs().sum(axis=1)
        ret_ratio_clean = ret_ratio.replace([np.inf, -np.inf], np.nan).dropna()
        
        apr_ratio = np.prod(1 + ret_ratio_clean) ** (252 / len(ret_ratio_clean)) - 1
        sharpe_ratio = np.sqrt(252) * ret_ratio_clean.mean() / ret_ratio_clean.std()
        
        self.results['spread_types']['ratio'] = {
            'apr': apr_ratio,
            'sharpe': sharpe_ratio
        }
        
        print(f"  APR: {apr_ratio*100:.2f}%")
        print(f"  ìƒ¤í”„ ë¹„ìœ¨: {sharpe_ratio:.4f}")
        
        # ì°¨íŠ¸ ìƒì„±
        fig, axes = plt.subplots(3, 1, figsize=(12, 10))
        
        axes[0].plot(spread_price.values, linewidth=0.8)
        axes[0].set_title('Price Spread: USO - hedgeRatio Ã— GLD', fontsize=12)
        axes[0].set_ylabel('Spread')
        axes[0].grid(True, alpha=0.3)
        
        axes[1].plot(spread_log.values, linewidth=0.8, color='orange')
        axes[1].set_title('Log Price Spread: log(USO) - hedgeRatio Ã— log(GLD)', fontsize=12)
        axes[1].set_ylabel('Spread')
        axes[1].grid(True, alpha=0.3)
        
        axes[2].plot(ratio.values, linewidth=0.8, color='green')
        axes[2].set_title('Ratio: USO / GLD', fontsize=12)
        axes[2].set_ylabel('Ratio')
        axes[2].grid(True, alpha=0.3)
        
        fig.tight_layout()
        fig.savefig(FIGURES_DIR / 'spread_types_comparison.png', dpi=150)
        plt.close(fig)
        self.figures.append('spread_types_comparison.png')
        
        print()
        
    def analyze_bollinger_bands(self):
        """ë³¼ë¦°ì € ë°´ë“œ ì „ëµ ë¶„ì„"""
        print("=" * 60)
        print("ğŸ“Š 2. ë³¼ë¦°ì € ë°´ë“œ ì „ëµ ë¶„ì„")
        print("=" * 60)
        
        self.results['bollinger'] = {}
        
        if self.df_gld_uso is None:
            print("  âœ— GLD/USO ë°ì´í„° ì—†ìŒ - ë¶„ì„ ê±´ë„ˆëœ€")
            return
            
        df = self.df_gld_uso.copy()
        lookback = 20
        
        from statsmodels.regression.rolling import RollingOLS
        
        # ë™ì  í—¤ì§€ ë¹„ìœ¨ ê³„ì‚°
        print("  â³ RollingOLS ê³„ì‚° ì¤‘...")
        endog = df['USO']
        exog = sm.add_constant(df['GLD'])
        rols = RollingOLS(endog, exog, window=lookback)
        rres = rols.fit()
        
        hedge_ratio = rres.params['GLD']
        
        # ìŠ¤í”„ë ˆë“œ ê³„ì‚°
        yport = df['USO'] - hedge_ratio * df['GLD']
        
        # Z-Score ê³„ì‚°
        ma = yport.rolling(lookback).mean()
        mstd = yport.rolling(lookback).std()
        zScore = (yport - ma) / mstd
        
        # ë³¼ë¦°ì € ë°´ë“œ ì§„ì…/ì²­ì‚°
        entry_zscore = 1
        exit_zscore = 0
        
        longs_entry = zScore < -entry_zscore
        longs_exit = zScore >= -exit_zscore
        shorts_entry = zScore > entry_zscore
        shorts_exit = zScore <= exit_zscore
        
        # í¬ì§€ì…˜ ê³„ì‚°
        num_units_long = np.zeros(len(df))
        num_units_long[:] = np.nan
        num_units_long[0] = 0
        num_units_long[longs_entry] = 1
        num_units_long[longs_exit] = 0
        num_units_long = pd.Series(num_units_long).ffill()
        
        num_units_short = np.zeros(len(df))
        num_units_short[:] = np.nan
        num_units_short[0] = 0
        num_units_short[shorts_entry] = -1
        num_units_short[shorts_exit] = 0
        num_units_short = pd.Series(num_units_short).ffill()
        
        num_units = num_units_long + num_units_short
        
        # í¬ì§€ì…˜ ë° P&L
        positions = pd.DataFrame({
            'GLD': -num_units.values * hedge_ratio * df['GLD'].values,
            'USO': num_units.values * df['USO'].values
        })
        
        pnl = (positions.shift() * df.pct_change().values).sum(axis=1)
        ret = pnl / positions.shift().abs().sum(axis=1)
        ret_clean = pd.Series(ret).replace([np.inf, -np.inf], np.nan).dropna()
        
        apr = np.prod(1 + ret_clean) ** (252 / len(ret_clean)) - 1
        sharpe = np.sqrt(252) * ret_clean.mean() / ret_clean.std()
        
        # ìµœëŒ€ ë‚™í­ ê³„ì‚°
        cumret = np.cumprod(1 + ret_clean)
        highwatermark = pd.Series(cumret).cummax()
        drawdown = (cumret - highwatermark) / highwatermark
        max_dd = drawdown.min()
        
        self.results['bollinger']['gld_uso'] = {
            'entry_zscore': entry_zscore,
            'exit_zscore': exit_zscore,
            'lookback': lookback,
            'apr': apr,
            'sharpe': sharpe,
            'max_drawdown': max_dd,
            'num_trades': int((num_units.diff().abs() > 0).sum()),
            'num_days': len(ret_clean)
        }
        
        print(f"\n### GLD-USO ë³¼ë¦°ì € ë°´ë“œ ì „ëµ")
        print("-" * 40)
        print(f"  ì§„ì… Z-Score: Â±{entry_zscore}")
        print(f"  ì²­ì‚° Z-Score: {exit_zscore}")
        print(f"  Lookback: {lookback}ì¼")
        print(f"  ì—°ê°„ ìˆ˜ìµë¥  (APR): {apr*100:.2f}%")
        print(f"  ìƒ¤í”„ ë¹„ìœ¨: {sharpe:.4f}")
        print(f"  ìµœëŒ€ ë‚™í­ (MDD): {max_dd*100:.2f}%")
        
        if sharpe > 0.5:
            print(f"  â†’ âœ… ë³¼ë¦°ì € ë°´ë“œê°€ ì„ í˜• ì „ëµ ëŒ€ë¹„ ê°œì„ ")
        else:
            print(f"  â†’ âš ï¸ ì „ëµ ê°œì„  í•„ìš”")
        
        # ì°¨íŠ¸ ìƒì„±
        fig, axes = plt.subplots(3, 1, figsize=(12, 10))
        
        # ìŠ¤í”„ë ˆë“œì™€ ë³¼ë¦°ì € ë°´ë“œ
        axes[0].plot(yport.values, linewidth=0.8, label='Spread')
        axes[0].plot(ma.values, linewidth=1, linestyle='--', label='MA')
        axes[0].plot((ma + entry_zscore * mstd).values, linewidth=0.8, linestyle=':', color='red', label=f'Upper Band (+{entry_zscore}Ïƒ)')
        axes[0].plot((ma - entry_zscore * mstd).values, linewidth=0.8, linestyle=':', color='green', label=f'Lower Band (-{entry_zscore}Ïƒ)')
        axes[0].set_title('Spread with Bollinger Bands', fontsize=12)
        axes[0].set_ylabel('Spread')
        axes[0].legend(loc='upper left')
        axes[0].grid(True, alpha=0.3)
        
        # Z-Score
        axes[1].plot(zScore.values, linewidth=0.8)
        axes[1].axhline(y=entry_zscore, color='red', linestyle='--', alpha=0.7)
        axes[1].axhline(y=-entry_zscore, color='green', linestyle='--', alpha=0.7)
        axes[1].axhline(y=0, color='gray', linestyle='-', alpha=0.5)
        axes[1].set_title('Z-Score', fontsize=12)
        axes[1].set_ylabel('Z-Score')
        axes[1].grid(True, alpha=0.3)
        
        # ëˆ„ì  ìˆ˜ìµë¥ 
        cumret_plot = np.cumprod(1 + ret_clean) - 1
        axes[2].plot(cumret_plot.values, linewidth=1)
        axes[2].axhline(y=0, color='gray', linestyle='-', alpha=0.5)
        axes[2].fill_between(range(len(cumret_plot)), 0, cumret_plot.values,
                           where=cumret_plot.values >= 0, alpha=0.3, color='green')
        axes[2].fill_between(range(len(cumret_plot)), 0, cumret_plot.values,
                           where=cumret_plot.values < 0, alpha=0.3, color='red')
        axes[2].set_title(f'Cumulative Returns (APR={apr*100:.1f}%, Sharpe={sharpe:.2f})', fontsize=12)
        axes[2].set_ylabel('Cumulative Return')
        axes[2].grid(True, alpha=0.3)
        
        fig.tight_layout()
        fig.savefig(FIGURES_DIR / 'bollinger_strategy.png', dpi=150)
        plt.close(fig)
        self.figures.append('bollinger_strategy.png')
        
        print()

    def analyze_scaling_in(self):
        """ìŠ¤ì¼€ì¼ë§ ì¸(í‰ê·  ë§¤ì…) vs ì˜¬ì¸ ì „ëµ ë¹„êµ ë¶„ì„"""
        print("=" * 60)
        print("ğŸ“ 2.5. ìŠ¤ì¼€ì¼ë§ ì¸ vs ì˜¬ì¸ ë¹„êµ ë¶„ì„")
        print("=" * 60)

        self.results['scaling_in'] = {}

        if self.df_gld_uso is None:
            print("  âœ— GLD/USO ë°ì´í„° ì—†ìŒ - ë¶„ì„ ê±´ë„ˆëœ€")
            return

        df = self.df_gld_uso.copy()
        lookback = 20

        from statsmodels.regression.rolling import RollingOLS

        # ë™ì  í—¤ì§€ ë¹„ìœ¨ ê³„ì‚°
        endog = df['USO']
        exog = sm.add_constant(df['GLD'])
        rols = RollingOLS(endog, exog, window=lookback)
        rres = rols.fit()
        hedge_ratio = rres.params['GLD']

        # ìŠ¤í”„ë ˆë“œ ê³„ì‚°
        yport = df['USO'] - hedge_ratio * df['GLD']
        ma = yport.rolling(lookback).mean()
        mstd = yport.rolling(lookback).std()
        zScore = (yport - ma) / mstd

        strategies = {}

        # --- ì „ëµ A: ì˜¬ì¸ (ë‹¨ì¼ ë³¼ë¦°ì € ë°´ë“œ, entry=1, exit=0) ---
        entry_z = 1
        longs_e = zScore < -entry_z
        longs_x = zScore >= 0
        shorts_e = zScore > entry_z
        shorts_x = zScore <= 0

        nu_long = np.zeros(len(df)); nu_long[:] = np.nan; nu_long[0] = 0
        nu_long[longs_e] = 1; nu_long[longs_x] = 0
        nu_long = pd.Series(nu_long).ffill()

        nu_short = np.zeros(len(df)); nu_short[:] = np.nan; nu_short[0] = 0
        nu_short[shorts_e] = -1; nu_short[shorts_x] = 0
        nu_short = pd.Series(nu_short).ffill()

        nu = nu_long + nu_short
        pos = pd.DataFrame({
            'GLD': -nu.values * hedge_ratio * df['GLD'].values,
            'USO': nu.values * df['USO'].values
        })
        pnl_a = (pos.shift() * df.pct_change().values).sum(axis=1)
        ret_a = pnl_a / pos.shift().abs().sum(axis=1)
        ret_a = pd.Series(ret_a).replace([np.inf, -np.inf], np.nan).dropna()

        apr_a = np.prod(1 + ret_a) ** (252 / len(ret_a)) - 1
        sharpe_a = np.sqrt(252) * ret_a.mean() / ret_a.std()
        cumret_a = np.cumprod(1 + ret_a)
        mdd_a = ((cumret_a - cumret_a.cummax()) / cumret_a.cummax()).min()

        strategies['allin_z1'] = {'apr': apr_a, 'sharpe': sharpe_a, 'mdd': mdd_a, 'label': 'ì˜¬ì¸ (Z=1)'}

        # --- ì „ëµ B: ìŠ¤ì¼€ì¼ë§ ì¸ (2ë‹¨ê³„, entry=0.5,1.5, exit=0) ---
        # 1ë‹¨ê³„: |Z|>=0.5ì—ì„œ 1ë‹¨ìœ„, |Z|>=1.5ì—ì„œ ì¶”ê°€ 1ë‹¨ìœ„, Z=0ì—ì„œ ì²­ì‚°
        nu_s1 = np.zeros(len(df)); nu_s1[:] = np.nan; nu_s1[0] = 0
        nu_s1[zScore < -0.5] = 1; nu_s1[zScore >= 0] = 0
        nu_s1 = pd.Series(nu_s1).ffill()

        nu_s2 = np.zeros(len(df)); nu_s2[:] = np.nan; nu_s2[0] = 0
        nu_s2[zScore < -1.5] = 1; nu_s2[zScore >= -0.5] = 0
        nu_s2 = pd.Series(nu_s2).ffill()

        nu_ss1 = np.zeros(len(df)); nu_ss1[:] = np.nan; nu_ss1[0] = 0
        nu_ss1[zScore > 0.5] = -1; nu_ss1[zScore <= 0] = 0
        nu_ss1 = pd.Series(nu_ss1).ffill()

        nu_ss2 = np.zeros(len(df)); nu_ss2[:] = np.nan; nu_ss2[0] = 0
        nu_ss2[zScore > 1.5] = -1; nu_ss2[zScore <= 0.5] = 0
        nu_ss2 = pd.Series(nu_ss2).ffill()

        nu_scale = nu_s1 + nu_s2 + nu_ss1 + nu_ss2

        pos_b = pd.DataFrame({
            'GLD': -nu_scale.values * hedge_ratio * df['GLD'].values,
            'USO': nu_scale.values * df['USO'].values
        })
        pnl_b = (pos_b.shift() * df.pct_change().values).sum(axis=1)
        ret_b = pnl_b / pos_b.shift().abs().sum(axis=1)
        ret_b = pd.Series(ret_b).replace([np.inf, -np.inf], np.nan).dropna()

        apr_b = np.prod(1 + ret_b) ** (252 / len(ret_b)) - 1
        sharpe_b = np.sqrt(252) * ret_b.mean() / ret_b.std()
        cumret_b = np.cumprod(1 + ret_b)
        mdd_b = ((cumret_b - cumret_b.cummax()) / cumret_b.cummax()).min()

        strategies['scale_in_z12'] = {'apr': apr_b, 'sharpe': sharpe_b, 'mdd': mdd_b, 'label': 'ìŠ¤ì¼€ì¼ë§ ì¸ (Z=0.5,1.5)'}

        # --- ì „ëµ C: ì„ í˜• ì „ëµ (ì—°ì† ìŠ¤ì¼€ì¼ ì¸) ---
        numUnits_lin = -(yport - ma) / mstd
        pos_c = pd.DataFrame({
            'GLD': -numUnits_lin * hedge_ratio * df['GLD'],
            'USO': numUnits_lin * df['USO']
        })
        pnl_c = (pos_c.shift() * df.pct_change()).sum(axis=1)
        ret_c = pnl_c / pos_c.shift().abs().sum(axis=1)
        ret_c = pd.Series(ret_c).replace([np.inf, -np.inf], np.nan).dropna()

        apr_c = np.prod(1 + ret_c) ** (252 / len(ret_c)) - 1
        sharpe_c = np.sqrt(252) * ret_c.mean() / ret_c.std()
        cumret_c = np.cumprod(1 + ret_c)
        mdd_c = ((cumret_c - cumret_c.cummax()) / cumret_c.cummax()).min()

        strategies['linear'] = {'apr': apr_c, 'sharpe': sharpe_c, 'mdd': mdd_c, 'label': 'ì„ í˜• (ì—°ì† ìŠ¤ì¼€ì¼ ì¸)'}

        self.results['scaling_in'] = strategies

        print("\n### ì „ëµë³„ ì„±ê³¼ ë¹„êµ")
        print("-" * 55)
        print(f"  {'ì „ëµ':<25} {'APR':>8} {'Sharpe':>8} {'MDD':>8}")
        print(f"  {'-'*25} {'-'*8} {'-'*8} {'-'*8}")
        for key, s in strategies.items():
            print(f"  {s['label']:<25} {s['apr']*100:>7.2f}% {s['sharpe']:>8.4f} {s['mdd']*100:>7.2f}%")

        # ì´ë¡ ì  ë¹„êµ (Schoenberg & Corwin ì¦ëª…)
        print("\n  ğŸ“– Schoenberg & Corwin (2010) í•µì‹¬ ê²°ë¡ :")
        print("  â†’ ë°±í…ŒìŠ¤íŠ¸ì—ì„œ ìŠ¤ì¼€ì¼ë§ ì¸ì´ ì˜¬ì¸ë³´ë‹¤ ìµœì ì¸ ê²½ìš°ëŠ” ì—†ë‹¤")
        print("  â†’ ë‹¨, ë³€ë™ì„±ì´ ë³€í•˜ëŠ” ì‹¤ì‹œì¥ì—ì„œëŠ” ìŠ¤ì¼€ì¼ë§ ì¸ì´ ìœ ìš©í•  ìˆ˜ ìˆë‹¤")

        # ì°¨íŠ¸ ìƒì„±
        fig, axes = plt.subplots(2, 1, figsize=(12, 8))

        # ëˆ„ì  ìˆ˜ìµë¥  ë¹„êµ
        axes[0].plot((np.cumprod(1 + ret_a) - 1).values, linewidth=1, label=f'ì˜¬ì¸ Z=1 (Sharpe={sharpe_a:.2f})')
        axes[0].plot((np.cumprod(1 + ret_b) - 1).values, linewidth=1, label=f'ìŠ¤ì¼€ì¼ë§ ì¸ Z=0.5,1.5 (Sharpe={sharpe_b:.2f})')
        axes[0].plot((np.cumprod(1 + ret_c) - 1).values, linewidth=1, label=f'ì„ í˜• ì—°ì† (Sharpe={sharpe_c:.2f})')
        axes[0].axhline(y=0, color='gray', linestyle='-', alpha=0.5)
        axes[0].set_title('Scaling-In vs All-In: Cumulative Returns Comparison', fontsize=12)
        axes[0].set_ylabel('Cumulative Return')
        axes[0].legend(loc='upper left')
        axes[0].grid(True, alpha=0.3)

        # ë“œë¡œë‹¤ìš´ ë¹„êµ
        dd_a = (cumret_a - cumret_a.cummax()) / cumret_a.cummax()
        dd_b = (cumret_b - cumret_b.cummax()) / cumret_b.cummax()
        dd_c = (cumret_c - cumret_c.cummax()) / cumret_c.cummax()
        axes[1].fill_between(range(len(dd_a)), 0, dd_a.values, alpha=0.3, label=f'ì˜¬ì¸ (MDD={mdd_a*100:.1f}%)')
        axes[1].fill_between(range(len(dd_b)), 0, dd_b.values, alpha=0.3, label=f'ìŠ¤ì¼€ì¼ë§ ì¸ (MDD={mdd_b*100:.1f}%)')
        axes[1].fill_between(range(len(dd_c)), 0, dd_c.values, alpha=0.3, label=f'ì„ í˜• (MDD={mdd_c*100:.1f}%)')
        axes[1].set_title('Drawdown Comparison', fontsize=12)
        axes[1].set_ylabel('Drawdown')
        axes[1].legend(loc='lower left')
        axes[1].grid(True, alpha=0.3)

        fig.tight_layout()
        fig.savefig(FIGURES_DIR / 'scaling_in_comparison.png', dpi=150)
        plt.close(fig)
        self.figures.append('scaling_in_comparison.png')

        print()

    def analyze_kalman_filter(self):
        """ì¹¼ë§Œ í•„í„° ê¸°ë°˜ ë™ì  í—¤ì§€ ë¹„ìœ¨ ë¶„ì„"""
        print("=" * 60)
        print("ğŸ”§ 3. ì¹¼ë§Œ í•„í„° ì „ëµ ë¶„ì„")
        print("=" * 60)
        
        self.results['kalman'] = {}
        
        if self.df_ewa_ewc is None:
            print("  âœ— EWA/EWC ë°ì´í„° ì—†ìŒ - ë¶„ì„ ê±´ë„ˆëœ€")
            return
            
        df = self.df_ewa_ewc.copy()
        
        # ì¹¼ë§Œ í•„í„° êµ¬í˜„
        x = df['EWA'].values
        y = df['EWC'].values
        
        # xì— ì ˆí¸ í•­ ì¶”ê°€ [EWA, 1]
        x_aug = np.column_stack([x, np.ones(len(x))])
        
        # ì¹¼ë§Œ í•„í„° íŒŒë¼ë¯¸í„°
        delta = 0.0001  # ìƒíƒœ ë³€í™”ìœ¨
        Ve = 0.001      # ì¸¡ì • ì˜¤ì°¨ ë¶„ì‚°
        
        # ì´ˆê¸°í™”
        n = len(y)
        yhat = np.full(n, np.nan)  # ì˜ˆì¸¡ê°’
        e = np.full(n, np.nan)     # ì˜ˆì¸¡ ì˜¤ì°¨
        Q = np.full(n, np.nan)     # ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„ì‚°
        
        R = np.zeros((2, 2))       # ìƒíƒœ ê³µë¶„ì‚°
        P = R.copy()
        beta = np.full((2, n), np.nan)  # [ê¸°ìš¸ê¸°, ì ˆí¸]
        
        Vw = delta / (1 - delta) * np.eye(2)  # ìƒíƒœ ì „ì´ ë…¸ì´ì¦ˆ ê³µë¶„ì‚°
        
        # ì´ˆê¸° beta
        beta[:, 0] = 0
        
        # ì¹¼ë§Œ í•„í„° ë°˜ë³µ
        for t in range(n):
            if t > 0:
                beta[:, t] = beta[:, t-1]  # ìƒíƒœ ì˜ˆì¸¡
                R = P + Vw                  # ìƒíƒœ ê³µë¶„ì‚° ì˜ˆì¸¡
            
            yhat[t] = np.dot(x_aug[t, :], beta[:, t])  # ì¸¡ì • ì˜ˆì¸¡
            Q[t] = np.dot(np.dot(x_aug[t, :], R), x_aug[t, :].T) + Ve  # ì¸¡ì • ë¶„ì‚° ì˜ˆì¸¡
            
            e[t] = y[t] - yhat[t]  # ì˜ˆì¸¡ ì˜¤ì°¨
            
            K = np.dot(R, x_aug[t, :].T) / Q[t]  # ì¹¼ë§Œ ì´ë“
            beta[:, t] = beta[:, t] + K * e[t]  # ìƒíƒœ ì—…ë°ì´íŠ¸
            P = R - np.outer(K, x_aug[t, :]) @ R  # ìƒíƒœ ê³µë¶„ì‚° ì—…ë°ì´íŠ¸
        
        # ê±°ë˜ ì‹ í˜¸
        sqrt_Q = np.sqrt(Q)
        longs_entry = e < -sqrt_Q
        longs_exit = e > 0
        shorts_entry = e > sqrt_Q
        shorts_exit = e < 0
        
        # í¬ì§€ì…˜ ê³„ì‚°
        num_units_long = np.zeros(n)
        num_units_long[:] = np.nan
        num_units_long[0] = 0
        num_units_long[longs_entry] = 1
        num_units_long[longs_exit] = 0
        num_units_long = pd.Series(num_units_long).ffill()
        
        num_units_short = np.zeros(n)
        num_units_short[:] = np.nan
        num_units_short[0] = 0
        num_units_short[shorts_entry] = -1
        num_units_short[shorts_exit] = 0
        num_units_short = pd.Series(num_units_short).ffill()
        
        num_units = num_units_long + num_units_short
        
        # í—¤ì§€ ë¹„ìœ¨ (ê¸°ìš¸ê¸°)
        hedge_ratio = beta[0, :]
        
        # í¬ì§€ì…˜ ë° P&L
        positions = pd.DataFrame({
            'EWA': -num_units.values * hedge_ratio * df['EWA'].values,
            'EWC': num_units.values * df['EWC'].values
        })
        
        pnl = (positions.shift() * df.pct_change().values).sum(axis=1)
        ret = pnl / positions.shift().abs().sum(axis=1)
        ret_clean = pd.Series(ret).replace([np.inf, -np.inf], np.nan).dropna()
        
        apr = np.prod(1 + ret_clean) ** (252 / len(ret_clean)) - 1
        sharpe = np.sqrt(252) * ret_clean.mean() / ret_clean.std()
        
        # ìµœëŒ€ ë‚™í­
        cumret = np.cumprod(1 + ret_clean)
        highwatermark = pd.Series(cumret).cummax()
        drawdown = (cumret - highwatermark) / highwatermark
        max_dd = drawdown.min()
        
        self.results['kalman']['ewa_ewc'] = {
            'delta': delta,
            'Ve': Ve,
            'apr': apr,
            'sharpe': sharpe,
            'max_drawdown': max_dd,
            'num_days': len(ret_clean),
            'beta_slope_mean': np.nanmean(beta[0, :]),
            'beta_slope_std': np.nanstd(beta[0, :]),
            'beta_intercept_mean': np.nanmean(beta[1, :]),
            'beta_intercept_std': np.nanstd(beta[1, :])
        }
        
        print(f"\n### EWA-EWC ì¹¼ë§Œ í•„í„° ì „ëµ")
        print("-" * 40)
        print(f"  Î´ (ìƒíƒœ ë³€í™”ìœ¨): {delta}")
        print(f"  VÎµ (ì¸¡ì • ì˜¤ì°¨ ë¶„ì‚°): {Ve}")
        print(f"  í‰ê·  í—¤ì§€ ë¹„ìœ¨: {np.nanmean(beta[0, :]):.4f} Â± {np.nanstd(beta[0, :]):.4f}")
        print(f"  ì—°ê°„ ìˆ˜ìµë¥  (APR): {apr*100:.2f}%")
        print(f"  ìƒ¤í”„ ë¹„ìœ¨: {sharpe:.4f}")
        print(f"  ìµœëŒ€ ë‚™í­ (MDD): {max_dd*100:.2f}%")
        
        if sharpe > 1.0:
            print(f"  â†’ âœ… ì¹¼ë§Œ í•„í„° ìš°ìˆ˜í•œ ì„±ê³¼")
        else:
            print(f"  â†’ âš ï¸ íŒŒë¼ë¯¸í„° ì¡°ì • í•„ìš”")
        
        # ì°¨íŠ¸ ìƒì„±
        fig, axes = plt.subplots(4, 1, figsize=(12, 12))
        
        # í—¤ì§€ ë¹„ìœ¨ (ê¸°ìš¸ê¸°)
        axes[0].plot(beta[0, :], linewidth=0.8)
        axes[0].axhline(y=1, color='red', linestyle='--', alpha=0.7)
        axes[0].set_title('Kalman Filter: Slope (Hedge Ratio) Î²â‚', fontsize=12)
        axes[0].set_ylabel('Î²â‚ (Slope)')
        axes[0].grid(True, alpha=0.3)
        
        # ì ˆí¸
        axes[1].plot(beta[1, :], linewidth=0.8, color='orange')
        axes[1].set_title('Kalman Filter: Intercept Î²â‚€', fontsize=12)
        axes[1].set_ylabel('Î²â‚€ (Intercept)')
        axes[1].grid(True, alpha=0.3)
        
        # ì˜ˆì¸¡ ì˜¤ì°¨ì™€ í‘œì¤€í¸ì°¨
        axes[2].plot(e[2:], linewidth=0.8, label='Prediction Error e(t)')
        axes[2].plot(sqrt_Q[2:], linewidth=0.8, color='red', label='âˆšQ(t)')
        axes[2].plot(-sqrt_Q[2:], linewidth=0.8, color='green', label='-âˆšQ(t)')
        axes[2].set_title('Measurement Prediction Error', fontsize=12)
        axes[2].set_ylabel('Error')
        axes[2].legend(loc='upper right')
        axes[2].grid(True, alpha=0.3)
        
        # ëˆ„ì  ìˆ˜ìµë¥ 
        cumret_plot = np.cumprod(1 + ret_clean) - 1
        axes[3].plot(cumret_plot.values, linewidth=1)
        axes[3].axhline(y=0, color='gray', linestyle='-', alpha=0.5)
        axes[3].fill_between(range(len(cumret_plot)), 0, cumret_plot.values,
                           where=cumret_plot.values >= 0, alpha=0.3, color='green')
        axes[3].fill_between(range(len(cumret_plot)), 0, cumret_plot.values,
                           where=cumret_plot.values < 0, alpha=0.3, color='red')
        axes[3].set_title(f'Cumulative Returns (APR={apr*100:.1f}%, Sharpe={sharpe:.2f})', fontsize=12)
        axes[3].set_ylabel('Cumulative Return')
        axes[3].grid(True, alpha=0.3)
        
        fig.tight_layout()
        fig.savefig(FIGURES_DIR / 'kalman_strategy.png', dpi=150)
        plt.close(fig)
        self.figures.append('kalman_strategy.png')
        
        print()
        
    def generate_report(self):
        """ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±"""
        print("=" * 60)
        print("ğŸ“ 4. ë¦¬í¬íŠ¸ ìƒì„±")
        print("=" * 60)
        
        report_lines = []
        
        # ì œëª© ë° ë©”íƒ€ë°ì´í„°
        report_lines.append("# Chapter 3: í‰ê·  íšŒê·€ ì „ëµ êµ¬í˜„ (Implementing Mean Reversion Strategies)\n")
        report_lines.append("# ë¶„ì„ ë¦¬í¬íŠ¸\n\n")
        report_lines.append(f"> **ìƒì„± ì‹œê°„**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n")
        report_lines.append("> **ë°ì´í„° ì¶œì²˜**: Ernest Chan's \"Algorithmic Trading\" (2013)\n\n")
        report_lines.append("---\n\n")
        
        # ëª©ì°¨
        report_lines.append("## ëª©ì°¨\n\n")
        report_lines.append("1. [ê°œìš” ë° ë¬¸ì œ ì •ì˜](#1-ê°œìš”-ë°-ë¬¸ì œ-ì •ì˜)\n")
        report_lines.append("2. [ì‚¬ìš© ë°ì´í„°](#2-ì‚¬ìš©-ë°ì´í„°)\n")
        report_lines.append("3. [ìŠ¤í”„ë ˆë“œ ìœ í˜• ë¹„êµ](#3-ìŠ¤í”„ë ˆë“œ-ìœ í˜•-ë¹„êµ)\n")
        report_lines.append("4. [ë³¼ë¦°ì € ë°´ë“œ ì „ëµ](#4-ë³¼ë¦°ì €-ë°´ë“œ-ì „ëµ)\n")
        report_lines.append("5. [ì¹¼ë§Œ í•„í„° ì „ëµ](#5-ì¹¼ë§Œ-í•„í„°-ì „ëµ)\n")
        report_lines.append("6. [ì „ëµ ë¹„êµ ë° ê²°ë¡ ](#6-ì „ëµ-ë¹„êµ-ë°-ê²°ë¡ )\n\n")
        report_lines.append("---\n\n")
        
        # 1. ê°œìš” ë° ë¬¸ì œ ì •ì˜
        report_lines.append("## 1. ê°œìš” ë° ë¬¸ì œ ì •ì˜\n\n")
        report_lines.append("### ğŸ’¡ í•´ê²°í•˜ë ¤ëŠ” ë¬¸ì œ\n\n")
        report_lines.append("**\"ì •ìƒì„±/ê³µì ë¶„ì´ ì™„ë²½í•˜ì§€ ì•Šì€ ì‹œê³„ì—´ì—ì„œ ì–´ë–»ê²Œ ì‹¤ìš©ì ì¸ í‰ê·  íšŒê·€ ì „ëµì„ êµ¬í˜„í•  ìˆ˜ ìˆì„ê¹Œ?\"**\n\n")
        report_lines.append("Chapter 2ì—ì„œ ì •ìƒì„±ê³¼ ê³µì ë¶„ì˜ ì´ë¡ ì  ê¸°ì´ˆë¥¼ ë°°ì› ì§€ë§Œ, ì‹¤ì œ ì‹œì¥ì—ì„œëŠ”:\n\n")
        report_lines.append("1. **ì™„ë²½í•œ ì •ìƒì„±/ê³µì ë¶„ì€ ë“œë¬¼ë‹¤** - ë‹¨ê¸° ë˜ëŠ” ê³„ì ˆì  í‰ê·  íšŒê·€ë§Œ ì¡´ì¬í•˜ëŠ” ê²½ìš°ê°€ ë§ìŒ\n")
        report_lines.append("2. **í—¤ì§€ ë¹„ìœ¨ì´ ë³€í•œë‹¤** - ì‹œê°„ì— ë”°ë¼ ë‘ ìì‚° ê°„ ê´€ê³„ê°€ ë³€í™”\n")
        report_lines.append("3. **ë¬´í•œí•œ ìë³¸ì´ ì—†ë‹¤** - ì„ í˜• ì „ëµì˜ ìŠ¤ì¼€ì¼ ì¸ì€ ë¹„í˜„ì‹¤ì \n\n")
        
        report_lines.append("### ğŸ“ í•µì‹¬ ìˆ˜í•™ì  ê°œë…\n\n")
        report_lines.append("| ê°œë… | ìˆ˜ì‹ | ì˜ë¯¸ |\n")
        report_lines.append("|------|------|------|\n")
        report_lines.append("| **ê°€ê²© ìŠ¤í”„ë ˆë“œ** | $y = y_1 - h \\cdot y_2$ | ê³ ì • ì£¼ì‹ ìˆ˜ í¬íŠ¸í´ë¦¬ì˜¤ |\n")
        report_lines.append("| **ë¡œê·¸ ê°€ê²© ìŠ¤í”„ë ˆë“œ** | $\\log(q) = h_1 \\log(y_1) + h_2 \\log(y_2)$ | ê³ ì • ìë³¸ ê°€ì¤‘ì¹˜ í¬íŠ¸í´ë¦¬ì˜¤ |\n")
        report_lines.append("| **ë³¼ë¦°ì € ë°´ë“œ** | ì§„ì…: $|Z| > Z_{entry}$, ì²­ì‚°: $|Z| < Z_{exit}$ | ì´ì‚°ì  ì§„ì…/ì²­ì‚° |\n")
        report_lines.append("| **ì¹¼ë§Œ í•„í„°** | $\\hat{\\beta}(t|t) = \\hat{\\beta}(t|t-1) + K(t) \\cdot e(t)$ | ë™ì  í—¤ì§€ ë¹„ìœ¨ ì¶”ì • |\n\n")
        report_lines.append("---\n\n")
        
        # 2. ì‚¬ìš© ë°ì´í„°
        report_lines.append("## 2. ì‚¬ìš© ë°ì´í„°\n\n")
        report_lines.append("### ğŸ“Š ë°ì´í„°ì…‹ ì„¤ëª…\n\n")
        report_lines.append("| íŒŒì¼ëª… | ë‚´ìš© | ìš©ë„ |\n")
        report_lines.append("|--------|------|------|\n")
        report_lines.append("| `inputData_GLD_USO.csv` | GLD(ê¸ˆ)/USO(ì›ìœ ) ETF | ìŠ¤í”„ë ˆë“œ ìœ í˜• ë¹„êµ, ë³¼ë¦°ì € ë°´ë“œ |\n")
        report_lines.append("| `inputData_EWA_EWC.csv` | EWA(í˜¸ì£¼)/EWC(ìºë‚˜ë‹¤) ETF | ì¹¼ë§Œ í•„í„° ì „ëµ |\n\n")
        
        report_lines.append("### ğŸ¯ ë°ì´í„° ì„ ì • ì´ìœ \n\n")
        report_lines.append("- **GLD-USO**: ê¸ˆê³¼ ì›ìœ ëŠ” ì¸í”Œë ˆì´ì…˜ê³¼ ì—°ê´€ë˜ì–´ ìˆë‹¤ëŠ” ë¯¿ìŒì´ ìˆì§€ë§Œ, **ê³µì ë¶„í•˜ì§€ ì•ŠìŒ**\n")
        report_lines.append("  - ì™„ë²½í•˜ì§€ ì•Šì€ ê³µì ë¶„ì—ì„œ ë‹¨ê¸° í‰ê·  íšŒê·€ë¥¼ í¬ì°©í•˜ëŠ” ë°©ë²• ì‹œì—°\n")
        report_lines.append("- **EWA-EWC**: í˜¸ì£¼ì™€ ìºë‚˜ë‹¤ëŠ” ëª¨ë‘ ì›ìì¬ ê²½ì œ, **ê³µì ë¶„ ê´€ê³„** ì¡´ì¬\n")
        report_lines.append("  - ì¹¼ë§Œ í•„í„°ë¡œ ë™ì  í—¤ì§€ ë¹„ìœ¨ ì¶”ì • íš¨ê³¼ ì‹œì—°\n\n")
        report_lines.append("---\n\n")
        
        # 3. ìŠ¤í”„ë ˆë“œ ìœ í˜• ë¹„êµ
        report_lines.append("## 3. ìŠ¤í”„ë ˆë“œ ìœ í˜• ë¹„êµ\n\n")
        report_lines.append("### ğŸ”¬ ë¶„ì„ ëª©ì \n\n")
        report_lines.append("ì„¸ ê°€ì§€ ìŠ¤í”„ë ˆë“œ ìœ í˜•ì˜ ì„±ê³¼ë¥¼ ë¹„êµí•˜ì—¬ ì–´ë–¤ ë°©ì‹ì´ ê°€ì¥ íš¨ê³¼ì ì¸ì§€ í™•ì¸í•©ë‹ˆë‹¤.\n\n")
        
        report_lines.append("### 3.1 ìŠ¤í”„ë ˆë“œ ìœ í˜• ì„¤ëª…\n\n")
        report_lines.append("| ìœ í˜• | ìˆ˜ì‹ | íŠ¹ì§• |\n")
        report_lines.append("|------|------|------|\n")
        report_lines.append("| **ê°€ê²© ìŠ¤í”„ë ˆë“œ** | $y = USO - \\beta \\cdot GLD$ | ê³ ì • ì£¼ì‹ ìˆ˜, ë™ì  í—¤ì§€ ë¹„ìœ¨ ì ìš© |\n")
        report_lines.append("| **ë¡œê·¸ ê°€ê²© ìŠ¤í”„ë ˆë“œ** | $y = \\log(USO) - \\beta \\cdot \\log(GLD)$ | ê³ ì • ìë³¸ ê°€ì¤‘ì¹˜, ë¦¬ë°¸ëŸ°ì‹± í•„ìš” |\n")
        report_lines.append("| **ë¹„ìœ¨** | $y = USO / GLD$ | í—¤ì§€ ë¹„ìœ¨ ë¶ˆí•„ìš”, ìŠ¤ì¼€ì¼ ë…ë¦½ì  |\n\n")
        
        if 'spread_types' in self.results:
            report_lines.append("### 3.2 ì„±ê³¼ ë¹„êµ ê²°ê³¼ (GLD-USO ì„ í˜• í‰ê· íšŒê·€ ì „ëµ)\n\n")
            report_lines.append("| ìŠ¤í”„ë ˆë“œ ìœ í˜• | APR | ìƒ¤í”„ ë¹„ìœ¨ | í‰ê°€ |\n")
            report_lines.append("|--------------|-----|-----------|------|\n")
            
            if 'price_spread' in self.results['spread_types']:
                ps = self.results['spread_types']['price_spread']
                status = "âœ…" if ps['sharpe'] > 0.5 else "âš ï¸"
                report_lines.append(f"| ê°€ê²© ìŠ¤í”„ë ˆë“œ | {ps['apr']*100:.2f}% | {ps['sharpe']:.4f} | {status} |\n")
            
            if 'log_spread' in self.results['spread_types']:
                ls = self.results['spread_types']['log_spread']
                status = "âœ…" if ls['sharpe'] > 0.5 else "âš ï¸"
                report_lines.append(f"| ë¡œê·¸ ê°€ê²© ìŠ¤í”„ë ˆë“œ | {ls['apr']*100:.2f}% | {ls['sharpe']:.4f} | {status} |\n")
            
            if 'ratio' in self.results['spread_types']:
                r = self.results['spread_types']['ratio']
                status = "âœ…" if r['sharpe'] > 0.5 else ("âŒ" if r['sharpe'] < 0 else "âš ï¸")
                report_lines.append(f"| ë¹„ìœ¨ | {r['apr']*100:.2f}% | {r['sharpe']:.4f} | {status} |\n")
            
            report_lines.append("\n")
            
        report_lines.append("### 3.3 ìŠ¤í”„ë ˆë“œ ìœ í˜•ë³„ ì°¨íŠ¸\n\n")
        report_lines.append("![Spread Types Comparison](figures/spread_types_comparison.png)\n\n")
        report_lines.append("> ğŸ“Š **í•´ì„**: ê°€ê²© ìŠ¤í”„ë ˆë“œ(ë™ì  í—¤ì§€ ë¹„ìœ¨)ê°€ ê°€ì¥ ì •ìƒì ìœ¼ë¡œ ë³´ì´ë©°, ë¹„ìœ¨ì€ í‰ê·  íšŒê·€í•˜ì§€ ì•ŠëŠ” ê²½í–¥\n\n")
        report_lines.append("---\n\n")
        
        # 4. ë³¼ë¦°ì € ë°´ë“œ ì „ëµ
        report_lines.append("## 4. ë³¼ë¦°ì € ë°´ë“œ ì „ëµ\n\n")
        report_lines.append("### ğŸ“ˆ ì „ëµ ì›ë¦¬\n\n")
        report_lines.append("ë³¼ë¦°ì € ë°´ë“œëŠ” **ì´ì‚°ì  ì§„ì…/ì²­ì‚°**ì„ ì‚¬ìš©í•˜ëŠ” ì‹¤ìš©ì ì¸ í‰ê·  íšŒê·€ ì „ëµì…ë‹ˆë‹¤.\n\n")
        report_lines.append("```python\n")
        report_lines.append("# Z-Score ê³„ì‚°\n")
        report_lines.append("z_score = (spread - moving_avg) / moving_std\n")
        report_lines.append("\n")
        report_lines.append("# ì§„ì… ì¡°ê±´\n")
        report_lines.append("long_entry = z_score < -entry_zscore   # ì €í‰ê°€ â†’ ë§¤ìˆ˜\n")
        report_lines.append("short_entry = z_score > entry_zscore   # ê³ í‰ê°€ â†’ ë§¤ë„\n")
        report_lines.append("\n")
        report_lines.append("# ì²­ì‚° ì¡°ê±´\n")
        report_lines.append("long_exit = z_score >= -exit_zscore    # í‰ê·  íšŒë³µ\n")
        report_lines.append("short_exit = z_score <= exit_zscore\n")
        report_lines.append("```\n\n")
        
        report_lines.append("### 4.1 ì¥ì \n\n")
        report_lines.append("- **ìë³¸ ê´€ë¦¬ ìš©ì´**: 0 ë˜ëŠ” 1 ë‹¨ìœ„ë§Œ íˆ¬ì\n")
        report_lines.append("- **íŒŒë¼ë¯¸í„° ìµœì í™” ê°€ëŠ¥**: `entry_zscore`, `exit_zscore`, `lookback`\n")
        report_lines.append("- **ì„ í˜• ì „ëµ ëŒ€ë¹„ ê°œì„ ëœ ì„±ê³¼**\n\n")
        
        if 'bollinger' in self.results and 'gld_uso' in self.results['bollinger']:
            bb = self.results['bollinger']['gld_uso']
            report_lines.append("### 4.2 GLD-USO ë³¼ë¦°ì € ë°´ë“œ ì „ëµ ê²°ê³¼\n\n")
            report_lines.append("**íŒŒë¼ë¯¸í„°:**\n\n")
            report_lines.append(f"- Entry Z-Score: Â±{bb['entry_zscore']}\n")
            report_lines.append(f"- Exit Z-Score: {bb['exit_zscore']}\n")
            report_lines.append(f"- Lookback: {bb['lookback']}ì¼\n\n")
            
            report_lines.append("**ì„±ê³¼ ì§€í‘œ:**\n\n")
            report_lines.append("| ì§€í‘œ | ê°’ | í‰ê°€ |\n")
            report_lines.append("|------|------|------|\n")
            
            apr_status = "âœ… ìš°ìˆ˜" if bb['apr'] > 0.10 else ("âš ï¸ ì–‘í˜¸" if bb['apr'] > 0.05 else "âŒ ì €ì¡°")
            report_lines.append(f"| ì—°ê°„ ìˆ˜ìµë¥  (APR) | {bb['apr']*100:.2f}% | {apr_status} |\n")
            
            sharpe_status = "âœ… ìš°ìˆ˜" if bb['sharpe'] > 0.8 else ("âš ï¸ ì–‘í˜¸" if bb['sharpe'] > 0.5 else "âŒ ì €ì¡°")
            report_lines.append(f"| **ìƒ¤í”„ ë¹„ìœ¨** | **{bb['sharpe']:.4f}** | {sharpe_status} |\n")
            
            mdd_status = "âœ… ì–‘í˜¸" if bb['max_drawdown'] > -0.20 else ("âš ï¸ ì£¼ì˜" if bb['max_drawdown'] > -0.30 else "âŒ ìœ„í—˜")
            report_lines.append(f"| ìµœëŒ€ ë‚™í­ (MDD) | {bb['max_drawdown']*100:.2f}% | {mdd_status} |\n\n")
            
        report_lines.append("### 4.3 ë³¼ë¦°ì € ë°´ë“œ ì „ëµ ì°¨íŠ¸\n\n")
        report_lines.append("![Bollinger Strategy](figures/bollinger_strategy.png)\n\n")
        report_lines.append("> ğŸ“Š **ì°¨íŠ¸ í•´ì„**:\n")
        report_lines.append("> - ìƒë‹¨: ìŠ¤í”„ë ˆë“œì™€ ë³¼ë¦°ì € ë°´ë“œ (ë¹¨ê°•=ìƒë‹¨ ë°´ë“œ, ì´ˆë¡=í•˜ë‹¨ ë°´ë“œ)\n")
        report_lines.append("> - ì¤‘ë‹¨: Z-Scoreì™€ ì§„ì…/ì²­ì‚° ì„ê³„ê°’\n")
        report_lines.append("> - í•˜ë‹¨: ëˆ„ì  ìˆ˜ìµë¥ \n\n")
        report_lines.append("---\n\n")

        # 4.5 ìŠ¤ì¼€ì¼ë§ ì¸ vs ì˜¬ì¸
        report_lines.append("## 4.5. ìŠ¤ì¼€ì¼ë§ ì¸ vs ì˜¬ì¸ ë¹„êµ\n\n")
        report_lines.append("### ğŸ“ ì´ë¡ ì  ë°°ê²½\n\n")
        report_lines.append("Schoenberg & Corwin (2010)ì€ **ìŠ¤ì¼€ì¼ë§ ì¸(í‰ê·  ë§¤ì…)ì´ ë°±í…ŒìŠ¤íŠ¸ì—ì„œ ê²°ì½” ìµœì ì´ ì•„ë‹˜**ì„ ì¦ëª…í–ˆìŠµë‹ˆë‹¤.\n\n")
        report_lines.append("ê°€ê²©ì´ $L_1$ìœ¼ë¡œ í•˜ë½ í›„, í™•ë¥  $p$ë¡œ $L_2 < L_1$ê¹Œì§€ ì¶”ê°€ í•˜ë½í•œ ë’¤ $F$ë¡œ íšŒê·€í•œë‹¤ê³  ê°€ì •í•˜ë©´:\n\n")
        report_lines.append("| ì „ëµ | ê¸°ëŒ€ ì´ìµ |\n")
        report_lines.append("|------|----------|\n")
        report_lines.append("| $L_1$ì—ì„œ ì˜¬ì¸ | $2(F - L_1)$ |\n")
        report_lines.append("| $L_2$ì—ì„œ ì˜¬ì¸ | $2p(F - L_2)$ |\n")
        report_lines.append("| í‰ê·  ë§¤ì… ($L_1$, $L_2$) | $(F - L_1) + p(F - L_2)$ |\n\n")
        report_lines.append("ì „í™˜ í™•ë¥  $\\hat{p} = (F - L_1)/(F - L_2)$ë¥¼ ê¸°ì¤€ìœ¼ë¡œ, $p < \\hat{p}$ì´ë©´ $L_1$ ì˜¬ì¸ì´ ìµœì , $p > \\hat{p}$ì´ë©´ $L_2$ ì˜¬ì¸ì´ ìµœì ì…ë‹ˆë‹¤. **í‰ê·  ë§¤ì…ì´ ìµœì ì¸ ê²½ìš°ëŠ” ì—†ìŠµë‹ˆë‹¤.**\n\n")
        report_lines.append("ë‹¨, ì‹¤ì‹œì¥ì—ì„œëŠ” ë³€ë™ì„±ì´ ì¼ì •í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ ìŠ¤ì¼€ì¼ë§ ì¸ì´ ë” ë‚˜ì€ **ì‹¤í˜„ ìƒ¤í”„ ë¹„ìœ¨**ì„ ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n")

        if 'scaling_in' in self.results and self.results['scaling_in']:
            report_lines.append("### 4.6 GLD-USO ì‹¤ì¦ ë¹„êµ\n\n")
            report_lines.append("| ì „ëµ | APR | ìƒ¤í”„ ë¹„ìœ¨ | MDD | í‰ê°€ |\n")
            report_lines.append("|------|-----|-----------|-----|------|\n")

            for key, s in self.results['scaling_in'].items():
                sharpe_status = "âœ…" if s['sharpe'] > 0.8 else ("âš ï¸" if s['sharpe'] > 0.5 else "âŒ")
                report_lines.append(f"| {s['label']} | {s['apr']*100:.2f}% | {s['sharpe']:.4f} | {s['mdd']*100:.2f}% | {sharpe_status} |\n")

            report_lines.append("\n")
            report_lines.append("![Scaling-In Comparison](figures/scaling_in_comparison.png)\n\n")
            report_lines.append("> ğŸ“Š **í•´ì„**: ì˜¬ì¸ ì „ëµì´ ê°€ì¥ ë†’ì€ ìˆ˜ìµë¥ ì„ ë³´ì´ë©°, Schoenberg & Corwinì˜ ì´ë¡ ê³¼ ì¼ì¹˜í•©ë‹ˆë‹¤.\n")
            report_lines.append("> ê·¸ëŸ¬ë‚˜ ìŠ¤ì¼€ì¼ë§ ì¸ì€ MDDë¥¼ ì¤„ì—¬ ì‹¤ì‹œì¥ ì ìš©ì— ìœ ë¦¬í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n\n")

        report_lines.append("---\n\n")

        # 5. ì¹¼ë§Œ í•„í„° ì „ëµ
        report_lines.append("## 5. ì¹¼ë§Œ í•„í„° ì „ëµ\n\n")
        report_lines.append("### ğŸ”§ ì¹¼ë§Œ í•„í„°ë€?\n\n")
        report_lines.append("ì¹¼ë§Œ í•„í„°ëŠ” **ìˆ¨ê²¨ì§„ ë³€ìˆ˜ì˜ ìµœì  ì¶”ì •**ì„ ìœ„í•œ ì„ í˜• ì•Œê³ ë¦¬ì¦˜ì…ë‹ˆë‹¤.\n\n")
        report_lines.append("**í•µì‹¬ ë°©ì •ì‹:**\n\n")
        report_lines.append("$$y(t) = x(t) \\beta(t) + \\epsilon(t) \\quad \\text{(ì¸¡ì • ë°©ì •ì‹)}$$\n\n")
        report_lines.append("$$\\beta(t) = \\beta(t-1) + \\omega(t-1) \\quad \\text{(ìƒíƒœ ì „ì´)}$$\n\n")
        report_lines.append("$$\\hat{\\beta}(t|t) = \\hat{\\beta}(t|t-1) + K(t) \\cdot e(t) \\quad \\text{(ìƒíƒœ ì—…ë°ì´íŠ¸)}$$\n\n")
        
        report_lines.append("### 5.1 ì¹¼ë§Œ í•„í„°ì˜ ì¥ì \n\n")
        report_lines.append("| ì¥ì  | ì„¤ëª… |\n")
        report_lines.append("|------|------|\n")
        report_lines.append("| **ë™ì  í—¤ì§€ ë¹„ìœ¨** | ì‹œê°„ì— ë”°ë¼ ë³€í•˜ëŠ” í—¤ì§€ ë¹„ìœ¨ ìë™ ì¶”ì • |\n")
        report_lines.append("| **ìŠ¤í”„ë ˆë“œ í‰ê· ** | ì ˆí¸(Î²â‚€)ì´ ìŠ¤í”„ë ˆë“œì˜ ì´ë™ í‰ê·  ì—­í•  |\n")
        report_lines.append("| **ì˜ˆì¸¡ ì˜¤ì°¨ ë¶„ì‚°** | âˆšQ(t)ê°€ ë³¼ë¦°ì € ë°´ë“œì˜ í‘œì¤€í¸ì°¨ ì—­í•  |\n")
        report_lines.append("| **ë°ì´í„° ê°€ì¤‘** | ìµœì‹  ë°ì´í„°ì— ë” ë§ì€ ê°€ì¤‘ì¹˜, ì„ì˜ ì ˆë‹¨ì  ì—†ìŒ |\n\n")
        
        if 'kalman' in self.results and 'ewa_ewc' in self.results['kalman']:
            kf = self.results['kalman']['ewa_ewc']
            report_lines.append("### 5.2 EWA-EWC ì¹¼ë§Œ í•„í„° ì „ëµ ê²°ê³¼\n\n")
            report_lines.append("**íŒŒë¼ë¯¸í„°:**\n\n")
            report_lines.append(f"- Î´ (ìƒíƒœ ë³€í™”ìœ¨): {kf['delta']}\n")
            report_lines.append(f"- VÎµ (ì¸¡ì • ì˜¤ì°¨ ë¶„ì‚°): {kf['Ve']}\n")
            report_lines.append(f"- í‰ê·  í—¤ì§€ ë¹„ìœ¨: {kf['beta_slope_mean']:.4f} Â± {kf['beta_slope_std']:.4f}\n\n")
            
            report_lines.append("**ì„±ê³¼ ì§€í‘œ:**\n\n")
            report_lines.append("| ì§€í‘œ | ê°’ | í‰ê°€ |\n")
            report_lines.append("|------|------|------|\n")
            
            apr_status = "âœ… ìš°ìˆ˜" if kf['apr'] > 0.15 else ("âš ï¸ ì–‘í˜¸" if kf['apr'] > 0.10 else "âŒ ì €ì¡°")
            report_lines.append(f"| ì—°ê°„ ìˆ˜ìµë¥  (APR) | {kf['apr']*100:.2f}% | {apr_status} |\n")
            
            sharpe_status = "âœ… ìš°ìˆ˜" if kf['sharpe'] > 1.5 else ("âš ï¸ ì–‘í˜¸" if kf['sharpe'] > 1.0 else "âŒ ì €ì¡°")
            report_lines.append(f"| **ìƒ¤í”„ ë¹„ìœ¨** | **{kf['sharpe']:.4f}** | {sharpe_status} |\n")
            
            mdd_status = "âœ… ì–‘í˜¸" if kf['max_drawdown'] > -0.15 else ("âš ï¸ ì£¼ì˜" if kf['max_drawdown'] > -0.25 else "âŒ ìœ„í—˜")
            report_lines.append(f"| ìµœëŒ€ ë‚™í­ (MDD) | {kf['max_drawdown']*100:.2f}% | {mdd_status} |\n\n")
            
        report_lines.append("### 5.3 ì¹¼ë§Œ í•„í„° ì „ëµ ì°¨íŠ¸\n\n")
        report_lines.append("![Kalman Strategy](figures/kalman_strategy.png)\n\n")
        report_lines.append("> ğŸ“Š **ì°¨íŠ¸ í•´ì„**:\n")
        report_lines.append("> - 1í–‰: ì¹¼ë§Œ í•„í„° ì¶”ì • ê¸°ìš¸ê¸° (í—¤ì§€ ë¹„ìœ¨) - 1 ì£¼ìœ„ì—ì„œ ì§„ë™\n")
        report_lines.append("> - 2í–‰: ì¹¼ë§Œ í•„í„° ì¶”ì • ì ˆí¸ - ì‹œê°„ì— ë”°ë¼ ë³€í™”\n")
        report_lines.append("> - 3í–‰: ì˜ˆì¸¡ ì˜¤ì°¨ e(t)ì™€ í‘œì¤€í¸ì°¨ âˆšQ(t)\n")
        report_lines.append("> - 4í–‰: ëˆ„ì  ìˆ˜ìµë¥ \n\n")
        report_lines.append("---\n\n")
        
        # 6. ê²°ë¡  ë° ê¶Œê³ ì‚¬í•­
        report_lines.append("## 6. ì „ëµ ë¹„êµ ë° ê²°ë¡ \n\n")
        report_lines.append("### âœ… í•µì‹¬ ë°œê²¬\n\n")
        report_lines.append("| ì „ëµ | ë°ì´í„° | APR | ìƒ¤í”„ | ì¥ì  |\n")
        report_lines.append("|------|--------|-----|------|------|\n")
        
        if 'spread_types' in self.results and 'price_spread' in self.results['spread_types']:
            ps = self.results['spread_types']['price_spread']
            report_lines.append(f"| ì„ í˜• (ê°€ê²© ìŠ¤í”„ë ˆë“œ) | GLD-USO | {ps['apr']*100:.1f}% | {ps['sharpe']:.2f} | ë‹¨ìˆœí•¨ |\n")
        
        if 'bollinger' in self.results and 'gld_uso' in self.results['bollinger']:
            bb = self.results['bollinger']['gld_uso']
            report_lines.append(f"| ë³¼ë¦°ì € ë°´ë“œ | GLD-USO | {bb['apr']*100:.1f}% | {bb['sharpe']:.2f} | ìë³¸ ê´€ë¦¬ ìš©ì´ |\n")
        
        if 'scaling_in' in self.results and 'allin_z1' in self.results['scaling_in']:
            si = self.results['scaling_in']['allin_z1']
            report_lines.append(f"| ì˜¬ì¸ (Z=1) | GLD-USO | {si['apr']*100:.1f}% | {si['sharpe']:.2f} | ì´ë¡ ì  ìµœì  |\n")

        if 'scaling_in' in self.results and 'scale_in_z12' in self.results['scaling_in']:
            si2 = self.results['scaling_in']['scale_in_z12']
            report_lines.append(f"| ìŠ¤ì¼€ì¼ë§ ì¸ | GLD-USO | {si2['apr']*100:.1f}% | {si2['sharpe']:.2f} | ë³€ë™ì„± ì ì‘ |\n")

        if 'kalman' in self.results and 'ewa_ewc' in self.results['kalman']:
            kf = self.results['kalman']['ewa_ewc']
            report_lines.append(f"| ì¹¼ë§Œ í•„í„° | EWA-EWC | {kf['apr']*100:.1f}% | {kf['sharpe']:.2f} | ë™ì  í—¤ì§€ ë¹„ìœ¨ |\n")

        report_lines.append("\n")

        report_lines.append("### ğŸ’¡ íŠ¸ë ˆì´ë”© ê¶Œê³ ì‚¬í•­\n\n")
        report_lines.append("1. **ìŠ¤í”„ë ˆë“œ ìœ í˜• ì„ íƒ**:\n")
        report_lines.append("   - ê³µì ë¶„ í˜ì–´: ê°€ê²© ìŠ¤í”„ë ˆë“œ ë˜ëŠ” ë¡œê·¸ ê°€ê²© ìŠ¤í”„ë ˆë“œ ì‚¬ìš©\n")
        report_lines.append("   - ë¹„ê³µì ë¶„ í˜ì–´: ë™ì  í—¤ì§€ ë¹„ìœ¨ í•„ìˆ˜, ë¹„ìœ¨ì€ í”¼í•˜ê¸°\n\n")
        
        report_lines.append("2. **ë³¼ë¦°ì € ë°´ë“œ ì „ëµ**:\n")
        report_lines.append("   - ì„ í˜• ì „ëµì˜ ì‹¤ìš©ì  ëŒ€ì•ˆ\n")
        report_lines.append("   - Entry/Exit Z-ScoreëŠ” í›ˆë ¨ ë°ì´í„°ë¡œ ìµœì í™”\n\n")
        
        report_lines.append("3. **ì¹¼ë§Œ í•„í„° ì „ëµ**:\n")
        report_lines.append("   - ê³µì ë¶„ í˜ì–´ì—ì„œ ê°€ì¥ ìš°ìˆ˜í•œ ì„±ê³¼\n")
        report_lines.append("   - Î´ íŒŒë¼ë¯¸í„°ë¡œ í—¤ì§€ ë¹„ìœ¨ ë³€í™” ì†ë„ ì¡°ì ˆ\n\n")
        
        report_lines.append("### âš ï¸ ì£¼ì˜ì‚¬í•­\n\n")
        report_lines.append("- **ë°ì´í„° ì˜¤ë¥˜**: í‰ê·  íšŒê·€ ì „ëµì€ ì´ìƒì¹˜ì— íŠ¹íˆ ë¯¼ê° (ì˜ëª»ëœ ìˆ˜ìµ ë¶€í’€ë¦¬ê¸° ìœ„í—˜)\n")
        report_lines.append("- **ìŠ¤ì¼€ì¼ ì¸**: ì´ë¡ ì ìœ¼ë¡œ ìµœì ì´ ì•„ë‹ ìˆ˜ ìˆìœ¼ë‚˜, ì‹¤ì œë¡œëŠ” ë³€ë™ì„± ë³€í™”ì— ìœ ìš©\n")
        report_lines.append("- **ê±°ë˜ ë¹„ìš©**: ë³¸ ë°±í…ŒìŠ¤íŠ¸ì— ë¯¸í¬í•¨\n")
        report_lines.append("- **Look-ahead bias**: ì „ì²´ ë°ì´í„°ë¡œ íŒŒë¼ë¯¸í„° ê³„ì‚° í›„ ë™ì¼ ë°ì´í„°ë¡œ í…ŒìŠ¤íŠ¸\n\n")
        
        report_lines.append("---\n\n")
        report_lines.append("*ì´ ë¦¬í¬íŠ¸ëŠ” `run_chapter3_analysis.py`ì— ì˜í•´ ìë™ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤.*\n")
        
        # íŒŒì¼ ì €ì¥
        report_path = REPORT_DIR / "chapter3_report.md"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.writelines(report_lines)
            
        print(f"  âœ“ ë¦¬í¬íŠ¸ ì €ì¥: {report_path}")
        print(f"  âœ“ ì°¨íŠ¸ ì €ì¥: {FIGURES_DIR}")
        print()
        
    def run(self):
        """ì „ì²´ ë¶„ì„ ì‹¤í–‰"""
        print("\n" + "=" * 60)
        print("   Chapter 3: í‰ê·  íšŒê·€ ì „ëµ êµ¬í˜„ - ì¢…í•© ë¶„ì„")
        print("   Ernest Chan's Algorithmic Trading")
        print("=" * 60 + "\n")
        
        self.load_data()
        self.analyze_spread_types()
        self.analyze_bollinger_bands()
        self.analyze_scaling_in()
        self.analyze_kalman_filter()
        self.generate_report()
        
        print("=" * 60)
        print("âœ… ë¶„ì„ ì™„ë£Œ!")
        print("=" * 60)
        print(f"\nğŸ“ ë¦¬í¬íŠ¸ ìœ„ì¹˜: {REPORT_DIR / 'chapter3_report.md'}")
        print(f"ğŸ“Š ì°¨íŠ¸ ìœ„ì¹˜: {FIGURES_DIR}\n")


if __name__ == "__main__":
    analyzer = Chapter3Analyzer()
    analyzer.run()
