{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0c241021-a46b-43e2-b7bd-ccff15bca8b4",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "\n",
    "\n",
    "# 📘 히든 마르코프 모델 (HMM)이란?\n",
    "\n",
    "**HMM**은 시간적으로 순차적인 데이터를 대상으로, \\*\\*관측된 데이터 뒤에 숨겨진 상태(state)\\*\\*가 존재한다고 가정하고 이 상태 전이 과정을 추론하는 **확률 모델**입니다.\n",
    "\n",
    "> 즉, **관측값은 보이지만, 그 관측값을 생성한 상태(state)는 보이지 않는다**는 점에서 \"히든(hidden)\"입니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 기본 구성 요소\n",
    "\n",
    "HMM은 다음 5가지 구성 요소로 정의됩니다:\n",
    "\n",
    "| 기호                      | 설명                                                      |\n",
    "| ----------------------- | ------------------------------------------------------- |\n",
    "| $S = \\{s_1, ..., s_N\\}$ | 가능한 **숨겨진 상태 집합** (예: 상태 A, B)                          |\n",
    "| $O = \\{o_1, ..., o_T\\}$ | 실제 관측된 **관측값 시퀀스**                                      |\n",
    "| $A = [a_{ij}]$          | **상태 전이 확률 행렬**: $a_{ij} = P(s_{t+1} = j \\mid s_t = i)$ |\n",
    "| $B = [b_j(k)]$          | **관측 확률 분포**: 상태 $j$에서 관측값 $o_k$ 나올 확률                  |\n",
    "| $\\pi = [\\pi_i]$         | **초기 상태 확률**: $\\pi_i = P(s_1 = i)$                      |\n",
    "\n",
    "---\n",
    "\n",
    "## 📐 동작 개요\n",
    "\n",
    "1. 초기 상태 $s_1$을 확률 $\\pi$에 따라 선택\n",
    "2. 상태 $s_1$에서 관측값 $o_1$이 확률 $b_{s_1}(o_1)$로 출력\n",
    "3. $s_1$에서 $s_2$로 확률 $a_{12}$에 따라 전이\n",
    "4. 상태 $s_2$에서 $o_2$ 관측\n",
    "5. … 계속 반복하며 전체 시계열을 생성\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 예시: 음성 인식\n",
    "\n",
    "| 시간 | 실제 단어 상태 | 관측된 특징(스펙트럼) |\n",
    "| -- | -------- | ------------ |\n",
    "| 1  | \"he\"     | MFCC 벡터 1    |\n",
    "| 2  | \"llo\"    | MFCC 벡터 2    |\n",
    "\n",
    "HMM은 이 관측값 시퀀스를 보고 원래의 상태 시퀀스를 추론합니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 HMM의 세 가지 핵심 문제\n",
    "\n",
    "1. **평가 문제 (Evaluation)**\n",
    "\n",
    "   * 관측값 시퀀스가 주어졌을 때 이 시퀀스가 해당 모델에서 생성될 확률은?\n",
    "   * → **Forward Algorithm**\n",
    "\n",
    "2. **추론 문제 (Decoding)**\n",
    "\n",
    "   * 관측값 시퀀스를 생성한 가장 가능한 상태 시퀀스는?\n",
    "   * → **Viterbi Algorithm**\n",
    "\n",
    "3. **학습 문제 (Training)**\n",
    "\n",
    "   * 관측 시퀀스만 주어졌을 때 모델 파라미터 $A, B, \\pi$는 어떻게 추정하는가?\n",
    "   * → **Baum-Welch Algorithm (EM 알고리즘 기반)**\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ Classification에의 적용\n",
    "\n",
    "HMM은 일반적인 \"정적\" 분류기가 아니라 **\"시계열 패턴\"을 기반으로 시퀀스 전체의 클래스를 예측**합니다.\n",
    "\n",
    "### 💡 적용 방식:\n",
    "\n",
    "1. **각 클래스마다 별도의 HMM 모델 학습**\n",
    "\n",
    "   * 예: 단어 \"yes\" → HMM1, 단어 \"no\" → HMM2\n",
    "\n",
    "2. **테스트 시퀀스를 각 모델에 넣어 가장 높은 가능도(likelihood)를 가진 클래스로 분류**\n",
    "\n",
    "### 📦 예시 분야:\n",
    "\n",
    "| 분야           | 설명                 |\n",
    "| ------------ | ------------------ |\n",
    "| **음성 인식**    | 단어, 문장 등의 연속 패턴 인식 |\n",
    "| **필기 인식**    | 연속된 필기 선을 상태로 모델링  |\n",
    "| **유전자 분석**   | DNA 염기서열의 상태 변화 추정 |\n",
    "| **소매 패턴 분류** | 고객 행동 시퀀스 분석       |\n",
    "\n",
    "---\n",
    "\n",
    "## 🔁 다른 분류 모델과의 차이점\n",
    "\n",
    "| 항목        | HMM            | 일반 분류기 (SVM, RF 등) |\n",
    "| --------- | -------------- | ------------------ |\n",
    "| 입력 구조     | 시계열(순차) 데이터    | 독립된 개별 샘플          |\n",
    "| 시간성 반영    | ✅ (상태 전이 기반)   | ❌                  |\n",
    "| 클래스 예측 방식 | 시퀀스 전체 기반      | 각 샘플 단일 예측         |\n",
    "| 모델 학습 방식  | EM 기반 확률 추정    | 손실 함수 최적화          |\n",
    "| 해석력       | 중간 (상태 시각화 가능) | 낮음 또는 없음           |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 Python 예제 (`hmmlearn`)\n",
    "\n",
    "```python\n",
    "from hmmlearn import hmm\n",
    "import numpy as np\n",
    "\n",
    "# 예시: 연속 관측값을 가진 2상태 HMM\n",
    "model = hmm.GaussianHMM(n_components=2, covariance_type='diag', n_iter=100)\n",
    "\n",
    "# X: (n_samples, n_features)\n",
    "model.fit(X)\n",
    "log_prob = model.score(X)  # 관측 시퀀스의 확률 평가\n",
    "states = model.predict(X)  # 상태 추정\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 장점\n",
    "\n",
    "* 시간 순서를 고려한 예측 가능\n",
    "* 비정상적이고 상태 변화가 많은 데이터에 적합\n",
    "* 각 클래스의 **구조적 패턴** 모델링 가능\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ 단점\n",
    "\n",
    "* 대규모 피처에는 확장 어려움 (고차원성 저주)\n",
    "* 상태 수를 사전에 정해야 함\n",
    "* 학습 시간이 오래 걸릴 수 있음\n",
    "* 관측 모델이 가우시안에 국한될 경우 표현력 한계\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 결론\n",
    "\n",
    "**HMM은 단순한 \"현재 입력 → 예측\" 구조를 넘어서**,\n",
    "\\*\\*\"현재 입력은 어떤 상태에서 왔는가\"\\*\\*를 추론함으로써 **시간적 구조와 상태 변화를 함께 고려한 분류 모델**입니다.\n",
    "\n",
    "> ✅ 시계열 분류에 매우 강력\n",
    "> ✅ 각 클래스의 동작 패턴을 모델링할 수 있음\n",
    "> ✅ 음성, 필기, 생물정보학 등 순차 데이터 분야에서 전통적으로 매우 강력한 접근 방식\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ccce30-f174-49f0-b6fe-163ef6007b36",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
