{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "![QuantConnect Logo](https://cdn.quantconnect.com/web/i/icon.png)\n",
    "<hr>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "class Project:\n",
    "    def __init__(\n",
    "            self, id, backtest_id, \n",
    "            benchmark_symbol=Symbol.create(\"SPY\", SecurityType.EQUITY, Market.USA),\n",
    "            plot_crisis_events=True, optimization_id=None, optimization_notes=''\n",
    "        ):\n",
    "        self.id = id\n",
    "        self.backtest_id = backtest_id\n",
    "        self.benchmark_symbol = benchmark_symbol\n",
    "        self.plot_crisis_events = plot_crisis_events\n",
    "        self.optimization_id = optimization_id\n",
    "        self.optimization_notes = optimization_notes\n",
    "\n",
    "projects = [\n",
    "    # 5 - LLM Summarization of Tiingo News Articles\n",
    "    Project(\n",
    "        id=17310192, \n",
    "        backtest_id='a674e08e0a2400a91a1687912784994d',\n",
    "        benchmark_symbol=Symbol.create(\"TSLA\", SecurityType.EQUITY, Market.USA),\n",
    "        plot_crisis_events=False\n",
    "    ),\n",
    "\n",
    "    # 6 - CNN Pattern Detection\n",
    "    Project(\n",
    "        id=16864087, \n",
    "        backtest_id='bc52b37ec178125138ecea86d87cb820', \n",
    "        benchmark_symbol=Symbol.create(\"USDCAD\", SecurityType.FOREX, Market.OANDA),\n",
    "        optimization_id='O-748d5fa9f4c7ae4e44004eb588ce53f2',\n",
    "        optimization_notes=\"\"\"\n",
    "Parameter `confidence_threshold`:\n",
    "- The minimum is 0.3 because going lower than that means <30% confident we found the pattern, which is quite low/unlikely.\n",
    "- The maximum is 0.9 because there are already only a few trades.\n",
    "- The step size is 0.1 because it leads to nice round values.\n",
    "\n",
    "Parameter `holding_period`:\n",
    "- The minimum is 2 because it's the shortest holding period with daily data.\n",
    "- The maximum is 10 because ...\n",
    "- The step size is 1 because it's the smallest possible step size.\n",
    "\n",
    "The results show:\n",
    "- The Sharpe ratio increases with the holding period.\n",
    "- The Sharpe ratio decreases with the confidence threshold (probably since there are so few trades).\n",
    "- All parameter combinations are profitable.\n",
    "\"\"\"\n",
    "    ),  \n",
    "\n",
    "    # 7 - SVM Wavelet Forecasting\n",
    "    Project(\n",
    "        id=16900481, \n",
    "        backtest_id='2ea6c390f7fb12c080280d11807d74a6', \n",
    "        benchmark_symbol=Symbol.create(\"EURUSD\", SecurityType.FOREX, Market.OANDA),\n",
    "        optimization_id='O-0dc7eb2eeaf2487a2180ccdf28958ef9',\n",
    "        optimization_notes=\"\"\"\n",
    "Parameter `period`:\n",
    "- The minimum is 63 because it's 3 months of trading days.\n",
    "- The maximum is 189 because it's 9 months of trading days.\n",
    "- The step size is 21 because it's 1 month of trading days.\n",
    "\n",
    "Parameter `weight_threshold`:\n",
    "- The minimum is 0.002 because ...\n",
    "- The maximum is 0.007 because ...\n",
    "- The step size is 0.001 because ...\n",
    "\n",
    "The results show:\n",
    "- The Sharpe ratio is maximized with a `period` of 8 months, but results are quite volatile between each consecutive period (high sensitivity).\n",
    "- The Sharpe ratio is typically greater with weight_threshold > 0.004 rather than <= 0.004.\n",
    "\"\"\"\n",
    "    ), \n",
    "\n",
    "    # 8 - PCA Statistical Arbitrage Mean Reversion\n",
    "    Project(\n",
    "        id=16900810, \n",
    "        backtest_id='5fa5170284639c164862b17056980686', \n",
    "        optimization_id='O-c0e0723996c41ee8b03651d45ab1ba77',\n",
    "        optimization_notes=\"\"\"\n",
    "Parameter `num_components`:\n",
    "- The minimum is 2 because it's the minimum number to perform multiple linear regression.\n",
    "- The maximum is 6 because each consecutive component explains less of the variance in the data.\n",
    "   The first 3 components already explain over 90% of the variance and each additional component explains less than the previous component.\n",
    "- The step size is 1 because it's the smallest possible step size.\n",
    "\n",
    "Parameter `lookback_days`:\n",
    "- The minimum is 21 because it's 1 month of trading days.\n",
    "- The maximum is 126 because it's 6 months of trading days.\n",
    "- The step size is 21 because it's the smallest step possible.\n",
    "\n",
    "The results show:\n",
    "- The Sharpe ratio is maximized when num_components=3 and lookback_days=126 (6 months).\n",
    "- The Sharpe ratio is typically the lowest when using 3/4 months for lookback_days.\n",
    "- All parameter combinations are profitable.\n",
    "\"\"\"\n",
    "    ), \n",
    "\n",
    "    # 9 - Temporal CNN Prediction\n",
    "    Project(\n",
    "        id=16902731, \n",
    "        backtest_id='daa9e7d0127abcb67e7b4cfb7bc2c55e', \n",
    "        benchmark_symbol=Symbol.create(\"QQQ\", SecurityType.EQUITY, Market.USA),\n",
    "        optimization_id='O-4be61675a7719b697380e6cd734fe9b8',\n",
    "        optimization_notes=\"\"\"\n",
    "Parameter `training_samples`:\n",
    "- The minimum is 300 because it's slightly longer than the number of trading days per year.\n",
    "- The maximum is 700 because it's large but not too large to cause the model training to be too slow.\n",
    "- The step size is 100 because it generates nice round numbers.\n",
    "\n",
    "Parameter `universe_size`:\n",
    "- The minimum is 2 because we want the algorithm to be always invested.\n",
    "   If there is only 1 asset and the model predicts a stationary direction, the algorithm will be uninvested for some of the rebalances.\n",
    "- The maximum is 10 because the algorithm would take longer than an hour to backtest if we use more than 10.\n",
    "- The step size is 2 because it gives us 5 different values of universe_size between 2 and 10.\n",
    "\n",
    "The results show:\n",
    "- The Sharpe ratio typically increases as we increase the number of training samples.\n",
    "- Most parameter combinations are unprofitable.\n",
    "\"\"\"\n",
    "    ), \n",
    "\n",
    "    # 10 - Gaussian Naive Bayes Classifier\n",
    "    Project(\n",
    "        id=16904128, \n",
    "        backtest_id='fab631d97b8e09d73120482f2b092ec7', \n",
    "        optimization_id='O-8e9a3817e0789fae3380f5aac2223c94',\n",
    "        optimization_notes=\"\"\"\n",
    "Parameter `days_per_sample`:\n",
    "- The minimum is 2 because then we have 2 factors for each asset instead of just 1.\n",
    "- The maximum is 8 because anything larger may cause the number of factors to be so large that it floods the model with noise.\n",
    "- The step size is 1 because it's the smallest possible step size.\n",
    "\n",
    "Parameter `universe_size`:\n",
    "- The minimum is 5 because anything smaller may cause the algorithm to resort to just cash during one of the rebalances.\n",
    "- The maximum is 25 because because including too many assets in the universe will cause the number of independent variables in the ML model to grow very large.\n",
    "- The step size is 5 because it leads to nice round numbers between the minimum and maximum.\n",
    "\n",
    "The results show:\n",
    "- The Sharpe ratio is greatest with a small universe size (5).\n",
    "   It's probably because as the universe grows, the number of independent variables in the ML model grows, potentially overwhelming the model with noise and not allowing it to learn.\n",
    "- All parameter combinations are profitable.\n",
    "\"\"\"\n",
    "    ),  \n",
    "\n",
    "    # 11 - Inverse Volatility Rank and Allocate to Future Contracts\n",
    "    Project(\n",
    "        id=16912977, \n",
    "        backtest_id='6397adabaf38d92024f28d2ebf2efdac', \n",
    "        optimization_id='O-015437ee1b51321222f7d0b39dff7e56',\n",
    "        optimization_notes=\"\"\"\n",
    "Parameter `std_months`:\n",
    "- The minimum is 1 because it's the smallest possible integer.\n",
    "- The maximum is 6 because it's half a year.\n",
    "- The step size is 1 because it's the smallest possible step size.\n",
    "\n",
    "Parameter `atr_months`:\n",
    "- The minimum is 1 because it's the smallest possible integer.\n",
    "- The maximum is 6 because it's half a year.\n",
    "- The step size is 1 because it's the smallest possible step size.\n",
    "\n",
    "The results show:\n",
    "- The Sharpe ratio is typically highest when at least one of the indicators uses a 6 month lookback.\n",
    "- The Sharpe ratio is typically lowest when at least one of the indicators uses a 3 month lookback.\n",
    "- All parameter combinations are profitable.\n",
    "\"\"\"\n",
    "    ),  \n",
    "\n",
    "    # 12 - Stock Selection through Clustering Fundamental Data\n",
    "    Project(\n",
    "        id=17072432, \n",
    "        backtest_id='36d60e3783e741074ec43227c6892c5a',\n",
    "        optimization_id='O-c52a45d53bd142ee25e790c5d44104a3',\n",
    "        optimization_notes=\"\"\"\n",
    "Parameter `final_universe_size`:\n",
    "- The minimum is 5 because anything smaller will concentrate the portfolio in very few assets.\n",
    "- The maximum is 25 because it makes the universe select the top quartile of assets, which is a common approach in practice.\n",
    "- The step size is 5 because it leads to round numbers that traders would likely choose.\n",
    "\n",
    "Parameter `components`:\n",
    "- The minimum is 3 because the first 3 components typically explain >= 80% of the variation in the data. \n",
    "- The maximum is 7 because each additional component explains less of the variation in the data.\n",
    "- The step size is 1 because it's the smallest possible step size.\n",
    "\n",
    "The results show:\n",
    "- The greatest Sharpe ratio was achieved by using the smallest value for both parameters.\n",
    "- All the Sharpe ratios are >= 0.\n",
    "- The performance can be sensitive to small changes in the `components` parameter. Changing it from 3 to 4 when the universe size is 5 drops the Sharpe ratio from 0.45 to 0.09.\n",
    "\"\"\"\n",
    "    ),\n",
    "\n",
    "    # 13 - Income Harvesting Selection of High-Yield Assets\n",
    "    Project(\n",
    "        id=17347025, \n",
    "        backtest_id='1b6e5ed9266c520307a2d5658ed3a661', \n",
    "        benchmark_symbol=Symbol.create(\"QQQ\", SecurityType.EQUITY, Market.USA),\n",
    "        optimization_id='O-adaf8a85c0dcc490beb630a8da0df31d',\n",
    "        optimization_notes=\"\"\"\n",
    "Parameter `universe_size`:\n",
    "- The minimum is 20 so that at least 1 asset will have a dividend payment.\n",
    "- The maximum is 100 to select all assets in the QQQ ETF (the universe).\n",
    "- The step size is 20 because it leads to round numbers.\n",
    "\n",
    "Parameter `lookback_years`:\n",
    "- The minimum is 4 because dividend payments don't happen very frequently. \n",
    "- The maximum is 8 because anything further into the past may no longer be relevant.\n",
    "- The step size is 1 because it's the smallest possible step size.\n",
    "\n",
    "The results show:\n",
    "- The Sharpe ratio only ranges from 0.476 to 0.617.\n",
    "- The Sharpe ratio is typically greater with a larger universe.\n",
    "- The results are more sensitive to changes in universe size than lookback years.\n",
    "- All parameter combinations lead to a positive Sharpe ratio.\n",
    "\"\"\"\n",
    "    ),   \n",
    "\n",
    "    # 14 - Effect of Positive-Negative Splits\n",
    "    Project(\n",
    "        id=17072779, \n",
    "        backtest_id='de53aed9aec5e97c67cfd2eb8a96961d',\n",
    "        benchmark_symbol=Symbol.create(\"XLK\", SecurityType.EQUITY, Market.USA),\n",
    "        optimization_id='O-b3ef4e39cee33ebe82a27204ed79fc46',\n",
    "        optimization_notes=\"\"\"\n",
    "Parameter `hold_duration`:\n",
    "- The minimum is 1 because it's the smallest positive integer.\n",
    "- The maximum is 5 because it equals 1 trading week.\n",
    "- The step size is 1 because it's the smallest possible step size.\n",
    "\n",
    "Parameter `training_lookback_years`:\n",
    "- The minimum is 3 because splits payments don't happen very frequently. \n",
    "- The maximum is 6 because anything further into the past may no longer be relevant.\n",
    "- The step size is 1 because it's the smallest possible step size.\n",
    "\n",
    "The results show:\n",
    "- A hold_duration of 3 days generates the greatest Sharpe ratio.\n",
    "- All the Sharpe ratios are >= 0.7\n",
    "\"\"\"\n",
    "    ),\n",
    "\n",
    "    # 15 - Stoploss Based on Historical Volatility and Drawdown Recovery/Part I - Benchmark - Fixed Percentage Stop Loss\n",
    "    Project(\n",
    "        id=17110876, \n",
    "        backtest_id='1d2616acd0e6b09aef1c82029717a57d',\n",
    "        benchmark_symbol=Symbol.create(\"KO\", SecurityType.EQUITY, Market.USA),\n",
    "        optimization_id='O-d29a5dc1cd9f5559a52160c41a2fc1e3',\n",
    "        optimization_notes=\"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "    ),   \n",
    "    \n",
    "    # 15 - Stoploss Based on Historical Volatility and Drawdown Recovery/Part II - ML Placed Stop Loss\n",
    "    Project(\n",
    "        id=17110845, \n",
    "        backtest_id='5a0736c211678b1fb1e579dbbd5f0799',\n",
    "        benchmark_symbol=Symbol.create(\"KO\", SecurityType.EQUITY, Market.USA),\n",
    "        optimization_id='O-51337d9dbbc7f2306eba204c4677be6b',\n",
    "        optimization_notes=\"\"\"\n",
    "TODO\n",
    "\"\"\"\n",
    "    ), \n",
    "    \n",
    "    # 15 - Stoploss Based on Historical Volatility and Drawdown Recovery/Part III - ML Put Option Hedge\n",
    "    Project(\n",
    "        id=17112124, \n",
    "        backtest_id='34ffe08e24db5560f95543e15ffed055',\n",
    "        benchmark_symbol=Symbol.create(\"KO\", SecurityType.EQUITY, Market.USA)\n",
    "    ),\n",
    "\n",
    "    # 16 - Hidden Markov Models/Part I - Equities\n",
    "    Project(\n",
    "        id=17126276, \n",
    "        backtest_id='3a6858927d4a246fdaa6c552f94b70de',\n",
    "        optimization_id='O-51f4ef88e9e49448f93d01e660273010',\n",
    "        optimization_notes=\"\"\"\n",
    "Parameter `lookback_years`:\n",
    "- The minimum is 1 because it's the smallest positive integer.\n",
    "- The maximum is 10 because data older than 10 years may no longer be relevant.\n",
    "- The step size is 1 because it's the smallest possible step size.\n",
    "\n",
    "The results show:\n",
    "- A lookback period of 4 years achieves the greatest Sharpe ratio.\n",
    "- The Sharpe ratio is very sensitive to changes in the lookback period.\n",
    "- A lookback perio do of 1 year leads to a negative Sharpe ratio.\n",
    "\"\"\"\n",
    "    ), \n",
    "\n",
    "    # 16 - Hidden Markov Models/Part II - Equity Options\n",
    "    Project(\n",
    "        id=17127820, \n",
    "        backtest_id='61b92c7c354b07992cbc3c8dbd491123' #'3618a2dd31eb7d6c7b1c6417ab65fab7'\n",
    "    ),\n",
    "    \n",
    "    # 16 - Hidden Markov Models/Part III - Index Options\n",
    "    Project(\n",
    "        id=17130231, \n",
    "        backtest_id='b42d5a7481a139b070449cf99f599d1a' # 'c5bf6111afa762cc4c2eabefb3a16547'\n",
    "    ),\n",
    "\n",
    "    ## 17 - ML Trade Costs Estimation\n",
    "    #Project(\n",
    "    #    id=17436014, \n",
    "    #    backtest_id='a9fbf386e7ce1c652cc4f49dae00253f'\n",
    "    #)\n",
    "\n",
    "    # HuggingFace Examples/I - Time Series Base Model\n",
    "    Project(\n",
    "        id=18263191, \n",
    "        backtest_id='0b3a0e7c3ad7ae8a1078d8e009822041'\n",
    "    ),\n",
    "\n",
    "    # HuggingFace Examples/II - Time Series Fine-Tuned Model\n",
    "    Project(\n",
    "        id=18254122, \n",
    "        backtest_id='f8a5822e4a9c7cc3365183bf31e45add'\n",
    "    ),   \n",
    "\n",
    "    # HuggingFace Examples/III - FinBert Base Model\n",
    "    Project(\n",
    "        id=18254451, \n",
    "        backtest_id='a9821c34f0ae57165f57c04a9f071772'\n",
    "    ),   \n",
    "\n",
    "    # HuggingFace Examples//IV - FinBert Fine Tuned Model\n",
    "    Project(\n",
    "        id=18345538, \n",
    "        backtest_id='80078cc9a62717e853e1a24e0fa518e3'\n",
    "    )    \n",
    "]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Tearsheets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mplfinance as mpf\n",
    "import matplotlib.dates as mdates\n",
    "import matplotlib.gridspec as gridspec\n",
    "import matplotlib.colors as mcolors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "import pytz\n",
    "import seaborn as sns\n",
    "\n",
    "# Set the theme\n",
    "blue_color = '#2A72C0'\n",
    "orange_color = '#ED7F12'\n",
    "gray_color = '#A1A2B7'\n",
    "background_color = '#EDEEF2'\n",
    "\n",
    "sns.set_palette(\n",
    "    [\n",
    "        blue_color, orange_color, gray_color, '#E01B1B', '#33B120',\n",
    "        '#E0C60D', '#8F14C6', '#A23B72', '#B86F52', '#455A64'\n",
    "    ]\n",
    ")\n",
    "plt.rcParams['lines.linewidth'] = 1\n",
    "\n",
    "qb = QuantBook()\n",
    "\n",
    "def line_style_by_series_index(idx):\n",
    "    if idx < 3:\n",
    "        return 'solid'\n",
    "    elif idx < 6:\n",
    "        return 'dotted'\n",
    "    elif idx < 9:\n",
    "        return 'dashed'\n",
    "    return 'dashdot'\n",
    "\n",
    "def find_worst_drawdowns(drawdown_series, n=5):\n",
    "    # Find all the drawdown start and end points\n",
    "    in_drawdown = False\n",
    "    drawdown_periods = []\n",
    "    start = None\n",
    "    for t in drawdown_series.index:\n",
    "        if drawdown_series[t] < 0 and not in_drawdown:\n",
    "            # Start of a drawdown\n",
    "            in_drawdown = True\n",
    "            start = t\n",
    "        elif drawdown_series[t] == 0 and in_drawdown:\n",
    "            # End of a drawdown\n",
    "            in_drawdown = False\n",
    "            end = t\n",
    "            drawdown_periods.append((start, end, drawdown_series[start:end].min()))\n",
    "    \n",
    "    # If still in drawdown at the end of the series\n",
    "    if in_drawdown and start is not None:\n",
    "        end = drawdown_series.index[-1]\n",
    "        drawdown_periods.append((start, end, drawdown_series[start:end].min()))\n",
    "    \n",
    "    # Sort drawdowns by the magnitude (the third element in each tuple)\n",
    "    drawdown_periods = sorted(drawdown_periods, key=lambda x: x[2])\n",
    "    \n",
    "    # Return the n worst drawdowns\n",
    "    return drawdown_periods[:n]\n",
    "\n",
    "excluded_charts = [\n",
    "    'Benchmark', 'Portfolio Margin', 'Assets Sales Volume',\n",
    "    'Portfolio Turnover', 'Capacity', \n",
    "]\n",
    "# Not excluding: 'Strategy Equity', 'Exposure', 'Drawdown'\n",
    "\n",
    "excluded_series_by_chart = {'Strategy Equity': ['Return']}\n",
    "\n",
    "# Define crisis events\n",
    "timezone = pytz.timezone('US/Eastern')\n",
    "crisis_events = {\n",
    "    \"COVID-19 Pandemic 2020\": (datetime(2020, 2, 10), datetime(2020, 6, 9)),\n",
    "    \"Oil Goes Negative 2020\": (datetime(2020, 4, 14), datetime(2020, 4, 30)),\n",
    "    \"Post-COVID Run-up 2020-2021\": (datetime(2020, 4, 1), datetime(2022, 1, 1)),\n",
    "    \"Meme Season 2021\": (datetime(2021, 1, 1), datetime(2021, 5, 15)),\n",
    "    \"Russian Ruble Collapse 2022\": (datetime(2022, 2, 21), datetime(2022, 3, 17)),\n",
    "    \"AI Boom 2022-Present\": (datetime(2023, 10, 30), datetime.now())\n",
    "}\n",
    "crisis_events = {\n",
    "    title: (timezone.localize(start_date), timezone.localize(end_date)) \n",
    "    for title, (start_date, end_date) in crisis_events.items()\n",
    "}\n",
    "\n",
    "earliest_start_time = timezone.localize(datetime(2019, 1, 1))\n",
    "\n",
    "for j, project in enumerate(projects):\n",
    "    if j not in [1]:\n",
    "        continue\n",
    "\n",
    "    ## Get benchmark equity curve\n",
    "    benchmark_history = qb.history(project.benchmark_symbol, datetime(2019, 1, 1), datetime.now(), Resolution.DAILY)\n",
    "    benchmark_equity = benchmark_history.loc[project.benchmark_symbol]['close']\n",
    "    benchmark_equity.index = pd.to_datetime(benchmark_equity.index).tz_localize(timezone).tz_convert(timezone)\n",
    "\n",
    "    project_name = api.read_project(project.id).projects[0].name\n",
    "    print(f\"{project_name}\")\n",
    "    backtest = api.read_backtest(project.id, project.backtest_id)\n",
    "\n",
    "    # Get the backtest charts.\n",
    "    charts = {}\n",
    "    for kvp in backtest.charts:\n",
    "        chart_name = kvp.key\n",
    "        if chart_name in excluded_charts:\n",
    "            continue\n",
    "        charts[chart_name] = (chart_name, kvp.value)\n",
    "\n",
    "    # Sort charts so that the default ones always come first\n",
    "    desired_order = ['Strategy Equity', 'Drawdown', 'Exposure']\n",
    "    ordered_charts = [charts[name] for name in desired_order]\n",
    "    for chart_name, chart_data in charts.items():\n",
    "        if chart_name not in desired_order:\n",
    "            ordered_charts.append(chart_data)\n",
    "    subplot_titles = [name for name, _ in ordered_charts]\n",
    "\n",
    "    # Create subplots\n",
    "    fig = plt.figure(figsize=(10, 2*len(ordered_charts)))\n",
    "    axes = []\n",
    "    rows = len(subplot_titles)\n",
    "\n",
    "    # Create a GridSpec layout with n rows and 6 columns\n",
    "    full_width = 3\n",
    "    height_ratios = (\n",
    "        [1.5]                         # 1.5 units for Equity curve plot\n",
    "        + [1]*(len(subplot_titles)-1) # 1 unit for each of the standard charts\n",
    "    )\n",
    "    gs = gridspec.GridSpec(rows, full_width, height_ratios=height_ratios)\n",
    "    # n rows for the standard and custom charts\n",
    "    for row_index, _ in enumerate(subplot_titles):\n",
    "        axes.append(fig.add_subplot(gs[row_index, 0:full_width]))\n",
    "\n",
    "    for i, (chart_name, chart) in enumerate(ordered_charts):    \n",
    "        for k, kvp1 in enumerate(chart.series):\n",
    "            series_name = kvp1.key\n",
    "            secondary_y = (\n",
    "                chart_name == 'HS Patterns Detected' and \n",
    "                series_name == 'Window Length' #in ['End of Pattern Detected', 'USDCAD Price']\n",
    "            )\n",
    "            yaxis_title = 'Value'\n",
    "            if secondary_y:\n",
    "                yaxis_title = 'Window Length' # 'USDCAD Price'\n",
    "            elif chart_name == 'HS Patterns Detected':\n",
    "                yaxis_title = 'USDCAD Price'  # 'Window Length'\n",
    "\n",
    "            if (chart_name in excluded_series_by_chart and\n",
    "                series_name in excluded_series_by_chart[chart_name]):\n",
    "                continue\n",
    "\n",
    "            series = kvp1.value\n",
    "            x = []\n",
    "            y = []\n",
    "            for point in series.values:\n",
    "                if series.series_type == SeriesType.CANDLE:\n",
    "                    x_i = point.long_time\n",
    "                    y_i = (point.open, point.high, point.low, point.close)\n",
    "                else:\n",
    "                    x_i = point.x\n",
    "                    y_i = point.y\n",
    "                # Convert Unix time to Eastern time.\n",
    "                x_i = datetime.utcfromtimestamp(x_i).replace(\n",
    "                    tzinfo=pytz.utc).astimezone(pytz.timezone('US/Eastern'))\n",
    "                if x_i < earliest_start_time:\n",
    "                    continue\n",
    "                x.append(x_i)\n",
    "                y.append(y_i)\n",
    "\n",
    "            if chart_name == \"Strategy Equity\":\n",
    "               series.series_type = SeriesType.LINE \n",
    "               y = np.array(y)[:, 3]\n",
    "               algorithm_equity = pd.Series(y, index=pd.DatetimeIndex(x))\n",
    "\n",
    "            if chart_name == 'Exposure': # Drop the first couple data points\n",
    "                x = x[2:]\n",
    "                y = y[2:]\n",
    "\n",
    "            if series.series_type == SeriesType.LINE:\n",
    "                if chart_name in [\"Strategy Equity\", \"Drawdown\"]:\n",
    "                    axes[i].plot(x, y, label=series_name, color=blue_color)\n",
    "                else:\n",
    "                    axes[i].plot(x, y, linestyle=line_style_by_series_index(k), label=series_name)\n",
    "            elif series.series_type == SeriesType.SCATTER:\n",
    "                if secondary_y:\n",
    "                    ax = axes[i].twinx() \n",
    "                    ax.scatter(x, y, label=series_name, color=orange_color)\n",
    "                else: \n",
    "                    ax = axes[i]\n",
    "                    ax.scatter(x, y, label=series_name, color=gray_color)\n",
    "            elif series.series_type == SeriesType.CANDLE:\n",
    "                y = np.array(y)\n",
    "                mpf.plot(pd.DataFrame(y, index=pd.DatetimeIndex(x), columns=['open', 'high', 'low', 'close']), type='candle', ax=axes[i], show_nontrading=True)\n",
    "            else:\n",
    "                raise Exception(\"Unhandled series type\")\n",
    "\n",
    "            # Add the benchmark equity curve to the plot\n",
    "            if chart_name == \"Strategy Equity\":\n",
    "                aligned_benchmark_curve = benchmark_equity[\n",
    "                    (benchmark_equity.index >= algorithm_equity.index[0]) &\n",
    "                    (benchmark_equity.index <= algorithm_equity.index[-1])\n",
    "                ]\n",
    "                aligned_benchmark_curve *= (y[0] / aligned_benchmark_curve.iloc[0])\n",
    "                axes[i].plot(aligned_benchmark_curve, label=f'Benchmark ({project.benchmark_symbol.value})', color=gray_color)\n",
    "\n",
    "            ax = ax if secondary_y else axes[i]\n",
    "            ax.set_ylabel(yaxis_title)\n",
    "            if series.series_type == SeriesType.CANDLE:\n",
    "                ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "                ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "                ax.set_xticklabels(ax.get_xticklabels(), rotation=0)\n",
    "            else:\n",
    "                ax.legend()\n",
    "            ax.set_title(chart_name)\n",
    "            ax.grid(True, which='both', linewidth=0.7, color='#FFFFFF')\n",
    "            ax.set_facecolor(background_color)\n",
    "\n",
    "            # Only show the x-axis labels and ticks for the bottom plot\n",
    "            if i == len(ordered_charts) - 1:\n",
    "                ax.set_xlabel('Date')\n",
    "            else:\n",
    "                ax.set_xticklabels([])\n",
    "\n",
    "            # Highlight the 5 worst drawdowns\n",
    "            if chart_name == 'Drawdown': \n",
    "                # Find the 5 worst drawdowns\n",
    "                worst_drawdowns = find_worst_drawdowns(pd.Series(y, index=x), n=5)\n",
    "                alphas = [0.15, 0.24, 0.36, 0.48, 0.68]\n",
    "                for k, (start, end, _) in enumerate(worst_drawdowns[::-1]):\n",
    "                    ax.axvspan(start, end, color=(240/255, 18/255, 18/255, alphas[k]))\n",
    "\n",
    "    ## Update the layout and show the plot.    \n",
    "    #fig.suptitle(f\"Tearsheet for Project \\\"{project_name}\\\"\", fontsize=12, x=0.0, y=1, ha='left')\n",
    "    plt.subplots_adjust(left=0.05, right=0.95, top=0.975, hspace=0.4)  # Adjust spacing between plots and add top margin\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "    height = (\n",
    "        4\n",
    "        + (4 if project.plot_crisis_events else 0)\n",
    "        + (4 if project.optimization_id else 0)\n",
    "    )\n",
    "    # Create subplots\n",
    "    fig = plt.figure(figsize=(10, height))\n",
    "    axes = []\n",
    "    crisis_event_rows = 2\n",
    "    rows = (\n",
    "        + 1                                                        # Monthly returns heatmap\n",
    "        + (crisis_event_rows if project.plot_crisis_events else 0) # Crisis events\n",
    "        + int(project.optimization_id is not None)                 # Optimization heatmap \n",
    "    )\n",
    "\n",
    "    # Create a GridSpec layout with n rows and 6 columns\n",
    "    full_width = 3\n",
    "    height_ratios = (\n",
    "        [2.5]                       # 2.5 units for the monthly returns heatmap\n",
    "        + ([2, 2] if project.plot_crisis_events else []) # 2 units for the crisis plots\n",
    "        + ([2.5] if project.optimization_id else []) # 2.5 units for the optimization heatmap\n",
    "    )\n",
    "    gs = gridspec.GridSpec(rows, full_width, height_ratios=height_ratios)\n",
    "    # 1 row for the monthly returns heatmap\n",
    "    row_index = 0\n",
    "    axes.append(fig.add_subplot(gs[row_index, 0:full_width]))\n",
    "    # n row for the crisis events \n",
    "    if project.plot_crisis_events:\n",
    "        for _ in range(crisis_event_rows):\n",
    "            row_index += 1\n",
    "            for start_index in range(3):\n",
    "                axes.append(fig.add_subplot(gs[row_index, start_index:start_index+1]))\n",
    "    # 1 row for the optimization heatmap (if there is an optimziation)\n",
    "    if project.optimization_id:\n",
    "        row_index += 1\n",
    "        axes.append(fig.add_subplot(gs[row_index, 0:full_width]))\n",
    "\n",
    "    ## Monthly Returns\n",
    "    monthly_closes = algorithm_equity.resample('M').last()\n",
    "    # Calculate monthly returns\n",
    "    monthly_returns = monthly_closes.pct_change().dropna() * 100\n",
    "    # Calculate the return for the first month\n",
    "    first_month_return = (monthly_closes.iloc[0] / algorithm_equity.iloc[0] - 1) * 100\n",
    "    # Prepend the first month's return to the monthly_returns series\n",
    "    first_month_series = pd.Series([first_month_return], index=[monthly_closes.index[0]])\n",
    "    monthly_returns = pd.concat([first_month_series, monthly_returns])\n",
    "    # Convert PeriodIndex to DatetimeIndex for year and month extraction\n",
    "    monthly_returns.index = pd.DatetimeIndex(monthly_returns.index)\n",
    "    # Create a DataFrame to pivot for the heatmap\n",
    "    monthly_returns_df = monthly_returns.to_frame(name='Returns')\n",
    "    monthly_returns_df['Year'] = monthly_returns_df.index.year\n",
    "    monthly_returns_df['Month'] = monthly_returns_df.index.month\n",
    "    # Pivot the DataFrame to get a matrix format suitable for a heatmap\n",
    "    returns_pivot = monthly_returns_df.pivot(index='Year', columns='Month', values='Returns')\n",
    "    # Reindex to ensure all months are included\n",
    "    all_months = np.arange(1, 13)\n",
    "    returns_pivot = returns_pivot.reindex(columns=all_months)\n",
    "    # Plot the heatmap\n",
    "    ax = axes[0]\n",
    "    # Create a heatmap\n",
    "    # Define the colors and positions\n",
    "    colors = [(240/255, 18/255, 18/255), (1, 1, 1), (28/255, 177/255, 86/255)]  # Red, Yellow, Green\n",
    "    positions = [0, 0.5, 1]  # Positions for the colors\n",
    "    cmap = LinearSegmentedColormap.from_list('red_yellow_green', list(zip(positions, colors)))\n",
    "    abs_max = monthly_returns.abs().max()\n",
    "    cax = ax.matshow(returns_pivot, cmap=cmap, vmin=-abs_max, vmax=abs_max, aspect='auto')\n",
    "    # Set the axis labels\n",
    "    ax.set_xlabel('Month')\n",
    "    ax.set_ylabel('Year')\n",
    "    ax.set_title('Monthly Returns (%)')\n",
    "    # Set x-axis ticks\n",
    "    ax.set_xticks(np.arange(12))\n",
    "    ax.set_xticklabels(['Jan', 'Feb', 'Mar', 'Apr', 'May', 'Jun', 'Jul', 'Aug', 'Sep', 'Oct', 'Nov', 'Dec'])\n",
    "    ax.xaxis.set_ticks_position('bottom')  # Move ticks to the bottom\n",
    "    # Set y-axis ticks\n",
    "    ax.set_yticks(np.arange(len(returns_pivot.index)))\n",
    "    ax.set_yticklabels(returns_pivot.index)\n",
    "    # Annotate each cell with the numeric value\n",
    "    for (i, k), val in np.ndenumerate(returns_pivot):\n",
    "        if not np.isnan(val):\n",
    "            ax.text(k, i, f'{val:.2f}', ha='center', va='center', color='black')\n",
    "    ax.grid(False)\n",
    "\n",
    "    # Plot each crisis event\n",
    "    if project.plot_crisis_events:\n",
    "        for i, (title, (start_date, end_date)) in enumerate(crisis_events.items()):\n",
    "            filtered_algorithm = algorithm_equity[\n",
    "                (algorithm_equity.index >= start_date) & \n",
    "                (algorithm_equity.index <= end_date)\n",
    "            ]\n",
    "            filtered_benchmark = benchmark_equity[\n",
    "                (benchmark_equity.index >= start_date) & \n",
    "                (benchmark_equity.index <= end_date) & \n",
    "                (benchmark_equity.index <= algorithm_equity.index[-1])\n",
    "            ]\n",
    "\n",
    "            if not filtered_algorithm.empty and not filtered_benchmark.empty:\n",
    "                normalized_curve = filtered_algorithm / filtered_algorithm.iloc[0]\n",
    "                normalized_benchmark = filtered_benchmark / filtered_benchmark.iloc[0]\n",
    "                ax = axes[i + 1]\n",
    "                ax.plot(normalized_curve, label='Algorithm')\n",
    "                ax.plot(normalized_benchmark, label=f'Benchmark ({project.benchmark_symbol.value})', color=gray_color)\n",
    "                ax.set_title(f\"{title}\")\n",
    "                ax.set_xticklabels([])\n",
    "                ax.set_yticklabels([])\n",
    "                ax.set_facecolor(background_color)\n",
    "                ax.legend()\n",
    "                ax.grid(True, which='both', linewidth=0.7, color='#FFFFFF')\n",
    "    \n",
    "    ## Plot optimization heatmap\n",
    "    if project.optimization_id:\n",
    "        # Get the optimization results.\n",
    "        optimization = api.read_optimization(project.optimization_id)\n",
    "        optimization_results = pd.DataFrame()\n",
    "        for opt_backtest in optimization.backtests.values:\n",
    "            for kvp in opt_backtest.parameter_set.value:\n",
    "                parameter_name = kvp.key\n",
    "                parameter_value = kvp.value\n",
    "                optimization_results.loc[opt_backtest.backtest_id, parameter_name] = float(parameter_value)\n",
    "            for kvp in opt_backtest.statistics:\n",
    "                statistic_name = kvp.key\n",
    "                statistic_value = kvp.value\n",
    "                if statistic_name == 'Sharpe Ratio':\n",
    "                    optimization_results.loc[opt_backtest.backtest_id, statistic_name] = float(statistic_value)\n",
    "        \n",
    "        # Drop the parameters that don't change.\n",
    "        parameter_sets = optimization_results[optimization_results.columns[:-1]]\n",
    "        optimized_params = parameter_sets[parameter_sets.columns[parameter_sets.std() > 0]]\n",
    "\n",
    "        ax = axes[-1]\n",
    "        if optimized_params.shape[1] == 1:\n",
    "            # Create a scatter plot\n",
    "            ax.scatter(\n",
    "                optimized_params.values.flatten(), \n",
    "                optimization_results['Sharpe Ratio'].values, \n",
    "                label='Sharpe Ratio'\n",
    "            )\n",
    "            ax.set_xticks(optimized_params.values.flatten())\n",
    "            ax.set_facecolor(background_color)\n",
    "            ax.legend()\n",
    "            ax.set_xlabel(optimized_params.columns[0])\n",
    "            ax.set_ylabel(\"Sharpe Ratio\")\n",
    "            ax.grid(True, which='both', linewidth=0.7, color='#FFFFFF')\n",
    "        else:\n",
    "            # Create a heat map\n",
    "            def labels(column_index):\n",
    "                return optimized_params[optimized_params.columns[column_index]].unique()\n",
    "            x_labels = labels(0)\n",
    "            y_labels = labels(1)\n",
    "            z = optimization_results['Sharpe Ratio'].values.reshape(len(y_labels), len(x_labels))\n",
    "            im = ax.imshow(\n",
    "                z, aspect='auto', \n",
    "                cmap=mcolors.LinearSegmentedColormap.from_list('custom_blue', ['#FFFFFF', blue_color], N=100)\n",
    "            )\n",
    "            # Optimization - Colorbar\n",
    "            cbar = fig.colorbar(im, ax=ax)\n",
    "            cbar.set_label('Sharpe Ratio')\n",
    "            # Optimization - Labels and title\n",
    "            ax.set_xlabel(optimized_params.columns[0])\n",
    "            ax.set_xticks(range(len(x_labels)))\n",
    "            ax.set_xticklabels(x_labels)\n",
    "            ax.set_ylabel(optimized_params.columns[1])\n",
    "            ax.set_yticks(range(len(y_labels)))\n",
    "            ax.set_yticklabels(y_labels)\n",
    "            # Optimization - remove grid lines\n",
    "            ax.grid(False)\n",
    "        ax.set_title(\"Sensitivity Test: Sharpe Ratio\")\n",
    "\n",
    "    plt.subplots_adjust(left=0.05, right=0.95, top=0.975, hspace=0.4)  # Adjust spacing between plots and add top margin\n",
    "    plt.show()\n",
    "\n",
    "    # Print the optimization notes\n",
    "    print(project.optimization_notes)\n",
    "\n",
    "    # Print the backtest parameters\n",
    "    value_by_parameter = {}\n",
    "    for kvp in backtest.parameter_set.value:\n",
    "        value_by_parameter[kvp.key] = kvp.value\n",
    "    if value_by_parameter:\n",
    "        text = \"Backtest Parameters\\n\"\n",
    "        for parameter_name, value in value_by_parameter.items():\n",
    "            text += f\"{parameter_name}: {value}\\n\"\n",
    "        print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Generate some data\n",
    "x = np.linspace(0, 10, 100)\n",
    "y1 = np.sin(x)\n",
    "y2 = np.cos(x)\n",
    "y3 = np.sin(x) * np.cos(x)\n",
    "y4 = np.exp(-x)\n",
    "\n",
    "# Create a figure and a grid of subplots\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# First subplot\n",
    "ax1.plot(x, y1, 'g-', label='sin(x)')\n",
    "ax1.set_xlabel('X-axis')\n",
    "ax1.set_ylabel('sin(x)', color='g')\n",
    "ax1.tick_params(axis='y', labelcolor='g')\n",
    "ax1.set_title('Plot 1: sin(x)')\n",
    "\n",
    "# Second subplot with three series and two y-axes\n",
    "ax2.plot(x, y2, 'b-', label='cos(x)')\n",
    "ax2.set_xlabel('X-axis')\n",
    "ax2.set_ylabel('cos(x)', color='b')\n",
    "ax2.tick_params(axis='y', labelcolor='b')\n",
    "ax2.set_title('Plot 2: Multiple Series')\n",
    "\n",
    "# Add the third series to the second y-axis\n",
    "ax2_2.plot(x, y4, 'k--', label='exp(-x)')\n",
    "ax2_2.set_ylabel('sin(x) * cos(x) and exp(-x)', color='k')\n",
    "ax2_2.tick_params(axis='y', labelcolor='k')\n",
    "\n",
    "# Create a second y-axis sharing the same x-axis\n",
    "ax2_2 = ax2.twinx()\n",
    "ax2_2.plot(x, y3, 'r-', label='sin(x) * cos(x)')\n",
    "ax2_2.set_ylabel('sin(x) * cos(x)', color='r')\n",
    "ax2_2.tick_params(axis='y', labelcolor='r')\n",
    "\n",
    "# Add legends\n",
    "ax1.legend(loc='upper left')\n",
    "ax2.legend(loc='upper left')\n",
    "ax2_2.legend(loc='upper right')\n",
    "\n",
    "# Adjust layout\n",
    "fig.tight_layout()\n",
    "\n",
    "# Show plot\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Foundation-Py-Default",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
