{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fd4c71f0-ef12-41fd-9e3f-9411fd47087a",
   "metadata": {},
   "source": [
    "\n",
    "# 📘 로지스틱 회귀란?\n",
    "\n",
    "**로지스틱 회귀**는 **이진 또는 다중 클래스 분류 문제**에 사용되는 통계 기반 기계학습 알고리즘입니다. 이름은 \"회귀\"지만, 실제 목적은 \\*\\*분류(classification)\\*\\*입니다.\n",
    "\n",
    "> 핵심 개념: **입력 변수의 선형 결합 결과를 시그모이드 함수에 통과시켜 확률로 변환**\n",
    "> 이 확률을 기준으로 특정 클래스를 예측합니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔍 왜 선형 회귀가 아닌가?\n",
    "\n",
    "| 항목    | 선형 회귀       | 로지스틱 회귀            |\n",
    "| ----- | ----------- | ------------------ |\n",
    "| 예측 값  | 연속적 숫자      | 0\\~1 사이 확률         |\n",
    "| 목적    | 예측값 추정 (수치) | 이진 또는 다중 클래스 분류    |\n",
    "| 출력 해석 | 실제 수치       | 클래스에 속할 **확률**로 해석 |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧠 수학적 구조\n",
    "\n",
    "### 1. **선형 조합 계산**\n",
    "\n",
    "$$\n",
    "z = w_0 + w_1 x_1 + w_2 x_2 + \\cdots + w_n x_n = \\mathbf{w}^T \\mathbf{x}\n",
    "$$\n",
    "\n",
    "### 2. **시그모이드(Sigmoid) 함수로 확률화**\n",
    "\n",
    "$$\n",
    "\\sigma(z) = \\frac{1}{1 + e^{-z}} \\in (0, 1)\n",
    "$$\n",
    "\n",
    "* 이 확률이 0.5 이상이면 클래스 1, 아니면 클래스 0으로 분류\n",
    "\n",
    "---\n",
    "\n",
    "## 📐 결정 경계\n",
    "\n",
    "로지스틱 회귀는 다음 조건으로 분류합니다:\n",
    "\n",
    "$$\n",
    "\\hat{y} =\n",
    "\\begin{cases}\n",
    "1 & \\text{if } \\sigma(z) \\geq 0.5 \\\\\n",
    "0 & \\text{otherwise}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "결정 경계는 **선형 결정 경계**입니다. 즉, 학습된 가중치에 따라 **직선, 평면, 초평면**이 분류선을 이룹니다.\n",
    "\n",
    "---\n",
    "\n",
    "## 🔁 다중 클래스 확장 (Multiclass)\n",
    "\n",
    "### 1. **One-vs-Rest (OvR)**\n",
    "\n",
    "* 각 클래스를 나머지 모든 클래스와 구분하는 **여러 개의 이진 분류기**를 학습\n",
    "\n",
    "### 2. **Softmax 회귀 (Multinomial Logistic Regression)**\n",
    "\n",
    "* 각 클래스에 대해 **확률 분포**를 직접 예측\n",
    "* 출력값이 총합 1인 **softmax 함수** 사용:\n",
    "\n",
    "$$\n",
    "P(y=i \\mid \\mathbf{x}) = \\frac{e^{\\mathbf{w}_i^T \\mathbf{x}}}{\\sum_{j} e^{\\mathbf{w}_j^T \\mathbf{x}}}\n",
    "$$\n",
    "\n",
    "---\n",
    "\n",
    "## 🧪 학습 방식\n",
    "\n",
    "* 손실 함수: **로그 손실 (log loss)** 또는 **이진 크로스엔트로피**\n",
    "\n",
    "$$\n",
    "\\mathcal{L} = -[y \\log(p) + (1 - y) \\log(1 - p)]\n",
    "$$\n",
    "\n",
    "* 최적화 방법: **경사 하강법 (Gradient Descent)** 또는 변형 알고리즘\n",
    "\n",
    "---\n",
    "\n",
    "## ✅ 장점\n",
    "\n",
    "| 항목            | 설명                            |\n",
    "| ------------- | ----------------------------- |\n",
    "| **해석 가능성 높음** | 계수(w)가 특성의 영향력을 명확히 나타냄       |\n",
    "| **빠른 학습 속도**  | 데이터가 크지 않다면 빠르게 학습 가능         |\n",
    "| **확률 예측 가능**  | 단순 예측뿐 아니라 **신뢰도 추정** 가능      |\n",
    "| **과적합 방지 쉬움** | L1 (라쏘), L2 (릿지) 정규화 쉽게 적용 가능 |\n",
    "\n",
    "---\n",
    "\n",
    "## ⚠️ 단점\n",
    "\n",
    "| 항목                | 설명                         |\n",
    "| ----------------- | -------------------------- |\n",
    "| **선형 결정 경계만 가능**  | 복잡한 경계선 표현에는 한계            |\n",
    "| **이상치에 민감**       | 입력 스케일 조정 필요 (정규화, 표준화 등)  |\n",
    "| **다중 클래스 확장은 복잡** | OvR 또는 Softmax 방식 별도 구현 필요 |\n",
    "\n",
    "---\n",
    "\n",
    "## 🧑‍💻 Python 코드 예시\n",
    "\n",
    "```python\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.datasets import load_iris\n",
    "\n",
    "X, y = load_iris(return_X_y=True)\n",
    "\n",
    "# 다중 클래스 분류\n",
    "model = LogisticRegression(multi_class='multinomial', solver='lbfgs')\n",
    "model.fit(X, y)\n",
    "\n",
    "print(model.predict(X[:5]))\n",
    "print(model.predict_proba(X[:5]))\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "## 📊 평가 지표\n",
    "\n",
    "* **Accuracy**\n",
    "* **Precision / Recall / F1**\n",
    "* **ROC-AUC** (이진 분류 시)\n",
    "* **Confusion Matrix**\n",
    "\n",
    "---\n",
    "\n",
    "## 🧩 적용 분야\n",
    "\n",
    "| 분야         | 예시           |\n",
    "| ---------- | ------------ |\n",
    "| **의료**     | 질병 유무 예측     |\n",
    "| **마케팅**    | 구매 확률 예측     |\n",
    "| **신용 평가**  | 대출 연체 가능성    |\n",
    "| **텍스트 분류** | 이메일 스팸 여부 분류 |\n",
    "| **산업 공정**  | 고장 여부 이진 분류  |\n",
    "\n",
    "---\n",
    "\n",
    "## 📌 결론\n",
    "\n",
    "**로지스틱 회귀**는 단순하면서도 해석이 명확한 모델로, 실전에서 널리 쓰입니다.\n",
    "\n",
    "> * 복잡한 패턴 처리에는 한계가 있지만\n",
    "> * 빠르고 직관적인 모델링과 확률 기반 의사결정이 필요한 문제에 매우 적합합니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa456fcb-d0e2-40c9-981b-8b02dcfd3e16",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
